{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3578f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuraluq as neuq\n",
    "import neuraluq.variables as neuq_vars\n",
    "from neuraluq.config import tf\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d87e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(noise_u, noise_f):\n",
    "    data = sio.loadmat(\"../dataset/kdv_train.mat\")\n",
    "    x_u_train, t_u_train = data[\"x_u_train\"], data[\"t_u_train\"]\n",
    "    x_f_train, t_f_train = data[\"x_f_train\"], data[\"t_f_train\"]\n",
    "    x_test, t_test, u_test = data[\"x_test\"], data[\"t_test\"], data[\"u_test\"]\n",
    "    x_test, t_test, u_test = (\n",
    "        x_test.reshape([-1, 1]),\n",
    "        t_test.reshape([-1, 1]),\n",
    "        u_test.reshape([-1, 1]),\n",
    "    )\n",
    "    u_train, f_train = data[\"u_train\"], data[\"f_train\"]\n",
    "    train_u = x_u_train, t_u_train, u_train\n",
    "    train_f = x_f_train, t_f_train, f_train\n",
    "    test = x_test, t_test, u_test\n",
    "    return train_u, train_f, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a89c3",
   "metadata": {},
   "source": [
    "### Defining the PDE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d9f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_fn(x, u, k_1, k_2):\n",
    "    u_x, u_t = tf.split(tf.gradients(u, x)[0], 2, axis=-1)\n",
    "    u_xx = tf.gradients(u_x, x)[0][..., 0:1]\n",
    "    u_xxx = tf.gradients(u_xx, x)[0][..., 0:1]\n",
    "    f = u_t - tf.exp(k_1) * u * u_x - tf.exp(k_2) * u_xxx\n",
    "    # tf.exp(k_1) Computes exponential of k_1 element-wise (y = e^{k_1})\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681f6b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "@neuq.utils.timer\n",
    "def Samplable(\n",
    "    x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers\n",
    "):\n",
    "    # build processes\n",
    "    process_u = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.FNN(layers=layers),\n",
    "        prior=neuq_vars.fnn.Samplable(layers=layers, mean=0, sigma=1),\n",
    "    )\n",
    "    process_logk_1 = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.Identity(),\n",
    "        prior=neuq_vars.const.Samplable(mean=0, sigma=1),\n",
    "    )\n",
    "    process_logk_2 = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.Identity(),\n",
    "        prior=neuq_vars.const.Samplable(mean=0, sigma=1),\n",
    "    )\n",
    "    # build likelihood\n",
    "    likelihood_u = neuq.likelihoods.Normal(\n",
    "        inputs=np.concatenate([x_u_train, t_u_train], axis=-1),\n",
    "        targets=u_train,\n",
    "        processes=[process_u],\n",
    "        sigma=noise,\n",
    "    )\n",
    "    likelihood_f = neuq.likelihoods.Normal(\n",
    "        inputs=np.concatenate([x_f_train, t_f_train], axis=-1),\n",
    "        targets=f_train,\n",
    "        processes=[process_u, process_logk_1, process_logk_2],\n",
    "        pde=pde_fn,\n",
    "        sigma=noise,\n",
    "    )\n",
    "    # build model\n",
    "    model = neuq.models.Model(\n",
    "        processes=[process_u, process_logk_1, process_logk_2],\n",
    "        likelihoods=[likelihood_u, likelihood_f],\n",
    "    )\n",
    "    # assign and compile method\n",
    "    # Change the parameters to make the acceptance rate close to 0.6.\n",
    "    method = neuq.inferences.HMC(\n",
    "        num_samples=500,\n",
    "        num_burnin=3000,\n",
    "        init_time_step=0.01,\n",
    "        leapfrog_step=50,\n",
    "        seed=66,\n",
    "    )\n",
    "    model.compile(method)\n",
    "    # obtain posterior samples\n",
    "    samples, results = model.run()\n",
    "    print(\"Acceptance rate: %.3f \\n\"%(np.mean(results)))\n",
    "\n",
    "    processes = [process_u, process_logk_1, process_logk_2]\n",
    "    return processes, samples, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb9363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@neuq.utils.timer\n",
    "def Trainable(\n",
    "    x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers\n",
    "):\n",
    "    # build processes\n",
    "    process_u = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.FNN(layers=layers),\n",
    "        posterior=neuq_vars.fnn.Trainable(layers=layers),\n",
    "    )\n",
    "    process_logk_1 = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.Identity(),\n",
    "        posterior=neuq_vars.const.Trainable(value=0),\n",
    "    )\n",
    "    process_logk_2 = neuq.process.Process(\n",
    "        surrogate=neuq.surrogates.Identity(),\n",
    "        posterior=neuq_vars.const.Trainable(value=0),\n",
    "    )\n",
    "    # build losses\n",
    "    loss_u = neuq.likelihoods.MSE(\n",
    "        inputs=np.concatenate([x_u_train, t_u_train], axis=-1),\n",
    "        targets=u_train,\n",
    "        processes=[process_u],\n",
    "        multiplier=1.0,\n",
    "    )\n",
    "    loss_f = neuq.likelihoods.MSE(\n",
    "        inputs=np.concatenate([x_f_train, t_f_train], axis=-1),\n",
    "        targets=f_train,\n",
    "        processes=[process_u, process_logk_1, process_logk_2],\n",
    "        pde=pde_fn,\n",
    "        multiplier=1.0,\n",
    "    )\n",
    "    # build model\n",
    "    model = neuq.models.Model(\n",
    "        processes=[process_u, process_logk_1, process_logk_2],\n",
    "        likelihoods=[loss_u, loss_f],\n",
    "    )\n",
    "    # assign and compile method\n",
    "    method = neuq.inferences.DEns(\n",
    "        num_samples=20, num_iterations=20000, optimizer=tf.train.AdamOptimizer(1e-3),\n",
    "    )\n",
    "    model.compile(method)\n",
    "    # obtain posterior samples\n",
    "    samples = model.run()\n",
    "    samples = neuq.utils.batch_samples(samples)  # reshape\n",
    "\n",
    "    processes = [process_u, process_logk_1, process_logk_2]\n",
    "    return processes, samples, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1132cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(\n",
    "    logk_1_pred,\n",
    "    logk_2_pred,\n",
    "    u_pred,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    u_test,\n",
    "    x_u_train,\n",
    "    t_u_train,\n",
    "    u_train,\n",
    "):\n",
    "    k_1_pred, k_2_pred = np.exp(logk_1_pred), np.exp(logk_2_pred)\n",
    "    print(\"Mean & Std of k1 are %.3f, %.3f\" % (np.mean(k_1_pred), np.std(k_1_pred)))\n",
    "    print(\"Mean & Std of k2 are %.3f, %.3f\" % (np.mean(k_2_pred), np.std(k_2_pred)))\n",
    "\n",
    "    u_pred = np.reshape(u_pred, [-1, NT, NX])\n",
    "    mu = np.mean(u_pred, axis=0)\n",
    "    std = np.std(u_pred, axis=0)\n",
    "\n",
    "    x_test = np.reshape(x_test, [NT, NX])\n",
    "    t_test = np.reshape(t_test, [NT, NX])\n",
    "    u_test = np.reshape(u_test, [NT, NX])\n",
    "    i = 15\n",
    "\n",
    "    current_t = t_test[i][0]\n",
    "    current_x = x_u_train[t_u_train == current_t]\n",
    "    current_u = u_train[t_u_train == current_t]\n",
    "    # std = np.sqrt(std**2 + 0.1**2)\n",
    "    plt.plot(np.linspace(-10, 10, 201), mu[i, :], \"--\", label=\"mean\")\n",
    "    plt.fill_between(\n",
    "        np.linspace(-10, 10, 201), (mu + 2 * std)[i, :], (mu - 2 * std)[i, :], alpha=0.3\n",
    "    )\n",
    "    plt.plot(np.linspace(-10, 10, 201), u_test[i, :], label=\"reference\")\n",
    "    plt.plot(current_x, current_u, \"o\", label=\"observations\")\n",
    "    plt.legend()\n",
    "    plt.title(\"t=\" + str(current_t))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df53186d",
   "metadata": {},
   "source": [
    "## Load data and specify some hyperparameters\n",
    "Noise for the measurements on both u and f is assumed to be distributed as a Gaussian with zero mean and standard deviation = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d340ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Load data and specify some hyperparameters ####################\n",
    "NT, NX = 31, 201\n",
    "noise = 0.1\n",
    "train_u, train_f, test = load_data(noise, noise)\n",
    "x_u_train, t_u_train, u_train = train_u\n",
    "x_f_train, t_f_train, f_train = train_f\n",
    "x_test, t_test, u_test = test\n",
    "\n",
    "layers = [2, 50, 50, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db437b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supporting backend tensorflow.compat.v1\n",
      "\n",
      "Compiling a MCMC method\n",
      "\n",
      "sampling from posterior distribution ...\n",
      "\n",
      "Finished sampling from posterior distribution ...\n",
      "\n",
      "Acceptance rate: 0.828 \n",
      "\n",
      "Execution time for 'Samplable' function is: 332.760 s, 5.546 mins\n"
     ]
    }
   ],
   "source": [
    "############################### Choose framework #################################\n",
    "processes, samples, model = Samplable(x_u_train, t_u_train, u_train, \n",
    "                                      x_f_train, t_f_train, f_train, noise, layers,)\n",
    "    # processes, samples, model = Trainable(\n",
    "    #     x_u_train, t_u_train, u_train, x_f_train, t_f_train, f_train, noise, layers,\n",
    "    # )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea2ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Predictions ####################################\n",
    "u_pred, logk_1_pred, logk_2_pred = model.predict(np.concatenate([x_test, t_test], axis=-1), \n",
    "                                                 samples, processes, pde_fn=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a44fb78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean & Std of k1 are 1.419, 0.038\n",
      "Mean & Std of k2 are 0.264, 0.008\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################### Postprocessing ###################################\n",
    "    # TODO: save the results, instead of visualizing them.\n",
    "plots(\n",
    "    logk_1_pred,\n",
    "    logk_2_pred,\n",
    "    u_pred,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    u_test,\n",
    "    x_u_train,\n",
    "    t_u_train,\n",
    "    u_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf7b28",
   "metadata": {},
   "source": [
    "### Prove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0d20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NT, NX = 31, 201\n",
    "noise = 0.3\n",
    "train_u, train_f, test = load_data(noise, noise)\n",
    "x_u_train, t_u_train, u_train = train_u\n",
    "x_f_train, t_f_train, f_train = train_f\n",
    "x_test, t_test, u_test = test\n",
    "\n",
    "layers = [2, 50, 50, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca79cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supporting backend tensorflow.compat.v1\n",
      "\n",
      "Compiling a MCMC method\n",
      "\n",
      "sampling from posterior distribution ...\n",
      "\n",
      "Finished sampling from posterior distribution ...\n",
      "\n",
      "Acceptance rate: 0.778 \n",
      "\n",
      "Execution time for 'Samplable' function is: 364.178 s, 6.070 mins\n"
     ]
    }
   ],
   "source": [
    "processes, samples, model = Samplable(x_u_train, t_u_train, u_train, \n",
    "                                      x_f_train, t_f_train, f_train, noise, layers,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a747c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred, logk_1_pred, logk_2_pred = model.predict(np.concatenate([x_test, t_test], axis=-1), \n",
    "                                                 samples, processes, pde_fn=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d60ab81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean & Std of k1 are 0.859, 0.065\n",
      "Mean & Std of k2 are 0.191, 0.014\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGxCAYAAAA+tv8YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3bklEQVR4nO3dd3gc1bn48e/MVu2qd8mWe8cFF4pNM9U0h5JAIMSBELiBGAiY0EIuLcWGm5B6QwKXEHIJMT/AJuTSDRiCwWBcwGBjcJVlS5bVy2rbzPz+mN2V1urSSqtdvZ/n2UfamTO7Z7X26tV7znmPYhiGgRBCCCFEDKjx7oAQQgghkocEFkIIIYSIGQkshBBCCBEzElgIIYQQImYksBBCCCFEzEhgIYQQQoiYkcBCCCGEEDEjgYUQQgghYkYCCyGEEELEjAQWQgxT77//Pvfddx91dXUxe8w1a9Ywf/58XC4Xubm5XHXVVVRWVvb4+pUrV3L00UfjdDopLi7m5ptvpqmpKWb9E0IMPAkshBim3n//fe6///6YBRbvvPMO55xzDgUFBfzzn//kt7/9LWvWrOH000/H5/N1e/3f//53Lr/8co455hheeeUV7r33Xv76179y8cUXx6R/QojBYY13B4QQyeG2225j0qRJPPfcc1it5kfL2LFjOeGEE/jLX/7C9ddf3+m1mqZx2223cdZZZ/HYY48BcOqpp5KWlsYVV1zBK6+8wjnnnDMor0MI0T+SsRBiGLrvvvu47bbbAPOXv6IoKIrC2rVr+/R4Bw4cYMOGDSxZsiQSVAAsWLCASZMmsXr16i6vX79+PeXl5Xz3u9+NOn7JJZeQmpra7fVCiKFDMhZCDEPXXHMNNTU1/P73v2fVqlUUFRUBMG3aNHRdR9f1bh9DURQsFgsAn332GQAzZ85s127mzJmsW7euy8fq7HqbzcaUKVMi54UQQ59kLIQYhkaOHMmoUaMAmD17NscffzzHH3886enpXH311dhstm5vp59+euTxqqurAcjOzm73XNnZ2ZHznenv9UKIoUMyFkKIKPfddx833HBDt+3S0tLaHVMUpcO2nR2P9fVCiPiTwEIIEWXUqFGMHDmy23Ztf9nn5OQAdJhZqKmp6TAT0Vbb6wsKCnp9vRBi6JChECFElL4MhUyfPh2ArVu3tnu8rVu3Rs53ZsaMGR1eHwwG+eKLL7q9XggxdEjGQohhyuFwANDS0hJ1vC9DISNGjODYY4/lqaee4kc/+lFkUuf69evZsWMHN998c5ePddxxx1FUVMRf//pXvvnNb0aOP/fcczQ1NUktCyESiGIYhhHvTgghBt/atWs59dRT+f73v8+VV16JzWZj8uTJHc6d6OnjnXnmmSxevJgf/OAHVFZWcuedd5KRkcHHH38cCWT27dvH+PHjufLKK3n88ccj1z/11FMsWbKE//iP/+Dyyy/nq6++4vbbb+eYY47h9ddfj8lrFkIMPBkKEWKYWrhwIXfddRf/+te/OPHEEznmmGPYuHFjvx7v5Zdfpry8nMWLF3PjjTdy6qmn8uabb0aCCgDDMNA0DU3Toq7/9re/zdNPP8369etZtGgR99xzD9/5zndYtWpVn/skhBh8krEQQgghRMxIxkIIIYQQMSOBhRBCCCFiRgILIYQQQsSMBBZCCCGEiBkJLIQQQggRMxJYCCGEECJmBr3ypq7rHDx4kLS0NNlYSAghhEgQhmHQ2NhIcXExqtp5XmLQA4uDBw9SUlIy2E8rhBBCiBjYv39/lxsVDnpgES4XvH//ftLT0wf76YUQQgjRBw0NDZSUlHRb9n/QA4vw8Ed6eroEFkIIIUSC6W4ag0zeFEIIIUTMSGAhhBBCiJiRwEIIIYQQMTPocyyEEEIMPsMwCAaD7barFyLMYrFgtVr7XQpCAgshhEhyfr+f8vJyPB5PvLsihjiXy0VRURF2u73PjyGBhRBCJDFd19mzZw8Wi4Xi4mLsdrsUJxTtGIaB3+/n8OHD7Nmzh4kTJ3ZZBKsrElgIIUQS8/v96LpOSUkJLpcr3t0RQ1hKSgo2m419+/bh9/txOp19ehyZvCmEEMNAX//6FMNLLP6dyL80IYQQQsSMBBZCCCGEiBkJLIQQQggRMxJYCCGEECJmJLAQQgghRMz0KrAYM2YMiqK0uy1dunSg+ieESCAefzDeXRC94PEHO715A1rM2/bWwoULufHGG7n55pvJysqioKCARx99lObmZr773e+SlpbG+PHjeeWVVyLXbNu2jXPPPZfU1FQKCgpYsmQJVVVVkfOvvvoqJ554IpmZmeTk5HD++eeza9euyPm9e/eiKAqrVq3i1FNPxeVyMWvWLD744INe93+46lUdiw0bNkSVg/3ss88488wzueSSS2LeMSFE4imrbcGqKozLS413V0QPTLvntU7PnTo5jye+e2zk/tyfrqEl0HE58OPGZvPM9+dH7p/44NvUNPvbtdu74rxe9/HJJ5/k9ttv56OPPuKZZ57h+uuv54UXXuCiiy7ixz/+Mb/+9a9ZsmQJpaWl1NfXc8opp3Dttdfy8MMP09LSwh133MGll17KW2+9BUBzczPLli1jxowZNDc3c88993DRRRexZcuWqKWWd999N7/85S+ZOHEid999N5dffjk7d+7EapXyT93p1U8oLy8v6v6KFSsYP348p5xySkw7JYRITB6/RlWjD6fNQnFmSry7I5LArFmz+MlPfgLAXXfdxYoVK8jNzeXaa68F4J577uGRRx7h008/5eWXX2bOnDn84he/iFz/l7/8hZKSEr788ksmTZrE17/+9ajHf/zxx8nPz2fbtm1Mnz49cvxHP/oR551nBkL3338/Rx11FDt37mTKlCkD/ZITXp9DL7/fz1NPPcWyZcu6LA/r8/nw+XyR+w0NDX19SiHEEOfxmenunZVNElgkgG0PLOr0nHrE5/rG/zyjx23fu+PU/nWsjZkzZ0a+t1gs5OTkMGPGjMixgoICACorK9m4cSNvv/02qantM2a7du1i0qRJ7Nq1i//8z/9k/fr1VFVVoes6AKWlpVGBRdvnLSoqijyHBBbd63Ng8cILL1BXV8dVV13VZbvly5dz//339/VphBAJQteNSKrcH9TRdAOLKntSDGUue89/BQxU2+7YbLao+4qiRB0L/2Gr6zq6rrN48WIefPDBdo8TDg4WL15MSUkJjz32GMXFxei6zvTp0/H7o4duOnsO0b0+v/uPP/4455xzDsXFxV22u+uuu1i2bFnkfkNDAyUlJX19WiHEEOUNahhG6/2WgEaqQ8ajxeCZM2cOzz//PGPGjOlwLkR1dTXbt2/nz3/+MyeddBIA77333mB3M+n1abnpvn37WLNmDddcc023bR0OB+np6VE3IUTy8fijJ/a1+Due6CfEQFm6dCk1NTVcfvnlfPTRR+zevZvXX3+dq6++Gk3TyMrKIicnh0cffZSdO3fy1ltvRf3hK2KjT4HFE088QX5+fmRiixBCeHzRgcSRSxCFGGjFxcWsW7cOTdNYtGgR06dP54c//CEZGRmoqoqqqqxcuZKNGzcyffp0brnlFv7rv/4r3t1OOr3OU+q6zhNPPMGVV14py26EEBGeQHSdgs6WJgrRU2vXrm13bO/eve2OGW3G4CZOnMiqVas6fcwzzjiDbdu2dXr9mDFjou4DZGZmtjsmOtfrjMWaNWsoLS3l6quvHoj+CCESlAyFCCGgDxmLs846SyI3IUQ7Rw6FSMZCiOFJ9goRQvSbphvt5lRIxkKI4UkCCyFEv3WUndB0A39Q1v0LMdxIYCGE6Ldwxc0jyXCIEMOPBBZCiH47cuJmmAyHCDH8SGAhhOi3TgMLyVgIMexIYCGE6DdfUDIWQgiTBBZCiH4LaB0vQZeMhRDDjwQWQoh+C2odr/6Qst5isBmGwX/8x3+QnZ2Noihs2bIl3l0adqQmtxCi3/xdBBaGYUS2nRZioL366qv89a9/Ze3atYwbN47c3Nx4d2nYkcBCCNEvhmEQ7GQoxDDAF9Rx2iyD3CuRjPx+P3a7vcs2u3btoqioiAULFvT5eQzDQNM02Q+rj2QoRAjRL53NrwjrLJsh4sgwwN8cn1svtoRYuHAhN9xwA8uWLSM3N5czzzyTbdu2ce6555KamkpBQQFLliyhqqoKgKuuuoobb7yR0tJSFEVhzJgxoZdr8NBDDzFu3DhSUlKYNWsWzz33XOR51q5di6IovPbaa8ybNw+Hw8G///3vHl/35ptvMm/ePFwuFwsWLGDHjh1Rr+PFF19k3rx5OJ1OcnNzufjiiyPn/H4/t99+OyNGjMDtdnPcccd1uPlaIpFwTAjRL0G968AhINU3h56AB35RHJ/n/vFBsLt73PzJJ5/k+uuvZ926ddTU1HDKKadw7bXX8vDDD9PS0sIdd9zBpZdeyltvvcVvf/tbxo8fz6OPPsqGDRuwWMxM2U9+8hNWrVrFI488wsSJE3n33Xf59re/TV5eHqecckrkuW6//XZ++ctfMm7cODIzM3t83d13382vfvUr8vLyuO6667j66qtZt24dAC+99BIXX3wxd999N//7v/+L3+/npZdeilz73e9+l71797Jy5UqKi4tZvXo1Z599Nlu3bmXixIn9/WnHhWIM8o5iDQ0NZGRkUF9fT3p6+mA+tRBiANR7AmzYW9Pp+ekjMijMcA5ij0RbXq+XPXv2MHbsWJzO0Pvgb06IwGLhwoXU19ezefNmAO655x4+/PBDXnvttUibsrIySkpK2LFjB5MmTeI3v/kNv/nNbyLbqzc3N5Obm8tbb73F/PnzI9ddc801eDwenn76adauXcupp57KCy+8wAUXXNDr69asWcPpp58OwMsvv8x5551HS0sLTqeTBQsWMG7cOJ566ql2r2/Xrl1MnDiRsrIyiotb348zzjiDY489ll/84hc9/KHGTof/XkJ6+vtbMhZCiH7pbqhD9gsZgmwu8xd8vJ67F+bNmxf5fuPGjbz99tukpqa2a7dr1y4mTZrU7vi2bdvwer2ceeaZUcf9fj+zZ8/u9Ll6c93MmTMj3xcVFQFQWVnJqFGj2LJlC9dee22Hr23Tpk0YhtGu3z6fj5ycnA6vSQQSWAgh+qW7oRCZYzEEKUqvhiPiye1u7aeu6yxevJgHH3ywXbvwL/Qj6aF/ny+99BIjRoyIOudwOLp8rp5eZ7PZIt+HV0CFr09JSemwX+E2FouFjRs3RoZtwjoKnhKFBBZCiH4JBLseTQ1IYCFiZM6cOTz//POMGTOmxys2pk2bhsPhoLS0NGpexEBdd6SZM2fy5ptv8t3vfrfdudmzZ6NpGpWVlZx00kl9fo6hRgILIUS/dJeRkMBCxMrSpUt57LHHuPzyy7ntttvIzc1l586drFy5kscee6zdX/0AaWlp/OhHP+KWW25B13VOPPFEGhoaeP/990lNTeXKK6/s8Ln6et2R7r33Xk4//XTGjx/PZZddRjAY5JVXXuH2229n0qRJXHHFFXznO9/hV7/6FbNnz6aqqoq33nqLGTNmcO655/br5xUvElgIIfqlu8BBAgsRK8XFxaxbt4477riDRYsW4fP5GD16NGeffTaq2nn1hJ/+9Kfk5+ezfPlydu/eTWZmJnPmzOHHP/5xl8/X1+vaWrhwIc8++yw//elPWbFiBenp6Zx88smR80888QQ/+9nPuPXWWzlw4AA5OTnMnz8/YYMKkFUhQoh+2lpWz6EGL9vLGyit8TAxP5Vxea3jwy6HhQXjpfphvHQ1y1+II8ViVYgUyBJC9Et4KGRTaS3Pbixjy/466jx+dh1uwjCMbgtoCSGSiwQWQoh+CQ911DT7AchIsXHbc5+y/JUvaPIFCWo6g5wYFULEkQQWQoh+Ce8TUh0KLArSnWSk2CLHDKP7st9CiOQhgYUQol+OzFhku+1ku82Noqqb/FFthBDJTwILIUSf6bqBphu0+DU8fg2IDizCwYYEFkIMHxJYCCH6LDxxs8ZjBhAuuwWnzUJOanRgIdU3hRg+JLAQQvRZOBNR3eQDICeUqchxmyWPq5t9oXYyx0KI4UIKZAkh+iw8cXNyYRr3nDeNQGh/hCOHQmQjMiGGDwkshBB9Fs5YOKwWRuW07lo5IjOFs6YVUJyREtVOCJH8ZChECNFnAb3jIY68NAeXzivhxIlmxU3JWCQHTdfYULGBl3e/zIaKDWi6Fre+rF27FkVRqKuri1sfYu2qq67iwgsvjHc3+k0yFkKIPguEAoY3th1CNwzmjc4iJ9XRvp1kLBLemn1rWPHRCg55DkWOFbgKuPPYOzlj9Blx7Fni2bt3L2PHjmXz5s0cffTRkeO//e1vk6KYnGQshBB9Fg4Y3th+iGc3llHXEoica2gJsOtwE/UtAZm8meDW7FvDsrXLooIKgEpPJcvWLmPNvjVx6tng8vv9A/r4GRkZZGZmDuhzDAYJLIQQfRbQzDoWdZ7W4lhhf1m3h+WvfMGnZXWSsUhgmq6x4qMVGLQPDsPHHvzowQEZFvH5fNx0003k5+fjdDo58cQT2bBhQ1SbdevWMWvWLJxOJ8cddxxbt26NnNu3bx+LFy8mKysLt9vNUUcdxcsvvxw5v23bNs4991xSU1MpKChgyZIlVFVVRc4vXLiQG264gWXLlpGbm8uZZ57J5ZdfzmWXXRbVh0AgQG5uLk888QQAr776KieeeCKZmZnk5ORw/vnns2vXrkj7sWPHAjB79mwURWHhwoVA+6GQ7l5/eDjozTffZN68ebhcLhYsWMCOHTsibT755BNOPfVU0tLSSE9PZ+7cuXz88ce9fSt6RQILIUSfBTSd+pYAugEWVYmU8gYiQyLVzX6ZY5HANlVuapepaMvAoMJTwabKTTF/7ttvv53nn3+eJ598kk2bNjFhwgQWLVpETU1NpM1tt93GL3/5SzZs2EB+fj5f+9rXCATMzNnSpUvx+Xy8++67bN26lQcffJDUVHPn3fLyck455RSOPvpoPv74Y1599VUOHTrEpZdeGtWHJ598EqvVyrp16/jzn//MFVdcwYsvvkhTU1OkzWuvvUZzczNf//rXAWhubmbZsmVs2LCBN998E1VVueiii9BDq6Y++ugjANasWUN5eTmrVq3q8+sHuPvuu/nVr37Fxx9/jNVq5eqrr46cu+KKKxg5ciQbNmxg48aN3HnnndhstiOfKqZkjoUQos8Cmh6pVZHlsqEqSuRc2yWnWqhCp0VVOnwcMXQd9hyOabueam5u5pFHHuGvf/0r55xzDgCPPfYYb7zxBo8//jjHHHMMAPfeey9nnnkmYAYBI0eOZPXq1Vx66aWUlpby9a9/nRkzZgAwbty4yOM/8sgjzJkzh1/84heRY3/5y18oKSnhyy+/ZNKkSQBMmDCBhx56KNJm/PjxuN1uVq9ezZIlSwB4+umnWbx4cWQr8XCAEfb444+Tn5/Ptm3bmD59Onl5eQDk5ORQWFjYp9d/2223Rdr+/Oc/55RTTgHgzjvv5LzzzsPr9eJ0OiktLeW2225jypQpAEycOLGH70DfScZCCNFnAc2I2iOkrRwp650U8lx5MW3XU7t27SIQCHDCCSdEjtlsNo499li2b98eOTZ//vzI99nZ2UyePDly/qabbuJnP/sZJ5xwAvfeey+ffvpppO3GjRt5++23SU1NjdzCv3zbDlvMmzcvql82m41LLrmEv//974AZAPzzn//kiiuuiOr7t771LcaNG0d6enpk6KO0tDTmrx9g5syZke+LiooAqKysBGDZsmVcc801nHHGGaxYsSLqtQ0UCSyEEH0W0PTIRmPhapthR25EJmW9E9Oc/DkUuApQ6DjbpKBQ6CpkTv6cmD5veHWEoijtjh95rF2fQuevueYadu/ezZIlS9i6dSvz5s3j97//PQC6rrN48WK2bNkSdfvqq684+eSTI4/ldrvbPf4VV1zBmjVrqKys5IUXXsDpdEayCgCLFy+murqaxx57jA8//JAPP/wQ6N3kz968/rZDG+Fz4WGX++67j88//5zzzjuPt956i2nTprF69eoe96Mveh1YHDhwgG9/+9vk5OTgcrk4+uij2bhx40D0TQgxxAV1vfuMhcePbhiRpakisVhUC3ceeydAu+AifP+OY+/Aolpi+rwTJkzAbrfz3nvvRY4FAgE+/vhjpk6dGjm2fv36yPe1tbV8+eWXkcwDQElJCddddx2rVq3i1ltv5bHHHgNgzpw5fP7554wZM4YJEyZE3ToKJtpasGABJSUlPPPMM/z973/nkksuwW4PBdLV1Wzfvp2f/OQnnH766UydOpXa2tqo68NtNa3zCa89ff09MWnSJG655RZef/11Lr744sgk04HSq8CitraWE044AZvNxiuvvMK2bdv41a9+lRTLY4QQvaPpBroOF88ZwT3nTeOkUDGssEyXHUUx2zXIktOEdsboM3h44cPku/Kjjhe4Cnh44cMDUsfC7XZz/fXXc9ttt/Hqq6+ybds2rr32WjweD9/73vci7R544AHefPNNPvvsM6666ipyc3MjKytuvvlmXnvtNfbs2cOmTZt46623Ir+Uly5dSk1NDZdffjkfffQRu3fv5vXXX+fqq6/u8hc+mFmBb33rW/zpT3/ijTfe4Nvf/nbkXFZWFjk5OTz66KPs3LmTt956i2XLlkVdn5+fT0pKSmTCaH19fZ9ff1daWlq44YYbWLt2Lfv27WPdunVs2LCh14FJb/Vq8uaDDz5ISUlJVLQzZsyYLq/x+Xz4fL7I/YaGht71UAgxJIXnTLjsVkblWLG3HKZk6/9SMep8mjMmYVEVLjx6BDaLgtWiyhyLBHfG6DM4teRUNlVu4rDnMHmuPObkz4l5pqKtFStWoOs6S5YsobGxkXnz5vHaa6+RlZUV1eaHP/whX331FbNmzeLFF1+MyggsXbqUsrIy0tPTOfvss/n1r38NQHFxMevWreOOO+5g0aJF+Hw+Ro8ezdlnn42qdv839xVXXMEvfvELRo8eHTUPQlVVVq5cyU033cT06dOZPHkyv/vd7yJLSgGsViu/+93veOCBB7jnnns46aSTWLt2bZ9ef1csFgvV1dV85zvf4dChQ+Tm5nLxxRdz//339+j6vlKMXpT5mjZtGosWLaKsrIx33nmHESNG8IMf/IBrr72202vuu+++Dl9EfX19ZAatECLxNHoDfLjbXPamBluY9/YVpNd+hs+Rw0dnPI/PXRzVflyem3F5qfHo6rDm9XrZs2cPY8eOxel0xrs7Yojr6t9LQ0MDGRkZ3f7+7tVQyO7du3nkkUeYOHEir732Gtdddx033XQTf/vb3zq95q677qK+vj5y279/f2+eUggxRIV3Nn1hcxmZa24hvfYzABy+ao5edz1q0BPdvpN9RYQQyaVXgYWu65F1v7Nnz+b73/8+1157LY888kin1zgcDtLT06NuQojEF9B1dN0gb/sTzGl4C12x8tlx/4XfkU1a3XambLqfOo+f3YebqG7ySZEsIYaJXgUWRUVFTJs2LerY1KlTe7U2VwiRHIKagcevcYX6JgA7Zt5GxegL+HT+7wAo3PcvXt/8Fb945Qve31UtGQshholeBRYnnHBCVA1ygC+//JLRo0fHtFNCiKEvqBkYdfuYoB4kaKgcGmtWG6zLPxZP6mhUI8hczdy3ockXlMmbQgwTvQosbrnlFtavX88vfvELdu7cydNPP82jjz7K0qVLB6p/Qoghyq/p5FT8G4CtyiSC9tZhzurCkwCY6TM3O5LAIv6SYTtuMfBi8e+kV4HFMcccw+rVq/nHP/7B9OnT+elPf8pvfvObqFKmQojhIajrFFWtA+Bj29yoc9VFZmAxtfkjwAgFFvKLLR7CVRk9Hk83LYVo/XfSn43Ker0J2fnnn8/555/f5ycUQiQHze9jbJ25hfNnzmMYGzqe6bIxdu7Z6OtsZPorGK8cpMnnJigZi7iwWCxkZmZG9o5wuVzdlsQWw49hGHg8HiorK8nMzMRi6Xt9EtndVAjRJ7byj3HoHqqMdCpc5k6QeWkOZo7MQFEUavKOIfvQ+5yifsqLvrEYBgQ1HatFtigabOEdNMPBhRCdyczM7HTH1Z6SwEII0Sep+98BoL7oRBYfPRKANKc18tdw/YhTQoHFJzztOw8wd0O1DlyhRtEJRVEoKioiPz+fQCAQ7+6IIcpms/UrUxEmgYUQok/SD7wLQMvoUylMNyv0OWytH0qeUQth03LmW7/g4qk5GIZBQNdJQSKLeLFYLDH5xSFEVyQnKYToPX8z7tptANTkz48ctrcZ5jByp+Bz5mE3/FxUWIOiKLLDqRDDgAQWQojeO/wFCgZN1ixW79Q41OAFwGFr/Uhx2i00ZprbV6fWm/VvpEiWEMlPAgshRK9p5ea+IF/oJazefICqJnMH47YZC4fVQlOGOalTq/iMJq/UshBiOJDAQgjRa8ahzwEzsABwO6woCjisbQMLlaaMyQA07/+UHYcapZaFEMOABBZCiN4LBRZbg+ZqkFSHFbtVjaqP4LC1ZiymKKU0eQNSy0KIYUACCyFE7xgG6mFz4ubnmpmxSHVYo4ZBwMxYNKdPQEMlQ/FgaS7HL4GFEElPAgshRO80HUJtqUFH5StjJBZVwWFVo5aaQmhYxGrnkM0MPrKaviIoQyFCJD0JLIQQvRMaBmlwjcKHnVSHWRTryIyFoijYrSqHUsYDkO/ZKZM3hRgGJLAQQvROKLA4HAoY3A4zU9F2qWmY02ah2j0BgCLvbpm8KcQwIJU3hRC9U2nOr9Dzp3HvnGnoodoUbVeEhDmsKvXpk6EcSoJ7OKhLxkKIZCcZCyFE7xwya1h4s6dQkuVidI4bAHsHgYXTZsFSeBQAY/Qygn7v4PVTCBEXElgIIXpOC8Jhs4pmuEZFmKOD3cUcVpXU/LEEbalY0HDW70GT6ptCJDUJLIQQPVezCzQ/mtXF+9Vu/u/Tg+w+3AR0NhRiAUWJ1LNIq98hEziFSHISWAgheq56JwAtGePYuL+eF7Yc5KtKM7A4clUIgDM0obPKOQYAR8MeCSyESHISWAgheq5mDwDe1FE0+YKAWc7bZlVRVaVd8/DwyIulDgDUur1Sy0KIJCeBhRCi52rNwKLZPYpmnwaYVTc7GgaB1uGRSlsxAO7m/ZKxECLJSWAhhOi5UMai2VXSJmNh6XBFCICqKtisKjX2EQCktewnIJM3hUhqElgIIXoulLFoSR1Fk9cMLLrKWIA596LOaQYW7kAtWkvDwPdTCBE3ElgIIXpGC0JdKQBNrhJaAm2HQtovNQ2zWRTUlAxqjFTzQO3ege6pECKOJLAQQvRMQxnoQQyLg2o1J3LYZe86Y2GzqKQ6rJQaBQAoElgIkdSkpLcQomdC8yu0jFG4nDbuXTyNFr+GRVU6nWMBYLUouO1W9hkFHM0urPV7BqvHQog4kIyFEKJnQvMrAumjsaoqJVkuJhWkAWZWojN2i8qkgjTseeamZdb6fQPfVyFE3EjGQgjRM6GMhT99dLtTNkv7GhZhVovK5MI0ilqOghqwSWAhRFKTwEII0TM1uwHwpo1id1UT2w42MDrHzYwRGV1mLMJBR0tqCQDORgkshEhmMhQihOiZ0KRLj7uELyuaeGHLQT7aUwN0XM47zGZRCeo6+0KTNx2egxD0D3h3hRDxIYGFEKJ7hhEZCmlyj4oqjmVRlQ7LeYfZLCrVTX5uffUQLYYdxdAJ1kjWQohkJYGFEKJ7zYch0AwoNDmLafa1FsfqahgEzKEQt8MKKJGshVa9e4A7LISIFwkshBDdC2UryBiJFxtN/tYNyKxdTNwEM2PhsltQgFIjHwC9RpacCpGsJLAQQnQvtNTUyBqDphm9zFioqIqCy26JZCzCE0GFEMlHAgshRPdqzTkRWoa51LSpTWDR1cRNIDQHw8xuhDMWSp3MsRAiWUlgIYToXv1+AIJpIwEiG5D1ZCgEzKyF22HlgJELgNpwYIA6KoSIN6ljIYToXn0ZAP7UYgBuPXMyjb4ABWmObodCAKyqitth4WAosLA0SmAhRLLqVcbivvvuQ1GUqFthYeFA9U0IMVSEMhY+lxlYjMhKYUphOg6bpduhEAC7VeGY0dnMmHYUABZvDfibB66/Qoi46XXG4qijjmLNmjWR+xZL59slCyGSgGFEMhYeVzEcUdvKZu1+KMSqqpwwIRfIJViaijXQBPUHIG/SAHRYCBFPvQ4srFZrr7IUPp8Pn88Xud/Q0NDbpxRCxJOnGoJeQKHFmU91TQsf7K4mN9XB8eNysKrdZyzaDpd4XcWk1n9pZkEksBAi6fR68uZXX31FcXExY8eO5bLLLmP37q6XjS1fvpyMjIzIraSkpM+dFULEQWgYhNQCfIaN8novL2w5yGufVwBdl/MOs1kUfEGNigYv9fbQktNQFkQIkVx6FVgcd9xx/O1vf+O1117jscceo6KiggULFlBdXd3pNXfddRf19fWR2/79+/vdaSHEIAoHABkj8Wt6pIaFWU2zZ0MhNovKptI6fvLCZ2ypT41+XCFEUunVUMg555wT+X7GjBnMnz+f8ePH8+STT7Js2bIOr3E4HDgcjv71UggRP3WhPwYyRuIP6lE1LIAerQqxWVXcdnM+VpmRYx6slz8yhEhG/apj4Xa7mTFjBl999VWs+iOEGGrCmYXMkqjAwu2woihg7WIDsjCbqkQyHKWaGVgYdRJYCJGM+hVY+Hw+tm/fTlFRUaz6I4QYakKZBS1tJJpu0OzTADNjYbWoKErPC2QB7A1kA2DIUIgQSalXgcWPfvQj3nnnHfbs2cOHH37IN77xDRoaGrjyyisHqn9CiHgLBQDBNLOGRdst0209yFYAWC1KZChkTyALAKXhAOh6rHsrhIizXs2xKCsr4/LLL6eqqoq8vDyOP/541q9fz+jRoweqf0KIeAtX3XQXQwvRG5BZe/a3ibnDqflxc4gsDFQUPQDNlZAmRfaESCa9CixWrlw5UP0QQgxFAa/5yx+z/gQt8K3jRlHr8VOY7uzRxE0wAwuLqpBis9ASAI8zH7e3wpwYKoGFEElF9goRQnQuvFmYzYXXmgE0UZDupCDdaR7uwQZk0LrD6elTzd1NWw4XmYFF/X4oOWYgei6EiBMJLIQQnQsvCc0ooSXYfj5ETzMW4bYXHj0CgMD6kVC7WWpZCJGEZNt0IUTn2hTHavYFCeo6//fpQd7eUUlQ13sdWIR5XUXRjy+ESBqSsRBCdK5NYNHi12j2abyw5SCKAqdMyuvxUAiYwyYef5CGliA5NinrLUSykoyFEKJzoaEQPX0kLQGNJm9oqandiqoovc5YrN58gJ/88zPWV6dEPb4QInlIYCGE6FwooxBILcIwoMEbACDN2fNy3mFWVcUdWnJ60MgNPb4EFkIkGwkshBCdazgIQEuKOSei1uMHINNlA3q+KgTAbm0t612mmUWyaKmFQEuseiuEGAIksBBCdK6hHACPw1wmWucxMxZZLjvQ+4xFaijTccjvRLOEhkNCwYsQIjlIYCGE6Ji3AfyNADTY84D2GQt7b+ZYWFXSQhmLJr+G1xUqjCWBhRBJRQILIUTHGs1sBY4Mmg2zIFYkY5Fix2pRUHu4VwiYO5yGt1pv9AbwpYRWhkhgIURSkeWmQoiOhatuphfj8ZurQS47poTTp+aTn+bsVbYCzGGT8KTPJl8Qb0o4Y3EgZl0WQsSfBBZCiI6F5lcY6cX4AmbVzZxUBzmpDgDsPdyALMxqUUh1Wjl1ch6pDiteNRRYhDMjQoikIIGFEKJjoSGKgLvjTcJ6M3Ez3N5htXDFceZuyL6dMsdCiGQkcyyEEB1rDAUWoUmWTd4gL2w5wL+/Ogz0PmNxZCDic8lQiBDJSDIWQoiOhWtYOM1JlpVNXv7v03KyXDZOmpjX64yFRVWwqAoNLQEavUGsltyo5xFCJAfJWAghOhb6hd/s7LiGhaOXGQsw51n8+d3d/OSfn7GxNlTHoqkSgv4YdFgIMRRIYCGE6FgosGiwmjUswoFFpIZFHwILm0WNLDmt1Nzoqh0woKkiBh0WQgwFElgIIdoL+sBTBUCN1RyyaC2O1fuqm2G20MoQgEa/jt8ltSyESDYSWAgh2gstATUsDgK2TKDtUEj/MhaR6pteqWUhRDKSwEII0V6ohkUwtQgUs7rmkRmL3hbIguj9Qhp9QbyR6ptSy0KIZCGBhRCivVAGITJUQXTGQlF6t7NpmN2qdJKxkKEQIZKFLDcVQrQXGgoJLzUFuOn0CdQ0+xmV7cJmUVGU3gcWbTMWTb5gm/1CZChEiGQhgYUQor3wUtPQdukA+WlO8tPMzcj6MnETzB1O81IdnDo5j9xUR5siWZKxECJZSGAhhGgv9Ive6+y4nHdfJm6COXySk+qIlPX2Vh+Kej4hROKTORZCiPZCv+h9oTkWB+taeGHLAT7eVwP0beImgE09oqx3eCiksRx0rY+dFUIMJRJYCCHaC2csQpMr91Q383+flvPul2Ztiz5nLELXNXmDHKxrocGWjaFYwNDMCpxCiIQngYUQIpquRSphhjMKNU3mUtNsd2ipaR8DC6tqTvj8+SvbuefFzymt8RF0heZxNMpwiBDJQAILIUS05sOgBzEUFb/TrLpZVtcCQFFGePJm71eEmNeZHzmRJae+IH6ZwClEUpHAQggRLTy/wpmLoZoBwIFaM7AYmWVuHNbXjEV4h9NIkSxvUFaGCJFkJLAQQkQLBxah+RUBTedQoxeAEZmhwKKPkzfB3OE0tU3GIlIrQ2pZCJEUJLAQQkQLFccKz68or/NiGOC2W8hI6fs+IWE2i0pam7LenhTZiEyIZCKBhRAiWihzEF4RciA0v2JEVkqk2mZ/Mha2thkLbxCvUwILIZKJFMgSQkTR6w+i0pqxOH5cNpMKUvEGdQBUFaz9CixU0hxm5qPRF5AdToVIMhJYCCGiaPUHzMAiNKlSUcxqmWF2i6Vfj29VVUZmpXDq5DxKsl34XC7zREM5GEZkN1UhRGKSwEIIES0yebOgw9P9mV9hXq8wJtfNmFy3+TyaWSMDzQeeGnDn9OvxhRDx1a9PiOXLl6MoCjfffHOMuiOEiCvDwNJkTt70phTS5AvyyNpd/OuTgxiGAUCKrX8ZiyM3MDMsdjRXnnlHhkOESHh9Diw2bNjAo48+ysyZM2PZHyFEnGi6xobStbzqUNjgdNDizKWs1sPG0lrW7aqKTNx02vqXsQjPz2jyBjlQ20JQ1wlILQshkkafhkKampq44ooreOyxx/jZz34W6z4JIQbZmn1rWPHRCg55DkG+WW0z4/PvMdHybaAwUr8CwNnvjIUZoNyx6lN8QZ2fXzgdv6sQJ1slYyFEEujTnx5Lly7lvPPO44wzzui2rc/no6GhIeomhBg61uxbw7K1y8ygoo36QBUft/wGa9pnjMhqDSxS7P0LLByhyZ+ZoZoY9S0BvC5ZcipEsuh1YLFy5Uo2btzI8uXLe9R++fLlZGRkRG4lJSW97qQQYmBousaKj1ZgYHTaxlHwL0ZmOiP3+52xsJoZi/Q2gYXHKUMhQiSLXgUW+/fv54c//CF///vfcTqd3V8A3HXXXdTX10du+/fv71NHhRCxt6lyU7tMRRQFVFs9zrR9kUP9nbwZLq6V0TawcIR2OJWhECESXq/mWGzcuJHKykrmzp0bOaZpGu+++y5/+MMf8Pl8WI5Y4+5wOHA4HEc+lBBiCDjsOdyjdkGlHgCbVcWi9q/OhNWioqrRgUVLTihjESonLoRIXL0KLE4//XS2bt0adey73/0uU6ZM4Y477mgXVAghhra88DLPbqTbsoH+ZyvCbBY1KrCIVN+sPyBFsoRIcL0KLNLS0pg+fXrUMbfbTU5OTrvjQoihb07+HApcBVR6KjudZ5Fhy2Nc2gyg/0tNw+xHBBa+lNDcq0Az+BrAmRGT5xFCDD7ZhEyIYcyiWrjz2Du7bHPxqB+gKmamImYZC6tKSbaL0ybnM3d0Fro1Bd2RaZ6UCZxCJLR+l/Reu3ZtDLohhIiXM0afwcMLH+anH/ycGl9V5HimPY+LSn7AzOyTIsf6uyIkzG5RGZXt4lvHjYocC6YWYffVmRM486fG5HmEEINP9goRQnDG6DPIqs1Ef/VcDtmc/Mr+n3iaxuAsHBvVLmaBRQf7jfhdhdirt0vGQogEJ0MhQgh03YD6co7x+jhVz2B/+QgO1fsjtSbC+lscK8x+RFlvf1CP7KYqgYUQiU0yFkIImvxBHJ4KAKqt+QR1gxy3nYK06KXizn7ubBpmCz3Off/6nLqWAD85dyot4ZUhUstCiIQmGQshBI3e1sCiTMsC4Kji9MjGYwBWixLZQKy/IkWyXKGVId4AHme4SJbUshAikUlgIYSg0RvA2WIGFl+1pAMwrTg9qk2sVoRAm8DCGQosPAGaHbJfiBDJQAILIQRN3iAOj5kp+MqbjqLAlMLowCJWEzehdfJmpJaFN4DXGQ4sZChEiEQmgYUQw5xhGDR6gzhbzD1Dyo1sxua4SXVET8FyO2IXWIS3To8EFp421Te9deBvjtlzCSEGlwQWQgxzLQENTTdwhIZCCkZO4Nix2e3apTtt7Y71Vbv9QrwBNFsqus1tNpB5FkIkLAkshBjmGr1BFM2Pw2sWx1o0fzZnTC1o1+7Ipaf9ZbdYWrdO9wRAUdBSi8yTMhwiRMKS5aZCDHON3iCO0DCIptoJ2LPatXHaLDGdYwHmcMiIzBROm5JPUYYTgIC7CFvtTpnAKUQCk8BCiGGu7YqQJkcBQcPAesTuoukpsf+osFlVCjOcfOvY1rLePlchLoBGCSyESFQyFCLEMNc2Y7GtKY1XP6to1yYjxsMg0LrktK3IBE7JWAiRsCRjIcQw5gtq+IM6zlBxrHKyGZ+X2q7dgAQWoSWnzb4gNc1+clMdeBzhIlkSWAiRqCSwEGIYa/QGzW8aygCoMLIZm+uOaqMokBbDFSFh4YzFQ6/t4EBdC7ecMZFRkcBCJm8KkahkKESIYawpFFjo9WaGwJtS0G6SZqrDikVV2l3bX+H9QrLddgCqm/20OKX6phCJTgILIYaxcMbCHqq6qWaMbNcmvJ9HrIUzFuHAoqbZ37rDafNhCPoG5HmFEANLAgshhrFGXwCANH8lAK68Ue3aZKbYB+S5OwosAvYsDEtoR9VGKZIlRCKSwEKIYUrTDVr8GsGAj2y9DoDswjFRbSwWhdzUAQosrO0DCxSFYKRIlgyHCJGIJLAQYphq8gUxDEjxHkZVDIKKjYycwqg2henOmG2VfiRHKLDIaRtYAAG3LDkVIpFJYCHEMNXkM+dXuHxmDQu/qxBFjZ64OSIrZcCeX1UVbFY1KmOhGwa+FMlYCJHIZLmpEMNUeEVIuIZFZOJkSHqKLaYbj3XEYVXJdNk4dXIe2W47um7gTZFaFkIkMgkshBimmkITN0v37mQG0ByuIREykNmKMIdVxaqqXHHc6MgxT2TJqdSyECIRyVCIEMNUozeIrhscPrALgHpba2BhtSgUpDkGvA8Oa/uNzZql+qYQCU0yFkIMQ96ARlAzqGzykU8NEF3DYkRmyoBN2mzLYTOfo8WvUdXkw2mzkC77hQiR0CSwEGIYChfGOlDbwlGKGVj4Q6sxFAVGZrkGpR/hlSH/9+lBXtt2iDOnFTDiqFBg0VQBWhAs8jElRCKRoRAhhqHwipADdS0UhgKL8M6ieWkOUuzthygGQngoJKvNyhC/IwdDtYKhQ9OhQemHECJ2JLAQYhgKrwgpr2kin1oAfKHAYlT24GQrAJy2DmpZqBY0d2gCp1TfFCLhSGAhxDDU6DVXhHjrDmBRDDTFit+ZQ6rTSqZrYCptdqTD6ptAILz0VVaGCJFwJLAQYpjRdIOWgIY/qGNrNjMCXmcBKOqAle/ujN2ioqqtgUV9S4CAprfW1JAJnEIkHAkshBhmPH6zlLfNonDrcalA68TNrEHMVgAoioLdYiHVYcVmMbdmr/ME2myfLhkLIRKNBBZCDDPNPg0wf6nn6VWAOb9CVQc/sABznoWiKJGsRXWzj+ZIYCEZCyESjazjEmKYCa8IAXC0mOW8va4iMl12VFUZ9P6YK0MCnDY5H7+mk+N24AlIYCFEopLAQohhpjkUWPzfpwf5zsE9jMbMWGTHIVsBrUWyTp9aEDnm88nkTSESlQyFCDHMhAOL93ZWYYQyAl5XAdmDPHEzLFwkq61wTQ0aK0DXB7lHQoj+kMBCiGFE0w08fo2AplPd5KdIqTaPpxaT5ohPAjNcJCug6eyv9bCjohF/Sh4GCmh+8FTHpV9CiL7pVWDxyCOPMHPmTNLT00lPT2f+/Pm88sorA9U3IUSMefxmtuJwow8VjXzqAEjJHYWiDP78CmjNWByobeH+f23j0X/vxlBtaK48s4EMhwiRUHoVWIwcOZIVK1bw8ccf8/HHH3PaaadxwQUX8Pnnnw9U/4QQMRReEXKowUsu9VgVHV2x4soqjFufwnMs8kK7qda3BPAFNPxSy0KIhNSrwGLx4sWce+65TJo0iUmTJvHzn/+c1NRU1q9fP1D9E0LEUHhFyKEGH0WhPUJ8Kfm4UwZ+i/TOhIdC3A4rrtAeJVVN/tZ5FpKxECKh9HlQVdM0nn32WZqbm5k/f36n7Xw+Hz6fL3K/oaGhr08phOin5khg4Y1sPuZLKcRtj98CMYuqYLUoBDWDvDQH+6o9VDZ68TgLyAbJWAiRYHo9eXPr1q2kpqbicDi47rrrWL16NdOmTeu0/fLly8nIyIjcSkpK+tVhIUTfhQOLykYfxaGJmz53UWQzsHhx2sxMRV6qmTk53ORrU31TAgshEkmvP00mT57Mli1bWL9+Pddffz1XXnkl27Zt67T9XXfdRX19feS2f//+fnVYCNE34RUhALecOZFvTDQna+qpRXGbuBkWHgIJz7M43Ohrs1+IDIUIkUh6nf+02+1MmDABgHnz5rFhwwZ++9vf8uc//7nD9g6HA4cjfuO3QghTeEUIgFVVydbMct6kF8epR61SbO0DC+/YcC0L2TpdiETS74FVwzCi5lAIIYam8IqQMKfH/IWtZo6MR3eipIQyFhPzU/n6nBGUZLnwuZzmyfoyMAyIc1ZFCNEzvQosfvzjH3POOedQUlJCY2MjK1euZO3atbz66qsD1T8hRIyEMxbbyxtYt6uKYxvMYUlbzuh4dgtozVgUZaRQlJECgFdLwUBBCXqhuQpS8+LZRSFED/UqsDh06BBLliyhvLycjIwMZs6cyauvvsqZZ545UP0TQsRIeH7FzsNNbNxdSarTnLzpzB0Tx16ZwhmLtgyLnaArH5vnENSXSmAhRILoVWDx+OOPD1Q/hBADLLIipMFHkVKNioFmcZKSkR/nnoHTakFRzBGPigYv5XUtjMp24XWPMAOLuv0wYm68uymE6AHZK0SIYcITaK26OVI5DIA/dQSKGv+PAVVVIktOV35Uyn+v3cXn5Q14UorMBnWlceydEKI34v+JIoQYcN6AhqYZgJkRGKGYK0KCafGfuBnmPGJlSFWjD49rhHmyXpapC5EoJLAQYhgIz69o9gXx+DVGhgILI33oBBZH1rKobPThDQcWdRJYCJEoJLAQYhgIz6843GQuDR9jNSduKtnxXxESFl4Zkp9mLjM91ODF6w7V2JCMhRAJQwILIYaBcMaizhNAAUZbzMDCkjUqjr2KFs5YFGaEAotGHy2uUGAhGQshEoYEFkIMA82hGhZHl2TyxyvmMNFeC4BtCGUsnKHAIjfVjqqAP6hToYSWmPrqoaUufp0TQvSYBBZCDAMt/taqmzbFIMV7yPx+CAUW4aEQq6pGNiM70KwScGSbDWQ4RIiEEL+9koUQg0LTjajAwuGtRDWC6IoVNa0wjj2LZrOoke3TLzh6BIoCI7NS8LqLsflqzOGQwhnx7qYQohsSWAiR5NpuPvand3YxQ9vGSUDAXYRDbV/xMp5cdisNLQGOHZsdOdaSUkwan0nGQogEIUMhQiS5cLYiqOtsKq2l5uAu8/4QWmoaFh4OaaslvDJEimQJkRAkYyFEkmsOBRY1zX50A0aFlprq6SXx7FaH3A4zsPAFNL441Eh9S4ASKZIlREKRwEKIJBceCjncaNawmGCrAR2UzKGz1DQs1WF+JHkCGr9/ayeqAhculIyFEIlEhkKESHLhGhZVTX4ASkI1LNQhVMMizBUKLDJTbNitKroB5YSWnEotCyESggQWQiS5cGARzlgUGeYGZNbsIRhY2CyoKiiKQkGotPfuYGgip6cK/J449k4I0RMSWAiRxAKaTiCoA+HAQmOPrZaX3S4+MRrQdK3rBxhkqqqQYjOzFuEKnKXNNoK2VLOBzLMQYsiTwEKIJOZpU7+ilo9Jm7CC7xdmc0d+Lld/8BMWPb+INfvWxLGH7YXnWRSktynt7Q5N4KzdF69uCSF6SAILIZJYeOLmpzX/5rD7MbA1Rp2v9FSybO2yIRVchFeGhAOLigYvLe7QsE3t3jj1SgjRUxJYCJHEPH4N3dBYVfrfHZ43MAB48KMHh8ywSDhjURjOWDT4aHGHlsbW7olXt4QQPSTLTYVIYi1+jd2NW6kPVHXaxsCgwlPBpspNHFN4zCD2rmPhlSHFGU6uOXEsRRlOPLWSsRAiUUhgIUQSa/YFaQjU9KjtYc/hAe5Nz4RXhjhsFo4flwNASyCcsdgbv44JIXpEhkKESGKegEa6Lbv7hkCeK2+Ae9MzbVeGhLUOhewFwxj8TgkhekwCCyGSlC+ooWkG49JmYDOyOv19rKBQ6CpkTv6cwe1gF8LzLMrrW1iz/RDvV7kwFBUCHmiqjHPvhBBdkcBCiCQV3nxMVSykNX8DAOWI6EJBAeCOY+/AMoR2Og2vDNlR0cjKDfv59+56vClF5kmZwCnEkCaBhRBJqrlNDYvm2qlkHTibfC165UeBq4CHFz7MGaPPGOzudSmcsSjKSAGgvN5LS6rMsxAiEcjkTSGSVEuohkVQ06lu9nO6ksaf9x9kXf5Ums6+hzxXHnPy5wypTEVYqjMcWJhLTquafDSNLCGb9RJYCDHESWAhRJIKV92sbvZjGDDOWokFmOUeR8a4c+PbuW6k2CxYLAppTituu4Vmv0alpZBRADUyFCLEUCZDIUIkqXBg0ewPkuWyMclu7mqqZY6JY696RlEU0hxWFEWhONMcDikl3zwpGQshhjQJLIRIQoZhRMp5j8tN5b++MYtT8prNk1lj4texXjhyOGRnILQcVgILIYY0CSyESEK+oI6uRx9zNZcCoGSPGfwO9UGa0wa07nL6uSdUj6OpQrZPF2IIkzkWQiShtruaAmDopDSXAWDNHR+HHvVeeGXIvNHZjM9LpSjDSeCldGyBBqjbB/lT49xDIURHJLAQIgmFh0EAfvvmV6T5D3GGHkBXrNizR8axZz2X6rCiKJDttpPttgPQklqCrfZzczhEAgshhiQZChEiCYUzFoZhsLOyCa3KXEnhdRdjt9nj2bUes6gKKfbopbCR0t41u+PQIyFET0hgIUQSiqwI8Wm0BDTGqQcB8KaPRVGUeHatV9JD8yw27qvl6Y9KKVOLzRPVO+PYKyFEVySwECIJeXzmUEhlkxeAqTZzf41A5ri49akvwvMsNu+v5a0vKtkRKDBPSGAhxJAlgYUQScYwDFoCZsaiqtEPwERrBQBa1oS49asvWpecmrUstgVCtSyqJLAQYqjqVWCxfPlyjjnmGNLS0sjPz+fCCy9kx44dA9U3IUQftAS0yE6mh5t8AIw2ygEwchJjRUhYWiiwKA4tOd3cnGueaDwIvqZ4dUsI0YVeBRbvvPMOS5cuZf369bzxxhsEg0HOOussmpubB6p/QohearvUtLLBi5UgBZoZWCg5E+PVrT5xWC3YrWokY/FVow2/Pcs8WbMrjj0TQnSmV8tNX3311aj7TzzxBPn5+WzcuJGTTz45ph0TQvSNx9caWDisFqY5a7GgoVlSsGUlxlLTtlKdVvLSHFhUBX9Qp949hjx/rTnPomhWvLsnhDhCv+pY1NfXA5Cdnd1pG5/Ph8/ni9xvaGjoz1MKIbrhCbTWsPjWcaPILdkJ74EnbQxO+9DbybQ76U4rNU1+CtIdHKzzUmkbSR6bZZ6FEENUnydvGobBsmXLOPHEE5k+fXqn7ZYvX05GRkbkVlJS0tenFEL0wJFVN12NZg2L5rSxOKyJF1ikOswlp+HhkP3qCPOErAwRYkjqc2Bxww038Omnn/KPf/yjy3Z33XUX9fX1kdv+/fv7+pRCiB5oOxQCrYGFN30sdmviLQQLT+C8dO5Ifn3pLIrGhf6Qqf4qjr0SQnSmT0MhN954Iy+++CLvvvsuI0d2PWbrcDhwOBx96pwQonc03cAbWmq6ubSWf2zYz9PWLwDwZybWipAwl92CRVXISTU/RzxpoVoc1bvAMCCBCn4JMRz06s8XwzC44YYbWLVqFW+99RZjx44dqH4JIfqg7R4hFQ1eapr9FATMLKGenZiBhaIokXoWAJ7UURiKCr4GaKqMY8+EEB3pVcZi6dKlPP300/zzn/8kLS2Nigqz6E5GRgYpKSkD0kEhRM+1nV9xuNFHKh6y9FrzQE5iFcdqK9Vhpa7Zz/ObDnCgroXjUkaQ6tlvzrNIK4h394QQbfQqY/HII49QX1/PwoULKSoqityeeeaZgeqfEKIXmn2tGYvKRh9jFTP49zlzsbsz49Sr/ktzWlEUhY37atl6oJ5qR2gSuMyzEGLI6VXGwgiX8xNCDElRxbEafZyomIWxPGljcdoSb0VIWFp4ZUimk8NNPsosIxgNsjJEiCEo8aaICyE6Fc5YBDSd2mY/40O7mnpSxyR0YJEaKe1tDrnu0gvNE1WSsRBiqJHAQogk4gmtCDnc6MMAploOANCUMRGnLXH/u1tUBZfDwogsM7D4xFdknqjcHsdeCSE6krifNEKIKN6AhqaZw5VB3WB8nptpocCiOWNiQhbHaivNYWNEphlYrG/MMw/W7ZPNyIQYYiSwECJJtJ1fMSrbxd1njmVEaFdTX/YULGpi13tIdVopynCiKHDA76bFEdrptEp2WBZiKJHAQogk0XZFCIC7cTeKoeO3Z2JJgiWZaU4rNotKQZqTFJuFaleoLocMhwgxpPRrEzIhxNDRNmOh6Qbu+i8BaM6YlJCbjx0p1WF+XN11zhRcdgv6lqlQ+6EEFkIMMZKxECJJNLepunn3C1vZuOF9AJrSJyT0ipAwp82Czaridpg1LZoyQgW/KrfFt2NCiCgSWAiRJMKbj/mCGlVNfkYG9wHQlDEJZ4JP3AxLa1PauyljkvmNZCyEGFJkKESIJNB287FDDT4ApqhlgLkiJCeBl5q2leawUlrl4ckP9tLcGOB1gMZy8NSAKzve3RNCIBkLIZJC1OZj9V5S8TBCOQxAU/pEHEkwFAKQ5rThtKtsPVDPl3UKTSnF5onDX8S3Y0KICAkshEgCzb7WiZvl9S1MVMz6Fd6UfIKOzIQujtVWqtOKVVUpzHACcMgR2mFZhkOEGDKS49NGiGGuyRe9Xfqk8DBI+iRUlYQvjhXmsllQVSKFsvZaRpsnJLAQYsiQwEKIJNC2hkVFvZfJyn4AmjImJM3ETQBVVXDbrZHAYlswNBQigYUQQ4YEFkIkgbaBxbi8VI52mJuPNSfR/IqwNKeNkaE9Qza2hDYjq/wcZPdlIYYECSyESHCabkQVx1py3ChmWMylpo1Z05JmfkVYmtPKyCwXYO4ZoitWaKmF+v1x7pkQAiSwECLhtS2MBeBsLsPmr0dXbTSlTyQl6TIWVrJcNrJcNgqzM6hPCxXKKv8kvh0TQgBSx0KIhNd2GMTjD5JT8xlgFpAyLHZSkqCcd1upocqbD359Jqqi4NkwnayGL+DgFpi6ON7dE2LYk4yFEAmuydsaWDy/6QAfvPcWAA1ZRwHgsiXX3w9Wi4rLbkFVzN1aG0OvUzIWQgwNElgIkeCajlgRcpSyB4DGTPMXrtOefP/N05y2yPf1GeHAYotM4BRiCEiuP2WEGIbaFseqqG9huhoKLLKPwqIqSVPDoq00p5Xt5X5+++ZX+Lx+PlIsqM2HoeEgZIyId/eEGNaS708ZIYaRoKZH9ghp8gVxeQ+RozSiK1aaMiYn3fyKsDSnlXSnlYoGL1VelYbUceYJGQ4RIu4ksBAigbXNVpTVepih7jaPZ0xAtziSbkVIWJrThtWiUhwq7V3mCO10Wr4lfp0SQgASWAiR0JraLDUtq23hKHUvAA1Z0wGSNmNht6o4bGqknsUX6njzhGQshIg7CSyESGBtV4SU1bYwIzJxcxpA0mYswMxalGSbFTg/DowyDx7cEr8OCSEACSyESGiN3kDk+0n5bmbbzIqbDdnJnbEAs55FSShj8V5DIYaiQlMFNFbEuWdCDG8SWAiRoAzDoLFNxuK0Ij9Zem1k4iaAK4kDi/QUKyXZZmBR1qzSkBoaDin7OI69EkJIYCFEgvL4NTS9tW5DRtUmABqzpqJbU1AUkmpn0yOlO22kOqxMK0rn2DHZVGXOMk/sXx/fjgkxzEkdCyESVEObYZCaZj+jyj8CoD5nLgAOqwVVVeLSt8HgtFmwW1WWnWmuCPHunQf7n4PSD+PcMyGGN8lYCJGg2g6DvPPlYYJ7zb/U63LnAMk9vyIsPaW1AmddKKCifAsEvPHpkBBCAgshElVDS2vGoqq6islKKdAmsEjiFSFh6U4z6aobBnu0fHyOHND8cHBznHsmxPAlgYUQCcgwDBrb7BGSXfcpFsWg3jkCf0o+MHwyFkFN5+ZntvCTFz+nKuto88R+GQ4RIl4ksBAiAXn8GppmhL4PMtn/OQANoWwFJPeKkLA0pxWrRSXLZQfgS3toQzIJLISIGwkshEhAjUcUxpqrfAlAU/68yPHhEFg4rBacNgtjc90AfKyby2zZ/6HsdCpEnEhgIUQCalsYa9/hemarO4HW+RWKAm778Fj0lZ5iZUxOqFBWUzGaxQGeaqjeGeeeCTE8SWAhRAJqu9RUq/icVMVLi+qmOX0CYE7cTOalpm2lO22MCWUsvqrx05A1wzxR+kEceyXE8NXrwOLdd99l8eLFFBcXoygKL7zwwgB0SwjRGV03qG+zIuTCDPMv86qs2aCawx9ux/DIVoA5gXNkZgpWVcHj1yjLCM0z2fNufDsmxDDV68CiubmZWbNm8Yc//GEg+iOE6EZ9SwBdb70/1bMRAE/JKZFjwymwCE/gHB0aDvlYDVXg3L2WqB+UEGJQ9PrT55xzzuGcc84ZiL4IIXqg1uOPfK9qPjKrNgBQU3BC5HjqMAosbBYVt8PKiRNymVqYjnXUJIJ7XFibD0Pl51A4I95dFGJYGfBPH5/Ph8/ni9xvaGgY6KcUIqnVelqHQep2vINF89HizKc5fXzkuNuR/CtC2sp02ThpYl7kfm3eseSVr4Vdb0tgIcQgG/DJm8uXLycjIyNyKykpGeinFCJp6boRVXEz+OXbAHzhmmsuBWF4rQgJy3TZou5Hsje73opDb4QY3gY8sLjrrruor6+P3Pbv3z/QTylE0mrwBiI7muq6wVE+c35FY/FJkTbDaUVIWEZoz5AmX5At++vY6phtnij9QPYNEWKQDXhg4XA4SE9Pj7oJIfqm7TBI9eEDHKXsBUAfMzwnboa57FZsVpWXtpbzh7d38uKBNLwp+RD0yrJTIQaZ1LEQIoG0nbhp3Wsup9yljiXoap1fMBwDC4DMFBuTC9IA+LKymZqCE80Tu9+OY6+EGH56HVg0NTWxZcsWtmzZAsCePXvYsmULpaWlse6bEKINXTeob5OxKKo0A4vdGcdGtRtOK0LaynTZmJifigJUNHjZn328eeLL1+PaLyGGm14HFh9//DGzZ89m9mxzDHPZsmXMnj2be+65J+adE0K0qvH4I/Mr0HzMajFT/HWjzopqN9xWhIRlpNhwO6yMyEoB4H1mo6s2OLwdqr6Kc++EGD56HVgsXLgQwzDa3f76178OQPeEEGGVDa3LtpU9/yaNFiqNTNzj5rceH4YrQsLSnTZUFaYUmsMhGysNavJDWYvt/4pjz4QYXmSOhRAJwDAMDje1BhaTa9cCcKDgNOy21kAizWkbditCwlRVId1pY8aIDAA+Lavj0IgzzZMSWAgxaCSwECIB1HoCBIKh8tS6Rt7BNwEwpiyOahdedjlcZbntTC5Iw2lTafAG+cR1AgYKHNwE9WXx7p4Qw4IEFkIkgMrG1loMmdWbcPiqCdjSqc2Pnrg53AOLbJcdq0XlP04ax/KLZpBfVEJd7lzz5BcvxbdzQgwTElgIMcQZhhE1v8K582UAtqWfgKFGBxLDPbDISLFhURVmjswkL80BQOVIc3Krse2f8eyaEMOGBBZCDHF1ngD+0DCIogcpKX8VgJcC86La2awqKfbhuSIkTFUVMo4o7304PM9i3/tQfyAOvRJieJHAQoghrrTGE/k++9B7ZASrqTbS8JScGtVuuGcrwnLcdgA+KavjD2/t5M0KB7V5x6JgwCf/iHPvhEh+ElgIMYR5/EEON7YOg+TvfA6Af2onMLUkN6qtBBamrFBgcaC2hS1ldXy0u4aDYy8GQNv0FBhGPLsnRNKTwEKIIWx/TUvke5uvhsIKc7fOd91nUZDujGorgYUpzWHFalGYNyYLgG0VDezIPo2g1Y2lbo/sHSLEAJPAQoghKqDpHKxrDSwK9/0fFiPIVn0MGWPmtGuf7hyehbGOpCgK2W47+WlOJuanYhjw3r4WDpWcA0Bg4//GuYdCJDcJLIQYospqW1pLeBsGhXueB+BZ7RTmjM6KapvqtGK1yH/nsNxUc0XICRPM4aJ1O6s4MMYcDlG3vQC+xnh1TYikJ59EQgxB3oDG3urmyP2Mqo1k1G/Hj4317tMozogeBglPWBSmvDQHigLzRmfhsKocavSxUZ9Ec9pYLEEPTR/+Ld5dFCJpSWAhxBD01aEmNK11kuHoHY8DUDnuYm4+/zgUJbpsd/gvdGGyWVQyXXacNgtzQ9mddbtqKJ14FQDWjx5BDwa6eAQhRF9JYCHEEFPd5ONQQ2ulTVfDbvIOmpM2Syd9F7s1+r+t1aLIxM0O5IcKZJ04IZfxeW4mF6ZRPuZC/I4snE37qdrwXJx7KERyksBCiCEkoOl8URE9/j/qyydQMDhYcCqe9HHtrslxO4btxmNdCVfenFSQxl3nTGX+uBx0awpl468AwLHhv6lv9sezi0IkJQkshBgiDMNg64F6Wvxa5JjdW0XR3tUA3FJ2Mp+U1bW7LjdN5ld0xGmzkN5BJmf/hCvQLA4yarZSuvl1Apoeh94JkbwksBBiiNhZ2URNU/Rf0GO3/RGL7mezPoGNxmTG56W2uy7HLfMrOhPOWgD4AhqvfV7Ba3s1ykMrREq2/IrPD9RjSNEsIWJGAgshhoB91c3sq/ZEHUtp3MeIXSsBeCj4TY4Zk0OqI7pWRYbL1m7OhWhV1Gb1zCdl9Ty7sYx/bjnA9gn/gWZxklm1CWXHy2wrb5DgQogYkU8kIeJs9+EmvjrU1O74hK0PoxpB3tGP5gP9KE6ZlNeuTZ6sBumS02YhJ9UcKpo3OovCdCfNfo2nvwhSOukqACZ8+ksqaprYcUhqWwgRCxJYCBEnum7wRUUDuw83tzuXXv0JBWWvoKOwPHAZIzJTGJ/njmqjKFCU6Wx3rYg2IisFMHc+veK4UQCs3XGYt3Iuw2/PxN24m+I9z1FW08LWsvrWomRCiD6RwEKIOPAGNDaV1lLWZi+QMEUPMHXjPQD8Uz+ZL4xRnDejqMPaFQ7r8N4mvSdy3Q4cNvOjbmpROieMz8EA/mdDDTun/gCACVt/hb3lMIcavHy8twZvQOviEYUQXZHAQohBVlHv5cM9NdR5Oi7QNPqL/yGtbjst1gwe0i9nRGZKZEOttiRb0TOqqlCUkRK5f8m8EtKcVsrrvfy69mQaMqdh89czefMDADR6g3ywu5r9NR6ZdyFEH0hgIcQgafFrfLK/js8O1BMIdrzE0V3/FeO2/QGAXXP/k9suOolrThyLekS2wm5VZX5FL4zITCH8I0x1WLly/hgA3ttTz/rpD6ArVgrKXiN//ysAaJrBjopGPt5XS63UuhhUmq6xoWIDL+9+mQ0VG9B0yR4lGtkOUYgBFtR09lZ7KK1pRu+iZIIa9DL9wx+h6gEOF59GxajFpCtKh7UYijOd7YZGROdS7BaKMlIiu8UeXZLJkuNHMzE/FTUzhb1Tv8+4bf/NlI33Up89C5+7GIB6T4CN+2rJTrUzKttFjtsuP/cBtGbfGlZ8tIJDnkORYwWuAu489k7OGH1GHHsmekMyFkIMkKCms6eqmfd2VrG3quugAsNg6sb/NIdAbJmsLloGnfwCUxQYkekamE4nsXF5btQ2n3inTMqjONMcItkz9Xpq06di99cx8/0bUDVf1LU1TX62lNbxwa5q9lQ1RxUxE7GxZt8alq1dFhVUAFR6Klm2dhlr9q2JU89Eb0lgIUSM+YIaOyubeG9nFbsqmwhq3Y/Tj9z5FEX7/omByq3GLfxiXQPvfnW4w7YF6U5S7DJps7ecNgsjszoOyL6s9nFxzfU0W9LJqP2MyZvuhw7mV3j8Grsqm1i3s4qP9tSw+3AT9S0BmYvRT5quseKjFRi0/zmGjz340YMyLJIgZChEJCxN19hUuYnDnsPkufKYkz8Hixq/X7h1Hj9ltS1UNnq7zk4cIa/sdSZt+QUAz+Vcy8sHJpKRYmPuqPYTNgFG50i2oq/G5Lg5UNcStXMswNayevYEc/m+vpQn7Q8yYs9zeF3F7Dnqhk4fq6ElQENLgN2Hm7FaFLJcdjJdNjJSbKQ7bbJ/Sy9sqtzULlPRloFBhaeCTZWbOKbwmEHsmegLCSxEQhoqY7G+oEZFvZcDdS14fL3/ayqn/B1mrL8F1dD4JPc8bis7GYBvHzcKt6P9f8/cNAdpTtnJtK/sVpVJBWlsP9gQdfyi2SPISLHx3CaFnwa+zX22vzH+89/hV50cmHpNt48b1AwON/o43GgOoSgKuB1W0p020pxW0pxW3A4rNoskiTty2NNxdq6v7UR8SWAhEk54LPbItGl4LPbhhQ8PaHDhD+ocDm1tXtvs7yhj3iN5B9Ywff0tqHqAXflncknZtwCFRUcVMLuTbMUYyVb024jMFKqbfFQ2tM6jUBSF06cWMLUoncfXpeCu83Kb7f8xdetDHKprJnj8TZ3OeemIYUCTN0iTNxh13Gmz4HZYSHWYgYbbbsXlsAz7gCPP1b6qbH/aifhSjEEeHGxoaCAjI4P6+nrS09MH86lFEtB0jUXPL+o0baqgUOAq4NWvvxrTYZFmX5CqJh9VTT7qPIE+BxMAGAYlXz3JpC3LUTAozV3IBVX/Qa0XZo3MYOnCCR2m0bNT7czpJOAQvRPQdNbvrsYXaD9mpekGH+yqZsTmX3ItqwAoG/dNdsy5B6+mYrOoMR/msFtVXHYLLrs19NVCSui+ZRgMqYT/X1d6KjucZzFQ/69F7/T097dkLIaQoTZnYCgarLFYjz9InSdArcdPbXMgZpUYLYEmJm96gOJ9LwBQNv5y/pp+PbVlZYzKdnHtSeM6/aU1Ib/9zqaib2wWlVklmWzaV9tucq1FVThxYi7+sb/gpY9GcW7Z7xi5+xncjbv5TdqPeHYnTC1MZ1pxOlOL0shLdfR7Cao/qOMP6h0WTXPYVFJsZqCRYjODjRSbBaddTZrKqxbVwp3H3smytctQUKKCCwXzZ3vHsXfI52GCkMBiiBgqcwaGuliPxQY0HY9fw+M309aNviANLYEereTorczDG5j20R24msswFJWdM37EvsnfY4GioFpszByZgdPW8QdnQbqTdJlbEVPpThuzS7LYtL+23WROMLMILPgBnxycwvT1t5J1eAO3Hb6a+uCVvFB6AhtLawHIcdsZm+tmdI6Ls6YVxjzD4Avo+AIdBx2qag6vpNgsUV+dNhWnzYLDqiZM3Y0zRp/Bwwsf7vBz8I5j75DPwQSSVEMh28sbCGg6qqKgKgqKYv71oSrmGKp5HPOr2uZ75YjvVfN7i2o+hqooWELXDITO5gyEI/WBnjMw1BmGgWGAAWwo/4hr13Q/me63J/+ZmXlz0XSDoG4Q1HQCmo4/aOALaviCOt6A1q8AQjc0djdupSFQQ7otm3FpM1CV9oGBw1PBhE9/SVHpiwA0u0bwS9cyph63iGy3vdvnURSYPz4Hl13+DhgI9Z4Anx6o63BYJCylqZTp628lo+YTAHamzOKXlqt5oyY/smlZutPKry6ZFflF/uzG/fgCOoUZTgrTnRSkO8lx2wd1tYiigMMaHWiEvzqsFhw2dcgFH5K5HbqG5VBIbbMfzwAXrgkHHe0CjzYBjKVdYNPmXJuARlHAQOfn65d3sX5bYfmHKzg2/ySsFgsKSmQOmaIQfZ/w8Y4/JMIxpAGhX9RGZK5A+L5umO26+qoZBrpuXqsbBpphRM7phoGuh762ORY5r7c+lkH4XOhrqHPhfnUU8upGCRm2XOoDVZ2+R5n2PIKeMWwprevm3ey7T2v+zarS/47qR4Ytl4tHLWVm9kkAOJoPMmbH/1C851ksmg8DhfWZ53FT9dc5XONgmraXZWdO6va5Rma5JKgYQBkuG8eOzebzgw3UNHVcvrsldRQfn/Y0o7/4H8Zuf4QJLZ/wCDdTPuYs3slfwsf+Egwj+v/eR3tqqD0iy2BVFXJTHYzNdfO9E8dGju+tbibFZiHbbY/pRE7DMDe8M4fyOt6bRlHM7IzDagYc5vcqDpsFu0XFYVOxW8zbYARFFtUiS0oTnHxa9ZKug27+ao7J4+1s2EKVt7KLFgaVLYd4+pO1TEg/OibPmchUxcLFo5byxK77O21zUckPOswcxMqnNf/u8PnrA1U8set+bqz7BheWf0ruwbdRDTPQ3eWczo+93+bDCnPb7lHZLi6ePaLb57JZVcYdsV26iD2H1cLskkzK673sOtzUYfbCUG3snXY95aMvYOKnD1G4/2WKD77G5Qdf4+zcuRwY900qg4vQrSkYhsGFs0dQUe+losHLoQYvlQ0+grpBRYOXNGf0R+8f395FjccMajJSbGY9DKdZE2NEVgpnTC2ItK3z+GO6dNUwWodbumOzqtHBhrXNV2ub+4MUhIihSQKLOGsI1MS03XAwM/skvsu97TIGmfY8Lir5QSRjMBB0Q2NV6X933sAwePbQSr534CAqsM15ND9rOI/3vdMAhWy3nYuOHsFx47LbbSzWkYn5qcN+KeJgURSF4swUCtKdlNV62F/T0uGkXZ+7mM/m/4Y9037AmO1/pnD/S2RVbSSraiPaxnuoLjyZw8WncXrBMXjHjYwsU9V1g+pmP9XNvqj3XjcMnHYVu0/Fr+nUtwSob2nNLkzMT40KLH7+8nZqPQFcdgsZKbaoW1GGk5Mmti7JrPP4SbFbYjbJMxDUCQR1mn3dDwVaLEok6LBZVGwWBUfkexVr6LzN0np+KA3JiL7rU2Dxxz/+kf/6r/+ivLyco446it/85jecdNLAfZgns3RbdkzbDRczs09ietaCHs1xiKXd9Zu7HIZBUaiwWnll/AXkTPg+z+138/6mA0zMT+X0KfnMHpXV48l9mS7zF4UYXBZVYXSOm1HZLg6H6l0cbvRF5lKENWdM4vPjf8XOmbdRvHcVRXuew9VcRv6B18k/8DoA3pRCavOOoS53Hk2ZU7CnjycvLXpsWlUUHvjadAzDoMkXpKbZT11LgHpPgHpvgIw2m9AZhhEZ7jUnHWuU13sj5ycVpEYFFj99aTv1LQEcVpU0Z9uCXTZGZKZw5rTWgKW8voUUm1ljw9pNMNuToUBNM2jRtF7tq2K1KGbQoSrYrCo2VQ0dU7CooeMWFYsaPqZgDbUZyHlwond6PXnzmWeeYcmSJfzxj3/khBNO4M9//jP/8z//w7Zt2xg1alS31w/k5M33d1YN+ByLWNMNjQc+uaLbOQP/OfOpAf+lOdwpehCbvw6brwa7rwZLSzVG/X52N3+OP1jJCG8N9YEafpzXfS2JJeN+zJyc02j0BvAFdXJ7ucW5RVU4dmx2h9U3xeDTdIM6j5+aZj+1ngCN3g5qmRgGaXXbyC97nazK9aTXbEU1gu0ey5uST3P6BFpSR+NNKcTnKjS/phQQsGcStKdjqJ2/7+HgIpzZaHvLcds5PZTdMAyDG/6xGV+w4yGOSQWp3L5oSuT+rc9+EsmUuOyWSCCS6rQyKsvF4lnmjq+dDQWGfXf8vQOaNeyKqhIJQCxtb5H5beFjbefGmQGJRWk70Z/QHLroOXFRX2m9P1wyLT39/d3rwOK4445jzpw5PPLII5FjU6dO5cILL2T58uUx61iv1ZWycc9hvG3HCTt8aR0VX+mgXQ+v7fDx2kxA1EMTHcMTGFPaTMJr8gbwBTW2ej7h6bq/dvDYpuuLrqEwOJkGbzAyKdIwDAw9NJHSMDi6JBNL6N/2zsomDjV6oyZYtp1MuXBSbiQ1uu1gPfuqW4DoDx8DUAyDUybnRSYOflHeyO7DjR28cvO7kyfmkR4aO/7yUCNfHmptC62TSwEWjM8my+1AMQx2H25ie0Vjm3ZGVNtjxmaTm2pHMXTKqhr4sqIW1dCxoGExNNQ2X48qdJOToqIYGtWNHvYfrsNh+LDrXhyGebPpLdh0H0UpOm7VjzXQiNpSgyPYgNrmVa1xpbAiJ4tD1tb3LEvTqLV0H+AtnfzLfs2JmVyYRkm2VNkcqjTdoNEboNEbpNEbpNkfpNkXjFplpAY9ZFR/QtbhDWRUb8bdsBNnS+c1WNoKWt0E7BkE7ekEbBkEbanoFie6xYlmcaBbHKHvnegWu3lOdWCoKoZiab2h4tMVPEHwBAya/AbNAWgKgsthZ0ZJNuFPwN+9tZMmXxDdaP1ENP8nKozKSeHK+WPRDZ07991HbaAu+j80kQtwGun8esoKVEUFFDbtr0VFJcURLv5lw2VXcdiskZVvycAMMMwgQwFQzB9Rp5PsiT5w5OT7I9sf+Vyd9AKAqUXpWLJGgyW2f5gMSGDh9/txuVw8++yzXHTRRZHjP/zhD9myZQvvvPNOu2t8Ph8+X2vp3IaGBkpKSmIfWPxyMjRVxO7xBllHv8QKg0HuqK7lDE9LHHs2vOiGQh1uXnJl8FBBKIDo5WdffzNMOan2Tkt6i6HNFzRT/y2B1q/hpc2+oA4tDbgbd+Nu2ElKcxlOTwWOFvPmbDmENdA0aH3VgE1OB4ctFvI0jTleH939i93gdHB1UUE3reAv5Yc4xuvrtt1Q1Jefy5B065eQ1v171RsDsty0qqoKTdMoKIjubEFBARUVHf9SX758Offf33naLGbsbppIaZdoCN9VFQWnTQ0dU/AGtKi2bS9TFIUUmyUSFrb4NfTIUs3o3zIK4GqTrm4JaGi60a5duHXb2eAtAY3w3LDZHnja08ynTgvVFpUczWCBoWBR3PicbrwBnWCbMV6lTV8UxUxdKigYilnFL/yXk7mkVYlcA2ZBnXBUHNBaH7ejPrdre2Tdh9A5A3BaLZExzoCmE+igRkT4OZw2NTKBLaAb+IOdx7dOmwWLqmAoFny6iicIumJBx4KmWCLf64qFNJcTu92OoVhpDkBVi45fceJXQzfFSdCSgm5NoSAnm7T0dDSrm2rS2etxojszUS0W/lr2HxDsYi5FF/qzKiXFbuGo4ow+XSviz1yyaSGzk/Oanoc/OBZfcCH+0P+RhqBOUNPxazrBQACjpQ6jpQ68dajeelRfHdZAE6rmRdV8WEJfo77XzfuKoaEYeuhr6KZrcMTxtbYgv3brVLb5Z5qvGdzaqHGaN5y9NKK+KgYcdPZsInG5Iw2/noKCgS+gmUvnQ+vJjfC6csCiKDhsrY/ZcsTnclttP8MBvAE9tCCfqAwBmJ/hNkvr55kW9dmpRLU125tf33Ta+K9MF4faTHYtCGrcVufh9JaOlyIPRRY1vrVJ+pQnObLDhmF0+iLuuusuli1bFrkfzljE3E2b+M9ntlDn8bcbM1NVhVSHNWpm9Ye7q2n2a5Hz4doTqmp+OBxdkhlpu7vKXH4WVTwr9BxW1ZxJHnl9LQF0w4gqthVuGx7T605O6Ov7sfrZCMD8x972H7wvdANQgXGh73c2bKGxB0GF25JOs9a6S2Z/V6VYLQpHl2SaFR9FUrKoilma295V4JkbdU8PFXnTdIOArqNpoa+6QVAz8OsGmq6HCsG1FoRrvW+2Df/C7myORKVF4Y5Ma5dzJMobtsCOH3X7Og/O/yPvdjEU6A/qoWEXI2r+0VtfVNLoDUQmpnr8wcj3RRlOrjtlfKTtLf9vC43e9nNYAEZmpXDf4qMi9+9evZVDjR1nUPLSHCy/aEbrz+WIwOaQxcKPctKYpCxltPN4zp1RFDn3+cF6fEHdXILbZsmtw2rBblVJjdMcqYWT87qdgDuQevWqc3NzsVgs7bITlZWV7bIYYQ6HA4ejdxPX+uqSuSN7PHnzuHE53TcKGZfb8z0a0lOk7HKi6+nS3gtH/YBMe25MVqWoKswamSmTNUU7qqpgD/1BktKPpHxQ0/EFgyz/7JEu2/2z7BFOGnkKQU0lqJtZyvBf/OPSZvSoQN24tBldPofdqpJtbV919rQp+T14Jaa7zplCs681+DALgel4gxqpRxSUG5ntIsVuoSXcJjw0BdgtavQy8iP/9lPMKXdfBJ5i7/6xUYHF6s0H2Fvt6bB/qQ4rv/nm0ZH7v3vzK/ZUN0dWtoSX3NpUlRS7hR+ePjHSds32Q5TXe7G1XSXT5pqFk/Iif8yXVnto8gWxWsw/dK0WlaCmJ05gYbfbmTt3Lm+88UbUHIs33niDCy64IOadEyIeerq0N9OeG5OiZeFMRaar+/LeQvSV1aKy+fAnVLZ0VZAPanyV4NzL/DbVL/VQtiSoGdxmu4OffHBbp9dfMeEmUp12ApqZORmoTSPy05yQ1rO217fJdITphoE/aJb63924tctgSVFAsdUzfVx11PGRWS4sqhLZRM6v6fhC39uP+MXe5At2mmFxHZHB+qSsju3ljR22tSgKp05uDcBe/PQgW/bXRbW5aHYxzjhW6+31My9btowlS5Ywb9485s+fz6OPPkppaSnXXXfdQPRPiEEXq7/KeiLFbmFWSWbcUqZieOnrJn6qquBQLTiscMGks3E7rO02Cyt0FXa4WVh4WCY8RyscoLT9PhAZujHnnRyZKRkI5pwNc9O2r5p7lqU8qiQ6nXHVgjGdttWP6Pv3Tx6HN6AT0PXWn0Unc9FOGJ/LxPy00Pmu22a77YzITAnti2S2jXdRvV5/mn3zm9+kurqaBx54gPLycqZPn87LL7/M6NGjB6J/w4IllMIKF3uxqG3uW1rXYEevw27dg+TI9data6tb11tHlkDR8VKlyJ4htO7jEV6qCkSWqrbdN0TT2+wP0mYvEE2PXt6qhY4ZRuvyWL3ttUc8TmTvkEHdHq/VYJUNH5mdwoS81LimLMXwkufK675RD9qdMfoMTi05tUebhVktKlYLne7c25VwpkTTDQLB0C/ONkFKsM3cksAR80p6E5gMRKHCI4t15fSils3xvRiq/9ax7etH9eVnHUtJtbtpPApkhTcaC4+DWUOlaa1q6Kul42px4ftWVcrYdkXX229WBu03TTMAQ289Fgls9NZN08I7nWq60fqXgG5E0phHfgh1VF0wFmXD89IcjMlxk+GS+ThicGm6xqLnF1Hpqexw40MFhQJXAa9+/dWk2FE0PPE1qJt/7WvhrIhuRCbBBjUDXzDAje99gxpf5xmdRCpUOFCTN4fl7qZ9Fc4YdBQMhCfXWC1K1PdtAwkxcMJRv2UQCumEl/x5Azq+oMb4/HNYNP50Pj28hUrPYVxqJqPd03v9waIo5qTe3FQHBekO2alUxI1FtXDnsXeybO0yc3l6m+AinNO849g7kiKogNaJr3a6/5z+z/k/ZtlacwXjkT8XA7jjmDs4rjivdSgn8jX6e61NEBPQolfkDBdJlbH4ZH8dQd0I/cJvrSEfySSEhhBsVjUSSFhVqS8vei4cfPgCZsbDH0rJhreOJ1RhL7z5kstuwW23yr8xMaSs2bemx3MkhpOB+rmE5z+YwYYRdb9tQBIeyglnV4OhwEQzQm06mGPRkXhnLJIqsBBCCNEzmq71aI7EcDOUfy7huW1B/civOrpOJFgpyXINyB8zMhQihBCiUxbVwjFtlpQK01D+uShKKBs/NOKcTskEASGEEELEjAQWQgghhIgZCSyEEEIIETMSWAghhBAiZiSwEEIIIUTMSGAhhBBCiJiRwEIIIYQQMSOBhRBCCCFiRgILIYQQQsSMBBZCCCGEiBkJLIQQQggRMxJYCCGEECJmJLAQQgghRMxIYCGEEEKImBn0bdMNwwDMfd2FEEIIkRjCv7fDv8c7M+iBRWNjIwAlJSWD/dRCCCGE6KfGxkYyMjI6Pa8Y3YUeMabrOgcPHiQtLQ1FUWL2uA0NDZSUlLB//37S09Nj9rhDSbK/Rnl9iS/ZX6O8vsSX7K9xIF+fYRg0NjZSXFyMqnY+k2LQMxaqqjJy5MgBe/z09PSk/MfSVrK/Rnl9iS/ZX6O8vsSX7K9xoF5fV5mKMJm8KYQQQoiYkcBCCCGEEDGTNIGFw+Hg3nvvxeFwxLsrAybZX6O8vsSX7K9RXl/iS/bXOBRe36BP3hRCCCFE8kqajIUQQggh4k8CCyGEEELEjAQWQgghhIgZCSyEEEIIETMSWAghhBAiZhImsPj5z3/OggULcLlcZGZmdtimtLSUxYsX43a7yc3N5aabbsLv93f5uD6fjxtvvJHc3Fzcbjdf+9rXKCsrG4BX0Dtr165FUZQObxs2bOj0uquuuqpd++OPP34Qe95zY8aMadfXO++8s8trDMPgvvvuo7i4mJSUFBYuXMjnn38+SD3unb179/K9732PsWPHkpKSwvjx47n33nu7/Tc5lN/DP/7xj4wdOxan08ncuXP597//3WX7d955h7lz5+J0Ohk3bhx/+tOfBqmnvbd8+XKOOeYY0tLSyM/P58ILL2THjh1dXtPZ/9MvvvhikHrdc/fdd1+7fhYWFnZ5TSK9f9DxZ4qiKCxdurTD9kP9/Xv33XdZvHgxxcXFKIrCCy+8EHW+r5+Hzz//PNOmTcPhcDBt2jRWr14d034nTGDh9/u55JJLuP766zs8r2ka5513Hs3Nzbz33nusXLmS559/nltvvbXLx7355ptZvXo1K1eu5L333qOpqYnzzz8fTdMG4mX02IIFCygvL4+6XXPNNYwZM4Z58+Z1ee3ZZ58ddd3LL788SL3uvQceeCCqrz/5yU+6bP/QQw/x8MMP84c//IENGzZQWFjImWeeGdncbij54osv0HWdP//5z3z++ef8+te/5k9/+hM//vGPu712KL6HzzzzDDfffDN33303mzdv5qSTTuKcc86htLS0w/Z79uzh3HPP5aSTTmLz5s38+Mc/5qabbuL5558f5J73zDvvvMPSpUtZv349b7zxBsFgkLPOOovm5uZur92xY0fU+zVx4sRB6HHvHXXUUVH93Lp1a6dtE+39A9iwYUPU63vjjTcAuOSSS7q8bqi+f83NzcyaNYs//OEPHZ7vy+fhBx98wDe/+U2WLFnCJ598wpIlS7j00kv58MMPY9dxI8E88cQTRkZGRrvjL7/8sqGqqnHgwIHIsX/84x+Gw+Ew6uvrO3ysuro6w2azGStXrowcO3DggKGqqvHqq6/GvO/94ff7jfz8fOOBBx7ost2VV15pXHDBBYPTqX4aPXq08etf/7rH7XVdNwoLC40VK1ZEjnm9XiMjI8P405/+NAA9jL2HHnrIGDt2bJdthup7eOyxxxrXXXdd1LEpU6YYd955Z4ftb7/9dmPKlClRx77//e8bxx9//ID1MZYqKysNwHjnnXc6bfP2228bgFFbWzt4Heuje++915g1a1aP2yf6+2cYhvHDH/7QGD9+vKHreofnE+n9A4zVq1dH7vf18/DSSy81zj777KhjixYtMi677LKY9TVhMhbd+eCDD5g+fTrFxcWRY4sWLcLn87Fx48YOr9m4cSOBQICzzjorcqy4uJjp06fz/vvvD3ife+PFF1+kqqqKq666qtu2a9euJT8/n0mTJnHttddSWVk58B3sowcffJCcnByOPvpofv7zn3c5TLBnzx4qKiqi3i+Hw8Epp5wy5N6vztTX15Odnd1tu6H2Hvr9fjZu3Bj1swc466yzOv3Zf/DBB+3aL1q0iI8//phAIDBgfY2V+vp6gB69X7Nnz6aoqIjTTz+dt99+e6C71mdfffUVxcXFjB07lssuu4zdu3d32jbR3z+/389TTz3F1Vdf3e1O2ony/rXV18/Dzt7XWH6GJk1gUVFRQUFBQdSxrKws7HY7FRUVnV5jt9vJysqKOl5QUNDpNfHy+OOPs2jRIkpKSrpsd8455/D3v/+dt956i1/96lds2LCB0047DZ/PN0g97bkf/vCHrFy5krfffpsbbriB3/zmN/zgBz/otH34PTnyfR6K71dHdu3axe9//3uuu+66LtsNxfewqqoKTdN69bPv6P9kQUEBwWCQqqqqAetrLBiGwbJlyzjxxBOZPn16p+2Kiop49NFHef7551m1ahWTJ0/m9NNP59133x3E3vbMcccdx9/+9jdee+01HnvsMSoqKliwYAHV1dUdtk/k9w/ghRdeoK6urss/xhLp/TtSXz8PO3tfY/kZOujbprd13333cf/993fZZsOGDd3OKQjrKCo1DKPbaDUW1/RUX15zWVkZr732Gv/v//2/bh//m9/8ZuT76dOnM2/ePEaPHs1LL73ExRdf3PeO91BvXt8tt9wSOTZz5kyysrL4xje+EclidObI92Yg36+O9OU9PHjwIGeffTaXXHIJ11xzTZfXxvs97Epvf/Ydte/o+FBzww038Omnn/Lee+912W7y5MlMnjw5cn/+/Pns37+fX/7yl5x88skD3c1eOeeccyLfz5gxg/nz5zN+/HiefPJJli1b1uE1ifr+gfnH2DnnnBOVxT5SIr1/nenL5+FAf4bGNbC44YYbuOyyy7psM2bMmB49VmFhYbvJJ7W1tQQCgXbRWdtr/H4/tbW1UVmLyspKFixY0KPn7a2+vOYnnniCnJwcvva1r/X6+YqKihg9ejRfffVVr6/ti/68p+GVDzt37uwwsAjPYK+oqKCoqChyvLKystP3eCD09jUePHiQU089lfnz5/Poo4/2+vkG+z3sSG5uLhaLpd1fNV397AsLCztsb7Vauwwc4+3GG2/kxRdf5N1332XkyJG9vv7444/nqaeeGoCexZbb7WbGjBmd/rtK1PcPYN++faxZs4ZVq1b1+tpEef/6+nnY2fsay8/QuAYWubm55ObmxuSx5s+fz89//nPKy8sjP+TXX38dh8PB3LlzO7xm7ty52Gw23njjDS699FIAysvL+eyzz3jooYdi0q8j9fY1G4bBE088wXe+8x1sNluvn6+6upr9+/dH/cMbSP15Tzdv3gzQaV/Hjh1LYWEhb7zxBrNnzwbMcdR33nmHBx98sG8d7oPevMYDBw5w6qmnMnfuXJ544glUtfejj4P9HnbEbrczd+5c3njjDS666KLI8TfeeIMLLrigw2vmz5/Pv/71r6hjr7/+OvPmzevTv+WBZhgGN954I6tXr2bt2rWMHTu2T4+zefPmuL5XPeXz+di+fTsnnXRSh+cT7f1r64knniA/P5/zzjuv19cmyvvX18/D+fPn88Ybb0RljF9//fXY/jEds2mgA2zfvn3G5s2bjfvvv99ITU01Nm/ebGzevNlobGw0DMMwgsGgMX36dOP00083Nm3aZKxZs8YYOXKkccMNN0Qeo6yszJg8ebLx4YcfRo5dd911xsiRI401a9YYmzZtMk477TRj1qxZRjAYHPTX2JE1a9YYgLFt27YOz0+ePNlYtWqVYRiG0djYaNx6663G+++/b+zZs8d4++23jfnz5xsjRowwGhoaBrPb3Xr//feNhx9+2Ni8ebOxe/du45lnnjGKi4uNr33ta1Ht2r4+wzCMFStWGBkZGcaqVauMrVu3GpdffrlRVFQ05F6fYZgrjCZMmGCcdtppRllZmVFeXh65tZUo7+HKlSsNm81mPP7448a2bduMm2++2XC73cbevXsNwzCMO++801iyZEmk/e7duw2Xy2XccsstxrZt24zHH3/csNlsxnPPPRevl9Cl66+/3sjIyDDWrl0b9V55PJ5ImyNf469//Wtj9erVxpdffml89tlnxp133mkAxvPPPx+Pl9ClW2+91Vi7dq2xe/duY/369cb5559vpKWlJc37F6ZpmjFq1CjjjjvuaHcu0d6/xsbGyO86IPKZuW/fPsMwevZ5uGTJkqiVW+vWrTMsFouxYsUKY/v27caKFSsMq9VqrF+/Pmb9TpjA4sorrzSAdre333470mbfvn3GeeedZ6SkpBjZ2dnGDTfcYHi93sj5PXv2tLumpaXFuOGGG4zs7GwjJSXFOP/8843S0tJBfGVdu/zyy40FCxZ0eh4wnnjiCcMwDMPj8RhnnXWWkZeXZ9hsNmPUqFHGlVdeOaReT9jGjRuN4447zsjIyDCcTqcxefJk49577zWam5uj2rV9fYZhLrG69957jcLCQsPhcBgnn3yysXXr1kHufc888cQTHf6bPTKeT6T38L//+7+N0aNHG3a73ZgzZ07UUswrr7zSOOWUU6Lar1271pg9e7Zht9uNMWPGGI888sgg97jnOnuv2v77O/I1Pvjgg8b48eMNp9NpZGVlGSeeeKLx0ksvDX7ne+Cb3/ymUVRUZNhsNqO4uNi4+OKLjc8//zxyPtHfv7DXXnvNAIwdO3a0O5do7194OeyRtyuvvNIwjJ59Hp5yyimR9mHPPvusMXnyZMNmsxlTpkyJeSClGEZoNo4QQgghRD8lzXJTIYQQQsSfBBZCCCGEiBkJLIQQQggRMxJYCCGEECJmJLAQQgghRMxIYCGEEEKImJHAQgghhBAxI4GFEEIIIWJGAgshhBBCxIwEFkIIIYSIGQkshBBCCBEz/x+/+EY+UQ9vAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(\n",
    "    logk_1_pred,\n",
    "    logk_2_pred,\n",
    "    u_pred,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    u_test,\n",
    "    x_u_train,\n",
    "    t_u_train,\n",
    "    u_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a06f8",
   "metadata": {},
   "source": [
    "### Using DEns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf01a7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supporting backend tensorflow.compat.v1\n",
      "\n",
      "Compiling a Ensemble method\n",
      "\n",
      "Generating 0th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.77563\n",
      "Iteration:  100 , loss:  2.3946304\n",
      "Iteration:  200 , loss:  1.8521\n",
      "Iteration:  300 , loss:  1.4893435\n",
      "Iteration:  400 , loss:  0.8568401\n",
      "Iteration:  500 , loss:  0.43293336\n",
      "Iteration:  600 , loss:  0.26609945\n",
      "Iteration:  700 , loss:  0.18364173\n",
      "Iteration:  800 , loss:  0.13955812\n",
      "Iteration:  900 , loss:  0.1107081\n",
      "Iteration:  1000 , loss:  0.09235907\n",
      "Iteration:  1100 , loss:  0.07882629\n",
      "Iteration:  1200 , loss:  0.06941541\n",
      "Iteration:  1300 , loss:  0.063365586\n",
      "Iteration:  1400 , loss:  0.05594806\n",
      "Iteration:  1500 , loss:  0.050908823\n",
      "Iteration:  1600 , loss:  0.047151256\n",
      "Iteration:  1700 , loss:  0.04371331\n",
      "Iteration:  1800 , loss:  0.041536573\n",
      "Iteration:  1900 , loss:  0.038441796\n",
      "Iteration:  2000 , loss:  0.03942822\n",
      "Iteration:  2100 , loss:  0.034488164\n",
      "Iteration:  2200 , loss:  0.03576564\n",
      "Iteration:  2300 , loss:  0.031429872\n",
      "Iteration:  2400 , loss:  0.030047584\n",
      "Iteration:  2500 , loss:  0.028978571\n",
      "Iteration:  2600 , loss:  0.02780762\n",
      "Iteration:  2700 , loss:  0.059665598\n",
      "Iteration:  2800 , loss:  0.025880774\n",
      "Iteration:  2900 , loss:  0.024938298\n",
      "Iteration:  3000 , loss:  0.024304869\n",
      "Iteration:  3100 , loss:  0.02343265\n",
      "Iteration:  3200 , loss:  0.02287261\n",
      "Iteration:  3300 , loss:  0.022221636\n",
      "Iteration:  3400 , loss:  0.021769393\n",
      "Iteration:  3500 , loss:  0.021254873\n",
      "Iteration:  3600 , loss:  0.020925682\n",
      "Iteration:  3700 , loss:  0.02047224\n",
      "Iteration:  3800 , loss:  0.027988605\n",
      "Iteration:  3900 , loss:  0.01980676\n",
      "Iteration:  4000 , loss:  0.019476622\n",
      "Iteration:  4100 , loss:  0.01924389\n",
      "Iteration:  4200 , loss:  0.018950041\n",
      "Iteration:  4300 , loss:  0.019131016\n",
      "Iteration:  4400 , loss:  0.018484082\n",
      "Iteration:  4500 , loss:  0.02743836\n",
      "Iteration:  4600 , loss:  0.01808362\n",
      "Iteration:  4700 , loss:  0.017874457\n",
      "Iteration:  4800 , loss:  0.017742684\n",
      "Iteration:  4900 , loss:  0.01755125\n",
      "Iteration:  5000 , loss:  0.017533924\n",
      "Iteration:  5100 , loss:  0.01725238\n",
      "Iteration:  5200 , loss:  0.017423807\n",
      "Iteration:  5300 , loss:  0.016993655\n",
      "Iteration:  5400 , loss:  0.021847695\n",
      "Iteration:  5500 , loss:  0.016767979\n",
      "Iteration:  5600 , loss:  0.016636036\n",
      "Iteration:  5700 , loss:  0.016615473\n",
      "Iteration:  5800 , loss:  0.016426431\n",
      "Iteration:  5900 , loss:  0.021558333\n",
      "Iteration:  6000 , loss:  0.016214069\n",
      "Iteration:  6100 , loss:  0.02826573\n",
      "Iteration:  6200 , loss:  0.016049393\n",
      "Iteration:  6300 , loss:  0.015949829\n",
      "Iteration:  6400 , loss:  0.016057182\n",
      "Iteration:  6500 , loss:  0.015826255\n",
      "Iteration:  6600 , loss:  0.015748437\n",
      "Iteration:  6700 , loss:  0.015721647\n",
      "Iteration:  6800 , loss:  0.015628548\n",
      "Iteration:  6900 , loss:  0.015634842\n",
      "Iteration:  7000 , loss:  0.015519479\n",
      "Iteration:  7100 , loss:  0.015507786\n",
      "Iteration:  7200 , loss:  0.01542419\n",
      "Iteration:  7300 , loss:  0.022733152\n",
      "Iteration:  7400 , loss:  0.015338343\n",
      "Iteration:  7500 , loss:  0.015277756\n",
      "Iteration:  7600 , loss:  0.0152662415\n",
      "Iteration:  7700 , loss:  0.015194997\n",
      "Iteration:  7800 , loss:  0.015500458\n",
      "Iteration:  7900 , loss:  0.015118832\n",
      "Iteration:  8000 , loss:  0.023680862\n",
      "Iteration:  8100 , loss:  0.01504597\n",
      "Iteration:  8200 , loss:  0.015529368\n",
      "Iteration:  8300 , loss:  0.014983559\n",
      "Iteration:  8400 , loss:  0.014930215\n",
      "Iteration:  8500 , loss:  0.014957439\n",
      "Iteration:  8600 , loss:  0.014864324\n",
      "Iteration:  8700 , loss:  0.014905855\n",
      "Iteration:  8800 , loss:  0.014802186\n",
      "Iteration:  8900 , loss:  0.015612345\n",
      "Iteration:  9000 , loss:  0.01474446\n",
      "Iteration:  9100 , loss:  0.02147054\n",
      "Iteration:  9200 , loss:  0.0147067765\n",
      "Iteration:  9300 , loss:  0.014658622\n",
      "Iteration:  9400 , loss:  0.050276037\n",
      "Iteration:  9500 , loss:  0.014610151\n",
      "Iteration:  9600 , loss:  0.014569515\n",
      "Iteration:  9700 , loss:  0.014574299\n",
      "Iteration:  9800 , loss:  0.0145153785\n",
      "Iteration:  9900 , loss:  0.014518717\n",
      "Iteration:  10000 , loss:  0.014466438\n",
      "Iteration:  10100 , loss:  0.014716491\n",
      "Iteration:  10200 , loss:  0.014420405\n",
      "Iteration:  10300 , loss:  0.014571449\n",
      "Iteration:  10400 , loss:  0.014371803\n",
      "Iteration:  10500 , loss:  0.015447266\n",
      "Iteration:  10600 , loss:  0.014323422\n",
      "Iteration:  10700 , loss:  0.015356634\n",
      "Iteration:  10800 , loss:  0.014279566\n",
      "Iteration:  10900 , loss:  0.016158026\n",
      "Iteration:  11000 , loss:  0.014240976\n",
      "Iteration:  11100 , loss:  0.014207265\n",
      "Iteration:  11200 , loss:  0.014207145\n",
      "Iteration:  11300 , loss:  0.014166223\n",
      "Iteration:  11400 , loss:  0.01420635\n",
      "Iteration:  11500 , loss:  0.0141255725\n",
      "Iteration:  11600 , loss:  0.014333781\n",
      "Iteration:  11700 , loss:  0.014088353\n",
      "Iteration:  11800 , loss:  0.014814012\n",
      "Iteration:  11900 , loss:  0.014050886\n",
      "Iteration:  12000 , loss:  0.056321274\n",
      "Iteration:  12100 , loss:  0.014021307\n",
      "Iteration:  12200 , loss:  0.013987854\n",
      "Iteration:  12300 , loss:  0.014040537\n",
      "Iteration:  12400 , loss:  0.013953332\n",
      "Iteration:  12500 , loss:  0.015211797\n",
      "Iteration:  12600 , loss:  0.013917366\n",
      "Iteration:  12700 , loss:  0.014331269\n",
      "Iteration:  12800 , loss:  0.013882566\n",
      "Iteration:  12900 , loss:  0.01680778\n",
      "Iteration:  13000 , loss:  0.013848506\n",
      "Iteration:  13100 , loss:  0.016528614\n",
      "Iteration:  13200 , loss:  0.013831271\n",
      "Iteration:  13300 , loss:  0.0137971\n",
      "Iteration:  13400 , loss:  0.018812265\n",
      "Iteration:  13500 , loss:  0.013769884\n",
      "Iteration:  13600 , loss:  0.013742473\n",
      "Iteration:  13700 , loss:  0.013747774\n",
      "Iteration:  13800 , loss:  0.013709808\n",
      "Iteration:  13900 , loss:  0.013716493\n",
      "Iteration:  14000 , loss:  0.013679066\n",
      "Iteration:  14100 , loss:  0.013676684\n",
      "Iteration:  14200 , loss:  0.014383272\n",
      "Iteration:  14300 , loss:  0.013639802\n",
      "Iteration:  14400 , loss:  0.014401155\n",
      "Iteration:  14500 , loss:  0.013609093\n",
      "Iteration:  14600 , loss:  0.014353236\n",
      "Iteration:  14700 , loss:  0.013579468\n",
      "Iteration:  14800 , loss:  0.022970099\n",
      "Iteration:  14900 , loss:  0.013549965\n",
      "Iteration:  15000 , loss:  0.019694436\n",
      "Iteration:  15100 , loss:  0.013520607\n",
      "Iteration:  15200 , loss:  0.020481687\n",
      "Iteration:  15300 , loss:  0.013489382\n",
      "Iteration:  15400 , loss:  0.0139667485\n",
      "Iteration:  15500 , loss:  0.013460547\n",
      "Iteration:  15600 , loss:  0.014085329\n",
      "Iteration:  15700 , loss:  0.013435099\n",
      "Iteration:  15800 , loss:  0.016532086\n",
      "Iteration:  15900 , loss:  0.01340536\n",
      "Iteration:  16000 , loss:  0.013960456\n",
      "Iteration:  16100 , loss:  0.013375239\n",
      "Iteration:  16200 , loss:  0.013385237\n",
      "Iteration:  16300 , loss:  0.01334523\n",
      "Iteration:  16400 , loss:  0.013362207\n",
      "Iteration:  16500 , loss:  0.013323091\n",
      "Iteration:  16600 , loss:  0.015185543\n",
      "Iteration:  16700 , loss:  0.01330197\n",
      "Iteration:  16800 , loss:  0.013280621\n",
      "Iteration:  16900 , loss:  0.0132761635\n",
      "Iteration:  17000 , loss:  0.017244961\n",
      "Iteration:  17100 , loss:  0.013250887\n",
      "Iteration:  17200 , loss:  0.01331255\n",
      "Iteration:  17300 , loss:  0.013229877\n",
      "Iteration:  17400 , loss:  0.013212541\n",
      "Iteration:  17500 , loss:  0.013554962\n",
      "Iteration:  17600 , loss:  0.013231063\n",
      "Iteration:  17700 , loss:  0.01389602\n",
      "Iteration:  17800 , loss:  0.013159874\n",
      "Iteration:  17900 , loss:  0.013139388\n",
      "Iteration:  18000 , loss:  0.013164472\n",
      "Iteration:  18100 , loss:  0.01615701\n",
      "Iteration:  18200 , loss:  0.0131015405\n",
      "Iteration:  18300 , loss:  0.013099793\n",
      "Iteration:  18400 , loss:  0.0131908\n",
      "Iteration:  18500 , loss:  0.015084213\n",
      "Iteration:  18600 , loss:  0.013056512\n",
      "Iteration:  18700 , loss:  0.013555255\n",
      "Iteration:  18800 , loss:  0.013030401\n",
      "Iteration:  18900 , loss:  0.013056108\n",
      "Iteration:  19000 , loss:  0.013001756\n",
      "Iteration:  19100 , loss:  0.013006795\n",
      "Iteration:  19200 , loss:  0.012980957\n",
      "Iteration:  19300 , loss:  0.013022105\n",
      "Iteration:  19400 , loss:  0.014798598\n",
      "Iteration:  19500 , loss:  0.01294907\n",
      "Iteration:  19600 , loss:  0.013493575\n",
      "Iteration:  19700 , loss:  0.012925882\n",
      "Iteration:  19800 , loss:  0.01578721\n",
      "Iteration:  19900 , loss:  0.012906805\n",
      "Generating 1th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  4.3695292\n",
      "Iteration:  100 , loss:  2.5480843\n",
      "Iteration:  200 , loss:  2.002897\n",
      "Iteration:  300 , loss:  1.6647729\n",
      "Iteration:  400 , loss:  1.1741972\n",
      "Iteration:  500 , loss:  0.53177214\n",
      "Iteration:  600 , loss:  0.3301994\n",
      "Iteration:  700 , loss:  0.23222236\n",
      "Iteration:  800 , loss:  0.18946919\n",
      "Iteration:  900 , loss:  0.14754945\n",
      "Iteration:  1000 , loss:  0.12428508\n",
      "Iteration:  1100 , loss:  0.1055293\n",
      "Iteration:  1200 , loss:  0.09103833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1300 , loss:  0.08055347\n",
      "Iteration:  1400 , loss:  0.07098538\n",
      "Iteration:  1500 , loss:  0.063379906\n",
      "Iteration:  1600 , loss:  0.057178717\n",
      "Iteration:  1700 , loss:  0.05175021\n",
      "Iteration:  1800 , loss:  0.047251366\n",
      "Iteration:  1900 , loss:  0.062498234\n",
      "Iteration:  2000 , loss:  0.039930124\n",
      "Iteration:  2100 , loss:  0.041132018\n",
      "Iteration:  2200 , loss:  0.034502473\n",
      "Iteration:  2300 , loss:  0.04459872\n",
      "Iteration:  2400 , loss:  0.030383164\n",
      "Iteration:  2500 , loss:  0.07800602\n",
      "Iteration:  2600 , loss:  0.027196405\n",
      "Iteration:  2700 , loss:  0.02580129\n",
      "Iteration:  2800 , loss:  0.024726227\n",
      "Iteration:  2900 , loss:  0.023611179\n",
      "Iteration:  3000 , loss:  0.02286388\n",
      "Iteration:  3100 , loss:  0.021936692\n",
      "Iteration:  3200 , loss:  0.021378333\n",
      "Iteration:  3300 , loss:  0.020610455\n",
      "Iteration:  3400 , loss:  0.031832036\n",
      "Iteration:  3500 , loss:  0.019547565\n",
      "Iteration:  3600 , loss:  0.01918626\n",
      "Iteration:  3700 , loss:  0.018661689\n",
      "Iteration:  3800 , loss:  0.018488219\n",
      "Iteration:  3900 , loss:  0.017946985\n",
      "Iteration:  4000 , loss:  0.021008767\n",
      "Iteration:  4100 , loss:  0.017363288\n",
      "Iteration:  4200 , loss:  0.017059026\n",
      "Iteration:  4300 , loss:  0.016887143\n",
      "Iteration:  4400 , loss:  0.01659891\n",
      "Iteration:  4500 , loss:  0.019520901\n",
      "Iteration:  4600 , loss:  0.016199317\n",
      "Iteration:  4700 , loss:  0.015978727\n",
      "Iteration:  4800 , loss:  0.015851203\n",
      "Iteration:  4900 , loss:  0.015642814\n",
      "Iteration:  5000 , loss:  0.017716166\n",
      "Iteration:  5100 , loss:  0.0153442975\n",
      "Iteration:  5200 , loss:  0.0153747015\n",
      "Iteration:  5300 , loss:  0.015086444\n",
      "Iteration:  5400 , loss:  0.014932876\n",
      "Iteration:  5500 , loss:  0.0151079\n",
      "Iteration:  5600 , loss:  0.014708834\n",
      "Iteration:  5700 , loss:  0.018642003\n",
      "Iteration:  5800 , loss:  0.014506286\n",
      "Iteration:  5900 , loss:  0.0148172015\n",
      "Iteration:  6000 , loss:  0.01433108\n",
      "Iteration:  6100 , loss:  0.014221578\n",
      "Iteration:  6200 , loss:  0.01448049\n",
      "Iteration:  6300 , loss:  0.014062412\n",
      "Iteration:  6400 , loss:  0.016103059\n",
      "Iteration:  6500 , loss:  0.013922412\n",
      "Iteration:  6600 , loss:  0.0138363885\n",
      "Iteration:  6700 , loss:  0.013807137\n",
      "Iteration:  6800 , loss:  0.013712441\n",
      "Iteration:  6900 , loss:  0.014841994\n",
      "Iteration:  7000 , loss:  0.013602288\n",
      "Iteration:  7100 , loss:  0.0135473665\n",
      "Iteration:  7200 , loss:  0.013504032\n",
      "Iteration:  7300 , loss:  0.013429001\n",
      "Iteration:  7400 , loss:  0.013430206\n",
      "Iteration:  7500 , loss:  0.013337273\n",
      "Iteration:  7600 , loss:  0.01635041\n",
      "Iteration:  7700 , loss:  0.013252655\n",
      "Iteration:  7800 , loss:  0.013197608\n",
      "Iteration:  7900 , loss:  0.013182905\n",
      "Iteration:  8000 , loss:  0.0131219085\n",
      "Iteration:  8100 , loss:  0.013160501\n",
      "Iteration:  8200 , loss:  0.013053946\n",
      "Iteration:  8300 , loss:  0.0130038485\n",
      "Iteration:  8400 , loss:  0.013014671\n",
      "Iteration:  8500 , loss:  0.012946414\n",
      "Iteration:  8600 , loss:  0.0129967425\n",
      "Iteration:  8700 , loss:  0.012890551\n",
      "Iteration:  8800 , loss:  0.012842318\n",
      "Iteration:  8900 , loss:  0.013072349\n",
      "Iteration:  9000 , loss:  0.012783939\n",
      "Iteration:  9100 , loss:  0.013664668\n",
      "Iteration:  9200 , loss:  0.012728534\n",
      "Iteration:  9300 , loss:  0.014631422\n",
      "Iteration:  9400 , loss:  0.012683644\n",
      "Iteration:  9500 , loss:  0.01264008\n",
      "Iteration:  9600 , loss:  0.013393032\n",
      "Iteration:  9700 , loss:  0.0125905285\n",
      "Iteration:  9800 , loss:  0.04240834\n",
      "Iteration:  9900 , loss:  0.012554104\n",
      "Iteration:  10000 , loss:  0.012512522\n",
      "Iteration:  10100 , loss:  0.017110378\n",
      "Iteration:  10200 , loss:  0.01247119\n",
      "Iteration:  10300 , loss:  0.012433971\n",
      "Iteration:  10400 , loss:  0.012438432\n",
      "Iteration:  10500 , loss:  0.012390557\n",
      "Iteration:  10600 , loss:  0.013328627\n",
      "Iteration:  10700 , loss:  0.012356716\n",
      "Iteration:  10800 , loss:  0.012321157\n",
      "Iteration:  10900 , loss:  0.012404735\n",
      "Iteration:  11000 , loss:  0.012283146\n",
      "Iteration:  11100 , loss:  0.02897901\n",
      "Iteration:  11200 , loss:  0.012253882\n",
      "Iteration:  11300 , loss:  0.012217561\n",
      "Iteration:  11400 , loss:  0.012584893\n",
      "Iteration:  11500 , loss:  0.012185743\n",
      "Iteration:  11600 , loss:  0.012152963\n",
      "Iteration:  11700 , loss:  0.012183266\n",
      "Iteration:  11800 , loss:  0.012125444\n",
      "Iteration:  11900 , loss:  0.012097921\n",
      "Iteration:  12000 , loss:  0.012105066\n",
      "Iteration:  12100 , loss:  0.012063804\n",
      "Iteration:  12200 , loss:  0.013647027\n",
      "Iteration:  12300 , loss:  0.012033672\n",
      "Iteration:  12400 , loss:  0.012006067\n",
      "Iteration:  12500 , loss:  0.012020521\n",
      "Iteration:  12600 , loss:  0.01197733\n",
      "Iteration:  12700 , loss:  0.06153048\n",
      "Iteration:  12800 , loss:  0.01196493\n",
      "Iteration:  12900 , loss:  0.011930719\n",
      "Iteration:  13000 , loss:  0.012696577\n",
      "Iteration:  13100 , loss:  0.011904379\n",
      "Iteration:  13200 , loss:  0.011874569\n",
      "Iteration:  13300 , loss:  0.011890361\n",
      "Iteration:  13400 , loss:  0.01185078\n",
      "Iteration:  13500 , loss:  0.013686365\n",
      "Iteration:  13600 , loss:  0.011823399\n",
      "Iteration:  13700 , loss:  0.038649652\n",
      "Iteration:  13800 , loss:  0.011799047\n",
      "Iteration:  13900 , loss:  0.0117710205\n",
      "Iteration:  14000 , loss:  0.011805144\n",
      "Iteration:  14100 , loss:  0.011750441\n",
      "Iteration:  14200 , loss:  0.023786543\n",
      "Iteration:  14300 , loss:  0.0117300935\n",
      "Iteration:  14400 , loss:  0.011703397\n",
      "Iteration:  14500 , loss:  0.011727305\n",
      "Iteration:  14600 , loss:  0.01167922\n",
      "Iteration:  14700 , loss:  0.011719533\n",
      "Iteration:  14800 , loss:  0.01165757\n",
      "Iteration:  14900 , loss:  0.013724353\n",
      "Iteration:  15000 , loss:  0.01163528\n",
      "Iteration:  15100 , loss:  0.012107137\n",
      "Iteration:  15200 , loss:  0.011622945\n",
      "Iteration:  15300 , loss:  0.011593135\n",
      "Iteration:  15400 , loss:  0.012078442\n",
      "Iteration:  15500 , loss:  0.011578317\n",
      "Iteration:  15600 , loss:  0.011553968\n",
      "Iteration:  15700 , loss:  0.011568054\n",
      "Iteration:  15800 , loss:  0.011533669\n",
      "Iteration:  15900 , loss:  0.012070923\n",
      "Iteration:  16000 , loss:  0.011515137\n",
      "Iteration:  16100 , loss:  0.03604536\n",
      "Iteration:  16200 , loss:  0.011496354\n",
      "Iteration:  16300 , loss:  0.011474013\n",
      "Iteration:  16400 , loss:  0.011479238\n",
      "Iteration:  16500 , loss:  0.011451609\n",
      "Iteration:  16600 , loss:  0.011505408\n",
      "Iteration:  16700 , loss:  0.011434448\n",
      "Iteration:  16800 , loss:  0.0128902085\n",
      "Iteration:  16900 , loss:  0.011421893\n",
      "Iteration:  17000 , loss:  0.0113975555\n",
      "Iteration:  17100 , loss:  0.01150318\n",
      "Iteration:  17200 , loss:  0.011378772\n",
      "Iteration:  17300 , loss:  0.013367827\n",
      "Iteration:  17400 , loss:  0.011366429\n",
      "Iteration:  17500 , loss:  0.011343627\n",
      "Iteration:  17600 , loss:  0.011458045\n",
      "Iteration:  17700 , loss:  0.011330672\n",
      "Iteration:  17800 , loss:  0.011349458\n",
      "Iteration:  17900 , loss:  0.011316662\n",
      "Iteration:  18000 , loss:  0.011290906\n",
      "Iteration:  18100 , loss:  0.01130941\n",
      "Iteration:  18200 , loss:  0.01127413\n",
      "Iteration:  18300 , loss:  0.01222007\n",
      "Iteration:  18400 , loss:  0.011262135\n",
      "Iteration:  18500 , loss:  0.01124059\n",
      "Iteration:  18600 , loss:  0.011258399\n",
      "Iteration:  18700 , loss:  0.011221965\n",
      "Iteration:  18800 , loss:  0.011279916\n",
      "Iteration:  18900 , loss:  0.01120264\n",
      "Iteration:  19000 , loss:  0.011328459\n",
      "Iteration:  19100 , loss:  0.011184991\n",
      "Iteration:  19200 , loss:  0.011583192\n",
      "Iteration:  19300 , loss:  0.011167875\n",
      "Iteration:  19400 , loss:  0.01683094\n",
      "Iteration:  19500 , loss:  0.011149361\n",
      "Iteration:  19600 , loss:  0.017211955\n",
      "Iteration:  19700 , loss:  0.01113173\n",
      "Iteration:  19800 , loss:  0.011110421\n",
      "Iteration:  19900 , loss:  0.011126713\n",
      "Generating 2th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.6048505\n",
      "Iteration:  100 , loss:  2.1612017\n",
      "Iteration:  200 , loss:  1.7386849\n",
      "Iteration:  300 , loss:  1.2244191\n",
      "Iteration:  400 , loss:  0.5146412\n",
      "Iteration:  500 , loss:  0.2404431\n",
      "Iteration:  600 , loss:  0.1706918\n",
      "Iteration:  700 , loss:  0.13225861\n",
      "Iteration:  800 , loss:  0.1168101\n",
      "Iteration:  900 , loss:  0.1110856\n",
      "Iteration:  1000 , loss:  0.08429523\n",
      "Iteration:  1100 , loss:  0.07510617\n",
      "Iteration:  1200 , loss:  0.067405954\n",
      "Iteration:  1300 , loss:  0.060594678\n",
      "Iteration:  1400 , loss:  0.05453372\n",
      "Iteration:  1500 , loss:  0.06684218\n",
      "Iteration:  1600 , loss:  0.04462806\n",
      "Iteration:  1700 , loss:  0.041215155\n",
      "Iteration:  1800 , loss:  0.03837227\n",
      "Iteration:  1900 , loss:  0.03596464\n",
      "Iteration:  2000 , loss:  0.03374677\n",
      "Iteration:  2100 , loss:  0.03167217\n",
      "Iteration:  2200 , loss:  0.029998764\n",
      "Iteration:  2300 , loss:  0.02837152\n",
      "Iteration:  2400 , loss:  0.027054584\n",
      "Iteration:  2500 , loss:  0.025921546\n",
      "Iteration:  2600 , loss:  0.025343213\n",
      "Iteration:  2700 , loss:  0.024050357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2800 , loss:  0.029363317\n",
      "Iteration:  2900 , loss:  0.022650367\n",
      "Iteration:  3000 , loss:  0.021671219\n",
      "Iteration:  3100 , loss:  0.021203062\n",
      "Iteration:  3200 , loss:  0.020602338\n",
      "Iteration:  3300 , loss:  0.01996607\n",
      "Iteration:  3400 , loss:  0.019535253\n",
      "Iteration:  3500 , loss:  0.019496804\n",
      "Iteration:  3600 , loss:  0.01872354\n",
      "Iteration:  3700 , loss:  0.018321067\n",
      "Iteration:  3800 , loss:  0.018021068\n",
      "Iteration:  3900 , loss:  0.01911777\n",
      "Iteration:  4000 , loss:  0.017398717\n",
      "Iteration:  4100 , loss:  0.017477263\n",
      "Iteration:  4200 , loss:  0.01688078\n",
      "Iteration:  4300 , loss:  0.019808045\n",
      "Iteration:  4400 , loss:  0.016441716\n",
      "Iteration:  4500 , loss:  0.016549354\n",
      "Iteration:  4600 , loss:  0.0437242\n",
      "Iteration:  4700 , loss:  0.015883401\n",
      "Iteration:  4800 , loss:  0.016640663\n",
      "Iteration:  4900 , loss:  0.01557439\n",
      "Iteration:  5000 , loss:  0.0156567\n",
      "Iteration:  5100 , loss:  0.015309242\n",
      "Iteration:  5200 , loss:  0.01569486\n",
      "Iteration:  5300 , loss:  0.030337356\n",
      "Iteration:  5400 , loss:  0.014969272\n",
      "Iteration:  5500 , loss:  0.015479719\n",
      "Iteration:  5600 , loss:  0.014776972\n",
      "Iteration:  5700 , loss:  0.029343834\n",
      "Iteration:  5800 , loss:  0.014615267\n",
      "Iteration:  5900 , loss:  0.014533069\n",
      "Iteration:  6000 , loss:  0.014716821\n",
      "Iteration:  6100 , loss:  0.014388366\n",
      "Iteration:  6200 , loss:  0.055277146\n",
      "Iteration:  6300 , loss:  0.01426219\n",
      "Iteration:  6400 , loss:  0.0143499\n",
      "Iteration:  6500 , loss:  0.014728638\n",
      "Iteration:  6600 , loss:  0.014119253\n",
      "Iteration:  6700 , loss:  0.014032176\n",
      "Iteration:  6800 , loss:  0.024832217\n",
      "Iteration:  6900 , loss:  0.013950105\n",
      "Iteration:  7000 , loss:  0.0138829695\n",
      "Iteration:  7100 , loss:  0.014659771\n",
      "Iteration:  7200 , loss:  0.013795729\n",
      "Iteration:  7300 , loss:  0.028045528\n",
      "Iteration:  7400 , loss:  0.013719373\n",
      "Iteration:  7500 , loss:  0.013678402\n",
      "Iteration:  7600 , loss:  0.013654402\n",
      "Iteration:  7700 , loss:  0.013596128\n",
      "Iteration:  7800 , loss:  0.013960589\n",
      "Iteration:  7900 , loss:  0.013527112\n",
      "Iteration:  8000 , loss:  0.013921263\n",
      "Iteration:  8100 , loss:  0.013461131\n",
      "Iteration:  8200 , loss:  0.014844694\n",
      "Iteration:  8300 , loss:  0.013400054\n",
      "Iteration:  8400 , loss:  0.020484561\n",
      "Iteration:  8500 , loss:  0.013344553\n",
      "Iteration:  8600 , loss:  0.013431566\n",
      "Iteration:  8700 , loss:  0.013297707\n",
      "Iteration:  8800 , loss:  0.013252755\n",
      "Iteration:  8900 , loss:  0.013338513\n",
      "Iteration:  9000 , loss:  0.013199534\n",
      "Iteration:  9100 , loss:  0.013216053\n",
      "Iteration:  9200 , loss:  0.013148422\n",
      "Iteration:  9300 , loss:  0.013145813\n",
      "Iteration:  9400 , loss:  0.013098945\n",
      "Iteration:  9500 , loss:  0.0131006045\n",
      "Iteration:  9600 , loss:  0.013053523\n",
      "Iteration:  9700 , loss:  0.013082852\n",
      "Iteration:  9800 , loss:  0.013008725\n",
      "Iteration:  9900 , loss:  0.013044249\n",
      "Iteration:  10000 , loss:  0.012964142\n",
      "Iteration:  10100 , loss:  0.012973794\n",
      "Iteration:  10200 , loss:  0.012921052\n",
      "Iteration:  10300 , loss:  0.012937141\n",
      "Iteration:  10400 , loss:  0.012882944\n",
      "Iteration:  10500 , loss:  0.012962375\n",
      "Iteration:  10600 , loss:  0.01284473\n",
      "Iteration:  10700 , loss:  0.013148811\n",
      "Iteration:  10800 , loss:  0.0128034465\n",
      "Iteration:  10900 , loss:  0.013098085\n",
      "Iteration:  11000 , loss:  0.012765432\n",
      "Iteration:  11100 , loss:  0.0134420935\n",
      "Iteration:  11200 , loss:  0.012729363\n",
      "Iteration:  11300 , loss:  0.013982619\n",
      "Iteration:  11400 , loss:  0.012692672\n",
      "Iteration:  11500 , loss:  0.014550804\n",
      "Iteration:  11600 , loss:  0.012657512\n",
      "Iteration:  11700 , loss:  0.015717605\n",
      "Iteration:  11800 , loss:  0.012626286\n",
      "Iteration:  11900 , loss:  0.013261322\n",
      "Iteration:  12000 , loss:  0.012594881\n",
      "Iteration:  12100 , loss:  0.012562717\n",
      "Iteration:  12200 , loss:  0.012579432\n",
      "Iteration:  12300 , loss:  0.01253526\n",
      "Iteration:  12400 , loss:  0.013433059\n",
      "Iteration:  12500 , loss:  0.012506612\n",
      "Iteration:  12600 , loss:  0.03012392\n",
      "Iteration:  12700 , loss:  0.012485491\n",
      "Iteration:  12800 , loss:  0.012452425\n",
      "Iteration:  12900 , loss:  0.012469413\n",
      "Iteration:  13000 , loss:  0.012423264\n",
      "Iteration:  13100 , loss:  0.012751441\n",
      "Iteration:  13200 , loss:  0.012392756\n",
      "Iteration:  13300 , loss:  0.012477234\n",
      "Iteration:  13400 , loss:  0.012362483\n",
      "Iteration:  13500 , loss:  0.012731722\n",
      "Iteration:  13600 , loss:  0.012333658\n",
      "Iteration:  13700 , loss:  0.013312608\n",
      "Iteration:  13800 , loss:  0.012305867\n",
      "Iteration:  13900 , loss:  0.01717672\n",
      "Iteration:  14000 , loss:  0.012281294\n",
      "Iteration:  14100 , loss:  0.012363139\n",
      "Iteration:  14200 , loss:  0.012261531\n",
      "Iteration:  14300 , loss:  0.01222856\n",
      "Iteration:  14400 , loss:  0.012251299\n",
      "Iteration:  14500 , loss:  0.012200572\n",
      "Iteration:  14600 , loss:  0.012205908\n",
      "Iteration:  14700 , loss:  0.01217303\n",
      "Iteration:  14800 , loss:  0.012192723\n",
      "Iteration:  14900 , loss:  0.012148833\n",
      "Iteration:  15000 , loss:  0.012631145\n",
      "Iteration:  15100 , loss:  0.012134065\n",
      "Iteration:  15200 , loss:  0.012108477\n",
      "Iteration:  15300 , loss:  0.012119817\n",
      "Iteration:  15400 , loss:  0.012085611\n",
      "Iteration:  15500 , loss:  0.012135085\n",
      "Iteration:  15600 , loss:  0.012060858\n",
      "Iteration:  15700 , loss:  0.012709335\n",
      "Iteration:  15800 , loss:  0.012043834\n",
      "Iteration:  15900 , loss:  0.012092337\n",
      "Iteration:  16000 , loss:  0.012025336\n",
      "Iteration:  16100 , loss:  0.012012486\n",
      "Iteration:  16200 , loss:  0.011998164\n",
      "Iteration:  16300 , loss:  0.019271847\n",
      "Iteration:  16400 , loss:  0.011971364\n",
      "Iteration:  16500 , loss:  0.021947837\n",
      "Iteration:  16600 , loss:  0.011945694\n",
      "Iteration:  16700 , loss:  0.013508661\n",
      "Iteration:  16800 , loss:  0.011922048\n",
      "Iteration:  16900 , loss:  0.015360848\n",
      "Iteration:  17000 , loss:  0.0119066145\n",
      "Iteration:  17100 , loss:  0.011881995\n",
      "Iteration:  17200 , loss:  0.011904016\n",
      "Iteration:  17300 , loss:  0.011860788\n",
      "Iteration:  17400 , loss:  0.0119144665\n",
      "Iteration:  17500 , loss:  0.011846612\n",
      "Iteration:  17600 , loss:  0.019200176\n",
      "Iteration:  17700 , loss:  0.011828274\n",
      "Iteration:  17800 , loss:  0.0137098655\n",
      "Iteration:  17900 , loss:  0.01180899\n",
      "Iteration:  18000 , loss:  0.011856665\n",
      "Iteration:  18100 , loss:  0.011793693\n",
      "Iteration:  18200 , loss:  0.0117658265\n",
      "Iteration:  18300 , loss:  0.011780607\n",
      "Iteration:  18400 , loss:  0.01174641\n",
      "Iteration:  18500 , loss:  0.01180579\n",
      "Iteration:  18600 , loss:  0.011727437\n",
      "Iteration:  18700 , loss:  0.011943917\n",
      "Iteration:  18800 , loss:  0.011710279\n",
      "Iteration:  18900 , loss:  0.019819172\n",
      "Iteration:  19000 , loss:  0.011704546\n",
      "Iteration:  19100 , loss:  0.011680068\n",
      "Iteration:  19200 , loss:  0.012646646\n",
      "Iteration:  19300 , loss:  0.011666735\n",
      "Iteration:  19400 , loss:  0.011806362\n",
      "Iteration:  19500 , loss:  0.011653507\n",
      "Iteration:  19600 , loss:  0.011627801\n",
      "Iteration:  19700 , loss:  0.011646541\n",
      "Iteration:  19800 , loss:  0.011610765\n",
      "Iteration:  19900 , loss:  0.011690503\n",
      "Generating 3th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.6589513\n",
      "Iteration:  100 , loss:  2.2871134\n",
      "Iteration:  200 , loss:  1.796726\n",
      "Iteration:  300 , loss:  1.3661809\n",
      "Iteration:  400 , loss:  0.58689433\n",
      "Iteration:  500 , loss:  0.2827697\n",
      "Iteration:  600 , loss:  0.20456934\n",
      "Iteration:  700 , loss:  0.16333945\n",
      "Iteration:  800 , loss:  0.12873572\n",
      "Iteration:  900 , loss:  0.1023716\n",
      "Iteration:  1000 , loss:  0.0868868\n",
      "Iteration:  1100 , loss:  0.0772636\n",
      "Iteration:  1200 , loss:  0.07023669\n",
      "Iteration:  1300 , loss:  0.06741057\n",
      "Iteration:  1400 , loss:  0.059295394\n",
      "Iteration:  1500 , loss:  0.054904684\n",
      "Iteration:  1600 , loss:  0.0802677\n",
      "Iteration:  1700 , loss:  0.047461387\n",
      "Iteration:  1800 , loss:  0.045356728\n",
      "Iteration:  1900 , loss:  0.041335598\n",
      "Iteration:  2000 , loss:  0.039126907\n",
      "Iteration:  2100 , loss:  0.036681853\n",
      "Iteration:  2200 , loss:  0.054360095\n",
      "Iteration:  2300 , loss:  0.033039507\n",
      "Iteration:  2400 , loss:  0.05947109\n",
      "Iteration:  2500 , loss:  0.030177288\n",
      "Iteration:  2600 , loss:  0.043663066\n",
      "Iteration:  2700 , loss:  0.027861057\n",
      "Iteration:  2800 , loss:  0.027594185\n",
      "Iteration:  2900 , loss:  0.025945902\n",
      "Iteration:  3000 , loss:  0.02533404\n",
      "Iteration:  3100 , loss:  0.02438481\n",
      "Iteration:  3200 , loss:  0.02672599\n",
      "Iteration:  3300 , loss:  0.023070933\n",
      "Iteration:  3400 , loss:  0.027850345\n",
      "Iteration:  3500 , loss:  0.021950688\n",
      "Iteration:  3600 , loss:  0.0214274\n",
      "Iteration:  3700 , loss:  0.021054015\n",
      "Iteration:  3800 , loss:  0.020624012\n",
      "Iteration:  3900 , loss:  0.020391226\n",
      "Iteration:  4000 , loss:  0.019914227\n",
      "Iteration:  4100 , loss:  0.048429105\n",
      "Iteration:  4200 , loss:  0.019326242\n",
      "Iteration:  4300 , loss:  0.01903733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4400 , loss:  0.018822813\n",
      "Iteration:  4500 , loss:  0.01856485\n",
      "Iteration:  4600 , loss:  0.01931085\n",
      "Iteration:  4700 , loss:  0.018161181\n",
      "Iteration:  4800 , loss:  0.0179553\n",
      "Iteration:  4900 , loss:  0.01783847\n",
      "Iteration:  5000 , loss:  0.017619567\n",
      "Iteration:  5100 , loss:  0.021732707\n",
      "Iteration:  5200 , loss:  0.017313497\n",
      "Iteration:  5300 , loss:  0.046647415\n",
      "Iteration:  5400 , loss:  0.017037096\n",
      "Iteration:  5500 , loss:  0.017066594\n",
      "Iteration:  5600 , loss:  0.016790707\n",
      "Iteration:  5700 , loss:  0.016662018\n",
      "Iteration:  5800 , loss:  0.016691912\n",
      "Iteration:  5900 , loss:  0.016448695\n",
      "Iteration:  6000 , loss:  0.016675955\n",
      "Iteration:  6100 , loss:  0.016245665\n",
      "Iteration:  6200 , loss:  0.016175626\n",
      "Iteration:  6300 , loss:  0.01606734\n",
      "Iteration:  6400 , loss:  0.016192451\n",
      "Iteration:  6500 , loss:  0.015905418\n",
      "Iteration:  6600 , loss:  0.023060672\n",
      "Iteration:  6700 , loss:  0.01575702\n",
      "Iteration:  6800 , loss:  0.015681334\n",
      "Iteration:  6900 , loss:  0.015621081\n",
      "Iteration:  7000 , loss:  0.0155456485\n",
      "Iteration:  7100 , loss:  0.0155557105\n",
      "Iteration:  7200 , loss:  0.0154219605\n",
      "Iteration:  7300 , loss:  0.019102944\n",
      "Iteration:  7400 , loss:  0.015315619\n",
      "Iteration:  7500 , loss:  0.01525291\n",
      "Iteration:  7600 , loss:  0.015431328\n",
      "Iteration:  7700 , loss:  0.01515286\n",
      "Iteration:  7800 , loss:  0.015094891\n",
      "Iteration:  7900 , loss:  0.015149751\n",
      "Iteration:  8000 , loss:  0.015002081\n",
      "Iteration:  8100 , loss:  0.014972199\n",
      "Iteration:  8200 , loss:  0.014918279\n",
      "Iteration:  8300 , loss:  0.014861729\n",
      "Iteration:  8400 , loss:  0.014841486\n",
      "Iteration:  8500 , loss:  0.014807207\n",
      "Iteration:  8600 , loss:  0.014735308\n",
      "Iteration:  8700 , loss:  0.014712924\n",
      "Iteration:  8800 , loss:  0.014672482\n",
      "Iteration:  8900 , loss:  0.0146267135\n",
      "Iteration:  9000 , loss:  0.014580788\n",
      "Iteration:  9100 , loss:  0.01455518\n",
      "Iteration:  9200 , loss:  0.014511678\n",
      "Iteration:  9300 , loss:  0.014476479\n",
      "Iteration:  9400 , loss:  0.014579367\n",
      "Iteration:  9500 , loss:  0.014406874\n",
      "Iteration:  9600 , loss:  0.014409446\n",
      "Iteration:  9700 , loss:  0.0143449325\n",
      "Iteration:  9800 , loss:  0.01487265\n",
      "Iteration:  9900 , loss:  0.014289031\n",
      "Iteration:  10000 , loss:  0.014253192\n",
      "Iteration:  10100 , loss:  0.014249374\n",
      "Iteration:  10200 , loss:  0.014198971\n",
      "Iteration:  10300 , loss:  0.014735965\n",
      "Iteration:  10400 , loss:  0.014152403\n",
      "Iteration:  10500 , loss:  0.014118618\n",
      "Iteration:  10600 , loss:  0.014632102\n",
      "Iteration:  10700 , loss:  0.014066903\n",
      "Iteration:  10800 , loss:  0.018702798\n",
      "Iteration:  10900 , loss:  0.01403155\n",
      "Iteration:  11000 , loss:  0.013998827\n",
      "Iteration:  11100 , loss:  0.013969863\n",
      "Iteration:  11200 , loss:  0.013975869\n",
      "Iteration:  11300 , loss:  0.013925657\n",
      "Iteration:  11400 , loss:  0.01415831\n",
      "Iteration:  11500 , loss:  0.013880993\n",
      "Iteration:  11600 , loss:  0.01464591\n",
      "Iteration:  11700 , loss:  0.013840779\n",
      "Iteration:  11800 , loss:  0.01428332\n",
      "Iteration:  11900 , loss:  0.0138034085\n",
      "Iteration:  12000 , loss:  0.013773618\n",
      "Iteration:  12100 , loss:  0.013780372\n",
      "Iteration:  12200 , loss:  0.013735682\n",
      "Iteration:  12300 , loss:  0.013723513\n",
      "Iteration:  12400 , loss:  0.013693806\n",
      "Iteration:  12500 , loss:  0.01368551\n",
      "Iteration:  12600 , loss:  0.01461137\n",
      "Iteration:  12700 , loss:  0.013640599\n",
      "Iteration:  12800 , loss:  0.015609193\n",
      "Iteration:  12900 , loss:  0.013601074\n",
      "Iteration:  13000 , loss:  0.013698005\n",
      "Iteration:  13100 , loss:  0.013563847\n",
      "Iteration:  13200 , loss:  0.01367528\n",
      "Iteration:  13300 , loss:  0.013528986\n",
      "Iteration:  13400 , loss:  0.013538022\n",
      "Iteration:  13500 , loss:  0.013494516\n",
      "Iteration:  13600 , loss:  0.01395893\n",
      "Iteration:  13700 , loss:  0.0134615\n",
      "Iteration:  13800 , loss:  0.015394695\n",
      "Iteration:  13900 , loss:  0.013430966\n",
      "Iteration:  14000 , loss:  0.013432503\n",
      "Iteration:  14100 , loss:  0.013398761\n",
      "Iteration:  14200 , loss:  0.017148774\n",
      "Iteration:  14300 , loss:  0.01336562\n",
      "Iteration:  14400 , loss:  0.03507418\n",
      "Iteration:  14500 , loss:  0.013336102\n",
      "Iteration:  14600 , loss:  0.01331464\n",
      "Iteration:  14700 , loss:  0.013326111\n",
      "Iteration:  14800 , loss:  0.013287159\n",
      "Iteration:  14900 , loss:  0.01339034\n",
      "Iteration:  15000 , loss:  0.013258578\n",
      "Iteration:  15100 , loss:  0.013268127\n",
      "Iteration:  15200 , loss:  0.013226727\n",
      "Iteration:  15300 , loss:  0.013241189\n",
      "Iteration:  15400 , loss:  0.016917085\n",
      "Iteration:  15500 , loss:  0.013181997\n",
      "Iteration:  15600 , loss:  0.013231436\n",
      "Iteration:  15700 , loss:  0.013153056\n",
      "Iteration:  15800 , loss:  0.013145046\n",
      "Iteration:  15900 , loss:  0.01313054\n",
      "Iteration:  16000 , loss:  0.016152684\n",
      "Iteration:  16100 , loss:  0.013096691\n",
      "Iteration:  16200 , loss:  0.013149524\n",
      "Iteration:  16300 , loss:  0.01306768\n",
      "Iteration:  16400 , loss:  0.0130696315\n",
      "Iteration:  16500 , loss:  0.02617811\n",
      "Iteration:  16600 , loss:  0.013029656\n",
      "Iteration:  16700 , loss:  0.014578737\n",
      "Iteration:  16800 , loss:  0.013002073\n",
      "Iteration:  16900 , loss:  0.014372611\n",
      "Iteration:  17000 , loss:  0.0129761435\n",
      "Iteration:  17100 , loss:  0.013773615\n",
      "Iteration:  17200 , loss:  0.013936678\n",
      "Iteration:  17300 , loss:  0.012936409\n",
      "Iteration:  17400 , loss:  0.02538876\n",
      "Iteration:  17500 , loss:  0.012909815\n",
      "Iteration:  17600 , loss:  0.013398889\n",
      "Iteration:  17700 , loss:  0.012886039\n",
      "Iteration:  17800 , loss:  0.01286777\n",
      "Iteration:  17900 , loss:  0.012868281\n",
      "Iteration:  18000 , loss:  0.03193962\n",
      "Iteration:  18100 , loss:  0.012834178\n",
      "Iteration:  18200 , loss:  0.012840256\n",
      "Iteration:  18300 , loss:  0.0128123015\n",
      "Iteration:  18400 , loss:  0.012792328\n",
      "Iteration:  18500 , loss:  0.012785766\n",
      "Iteration:  18600 , loss:  0.012767271\n",
      "Iteration:  18700 , loss:  0.012772995\n",
      "Iteration:  18800 , loss:  0.01275351\n",
      "Iteration:  18900 , loss:  0.012734864\n",
      "Iteration:  19000 , loss:  0.016346216\n",
      "Iteration:  19100 , loss:  0.012709124\n",
      "Iteration:  19200 , loss:  0.013112921\n",
      "Iteration:  19300 , loss:  0.012685538\n",
      "Iteration:  19400 , loss:  0.012670637\n",
      "Iteration:  19500 , loss:  0.012663103\n",
      "Iteration:  19600 , loss:  0.012647964\n",
      "Iteration:  19700 , loss:  0.012636784\n",
      "Iteration:  19800 , loss:  0.012831141\n",
      "Iteration:  19900 , loss:  0.012610105\n",
      "Generating 4th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.5952919\n",
      "Iteration:  100 , loss:  2.1325283\n",
      "Iteration:  200 , loss:  1.6822517\n",
      "Iteration:  300 , loss:  0.96837276\n",
      "Iteration:  400 , loss:  0.3522837\n",
      "Iteration:  500 , loss:  0.22288033\n",
      "Iteration:  600 , loss:  0.16508502\n",
      "Iteration:  700 , loss:  0.13466294\n",
      "Iteration:  800 , loss:  0.11080936\n",
      "Iteration:  900 , loss:  0.1342666\n",
      "Iteration:  1000 , loss:  0.08258806\n",
      "Iteration:  1100 , loss:  0.07257066\n",
      "Iteration:  1200 , loss:  0.06533584\n",
      "Iteration:  1300 , loss:  0.059310995\n",
      "Iteration:  1400 , loss:  0.054881673\n",
      "Iteration:  1500 , loss:  0.051114418\n",
      "Iteration:  1600 , loss:  0.048341677\n",
      "Iteration:  1700 , loss:  0.045779496\n",
      "Iteration:  1800 , loss:  0.043803606\n",
      "Iteration:  1900 , loss:  0.04195014\n",
      "Iteration:  2000 , loss:  0.0404925\n",
      "Iteration:  2100 , loss:  0.03900851\n",
      "Iteration:  2200 , loss:  0.03827224\n",
      "Iteration:  2300 , loss:  0.03652124\n",
      "Iteration:  2400 , loss:  0.035703853\n",
      "Iteration:  2500 , loss:  0.034252048\n",
      "Iteration:  2600 , loss:  0.042445056\n",
      "Iteration:  2700 , loss:  0.03226468\n",
      "Iteration:  2800 , loss:  0.031297565\n",
      "Iteration:  2900 , loss:  0.03051188\n",
      "Iteration:  3000 , loss:  0.029658714\n",
      "Iteration:  3100 , loss:  0.029623024\n",
      "Iteration:  3200 , loss:  0.028192384\n",
      "Iteration:  3300 , loss:  0.029749466\n",
      "Iteration:  3400 , loss:  0.02690554\n",
      "Iteration:  3500 , loss:  0.026274148\n",
      "Iteration:  3600 , loss:  0.02575768\n",
      "Iteration:  3700 , loss:  0.025197245\n",
      "Iteration:  3800 , loss:  0.024761938\n",
      "Iteration:  3900 , loss:  0.024260478\n",
      "Iteration:  4000 , loss:  0.024970075\n",
      "Iteration:  4100 , loss:  0.023407253\n",
      "Iteration:  4200 , loss:  0.026658792\n",
      "Iteration:  4300 , loss:  0.02266946\n",
      "Iteration:  4400 , loss:  0.022291746\n",
      "Iteration:  4500 , loss:  0.022149071\n",
      "Iteration:  4600 , loss:  0.021635726\n",
      "Iteration:  4700 , loss:  0.021593893\n",
      "Iteration:  4800 , loss:  0.02104914\n",
      "Iteration:  4900 , loss:  0.020987432\n",
      "Iteration:  5000 , loss:  0.020512424\n",
      "Iteration:  5100 , loss:  0.020227753\n",
      "Iteration:  5200 , loss:  0.020068398\n",
      "Iteration:  5300 , loss:  0.019747298\n",
      "Iteration:  5400 , loss:  0.020329151\n",
      "Iteration:  5500 , loss:  0.019311693\n",
      "Iteration:  5600 , loss:  0.019973246\n",
      "Iteration:  5700 , loss:  0.018925933\n",
      "Iteration:  5800 , loss:  0.018717088\n",
      "Iteration:  5900 , loss:  0.01871785\n",
      "Iteration:  6000 , loss:  0.018372541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  6100 , loss:  0.018219449\n",
      "Iteration:  6200 , loss:  0.018078905\n",
      "Iteration:  6300 , loss:  0.017902851\n",
      "Iteration:  6400 , loss:  0.017896233\n",
      "Iteration:  6500 , loss:  0.01762246\n",
      "Iteration:  6600 , loss:  0.017459765\n",
      "Iteration:  6700 , loss:  0.017364638\n",
      "Iteration:  6800 , loss:  0.017205885\n",
      "Iteration:  6900 , loss:  0.017581038\n",
      "Iteration:  7000 , loss:  0.016967539\n",
      "Iteration:  7100 , loss:  0.017620657\n",
      "Iteration:  7200 , loss:  0.016747762\n",
      "Iteration:  7300 , loss:  0.016620273\n",
      "Iteration:  7400 , loss:  0.016628139\n",
      "Iteration:  7500 , loss:  0.016432125\n",
      "Iteration:  7600 , loss:  0.016337609\n",
      "Iteration:  7700 , loss:  0.016252682\n",
      "Iteration:  7800 , loss:  0.016131863\n",
      "Iteration:  7900 , loss:  0.016126638\n",
      "Iteration:  8000 , loss:  0.01595655\n",
      "Iteration:  8100 , loss:  0.016396143\n",
      "Iteration:  8200 , loss:  0.015791474\n",
      "Iteration:  8300 , loss:  0.02443796\n",
      "Iteration:  8400 , loss:  0.015634503\n",
      "Iteration:  8500 , loss:  0.015846714\n",
      "Iteration:  8600 , loss:  0.015494239\n",
      "Iteration:  8700 , loss:  0.015400162\n",
      "Iteration:  8800 , loss:  0.015665865\n",
      "Iteration:  8900 , loss:  0.015261061\n",
      "Iteration:  9000 , loss:  0.016982995\n",
      "Iteration:  9100 , loss:  0.015129682\n",
      "Iteration:  9200 , loss:  0.021848287\n",
      "Iteration:  9300 , loss:  0.014999304\n",
      "Iteration:  9400 , loss:  0.018508226\n",
      "Iteration:  9500 , loss:  0.014884448\n",
      "Iteration:  9600 , loss:  0.014806735\n",
      "Iteration:  9700 , loss:  0.014804043\n",
      "Iteration:  9800 , loss:  0.0146940965\n",
      "Iteration:  9900 , loss:  0.014927346\n",
      "Iteration:  10000 , loss:  0.014593733\n",
      "Iteration:  10100 , loss:  0.014560303\n",
      "Iteration:  10200 , loss:  0.014505072\n",
      "Iteration:  10300 , loss:  0.014428871\n",
      "Iteration:  10400 , loss:  0.014673715\n",
      "Iteration:  10500 , loss:  0.014335507\n",
      "Iteration:  10600 , loss:  0.015010079\n",
      "Iteration:  10700 , loss:  0.0142433075\n",
      "Iteration:  10800 , loss:  0.014331702\n",
      "Iteration:  10900 , loss:  0.014157791\n",
      "Iteration:  11000 , loss:  0.017721884\n",
      "Iteration:  11100 , loss:  0.014092867\n",
      "Iteration:  11200 , loss:  0.01402916\n",
      "Iteration:  11300 , loss:  0.014499713\n",
      "Iteration:  11400 , loss:  0.013961226\n",
      "Iteration:  11500 , loss:  0.013905994\n",
      "Iteration:  11600 , loss:  0.013920136\n",
      "Iteration:  11700 , loss:  0.013838705\n",
      "Iteration:  11800 , loss:  0.014470761\n",
      "Iteration:  11900 , loss:  0.013772384\n",
      "Iteration:  12000 , loss:  0.014895171\n",
      "Iteration:  12100 , loss:  0.013710694\n",
      "Iteration:  12200 , loss:  0.013663801\n",
      "Iteration:  12300 , loss:  0.013665189\n",
      "Iteration:  12400 , loss:  0.013601238\n",
      "Iteration:  12500 , loss:  0.013648512\n",
      "Iteration:  12600 , loss:  0.013543926\n",
      "Iteration:  12700 , loss:  0.016368868\n",
      "Iteration:  12800 , loss:  0.0134894885\n",
      "Iteration:  12900 , loss:  0.015531048\n",
      "Iteration:  13000 , loss:  0.013440653\n",
      "Iteration:  13100 , loss:  0.013391143\n",
      "Iteration:  13200 , loss:  0.013406076\n",
      "Iteration:  13300 , loss:  0.013341013\n",
      "Iteration:  13400 , loss:  0.0137502905\n",
      "Iteration:  13500 , loss:  0.013293561\n",
      "Iteration:  13600 , loss:  0.014552791\n",
      "Iteration:  13700 , loss:  0.013254365\n",
      "Iteration:  13800 , loss:  0.013207089\n",
      "Iteration:  13900 , loss:  0.013289435\n",
      "Iteration:  14000 , loss:  0.013160446\n",
      "Iteration:  14100 , loss:  0.01416784\n",
      "Iteration:  14200 , loss:  0.013116356\n",
      "Iteration:  14300 , loss:  0.014805498\n",
      "Iteration:  14400 , loss:  0.013074865\n",
      "Iteration:  14500 , loss:  0.013045493\n",
      "Iteration:  14600 , loss:  0.01303851\n",
      "Iteration:  14700 , loss:  0.012993513\n",
      "Iteration:  14800 , loss:  0.013020409\n",
      "Iteration:  14900 , loss:  0.012952806\n",
      "Iteration:  15000 , loss:  0.013553845\n",
      "Iteration:  15100 , loss:  0.012916235\n",
      "Iteration:  15200 , loss:  0.015725572\n",
      "Iteration:  15300 , loss:  0.012883185\n",
      "Iteration:  15400 , loss:  0.01325632\n",
      "Iteration:  15500 , loss:  0.042569138\n",
      "Iteration:  15600 , loss:  0.012815587\n",
      "Iteration:  15700 , loss:  0.012925686\n",
      "Iteration:  15800 , loss:  0.012782028\n",
      "Iteration:  15900 , loss:  0.012744572\n",
      "Iteration:  16000 , loss:  0.0127845025\n",
      "Iteration:  16100 , loss:  0.012709105\n",
      "Iteration:  16200 , loss:  0.013001516\n",
      "Iteration:  16300 , loss:  0.012673141\n",
      "Iteration:  16400 , loss:  0.013521042\n",
      "Iteration:  16500 , loss:  0.012637587\n",
      "Iteration:  16600 , loss:  0.014033407\n",
      "Iteration:  16700 , loss:  0.012599792\n",
      "Iteration:  16800 , loss:  0.012838234\n",
      "Iteration:  16900 , loss:  0.012561575\n",
      "Iteration:  17000 , loss:  0.012986382\n",
      "Iteration:  17100 , loss:  0.012526773\n",
      "Iteration:  17200 , loss:  0.013218353\n",
      "Iteration:  17300 , loss:  0.012491247\n",
      "Iteration:  17400 , loss:  0.014325053\n",
      "Iteration:  17500 , loss:  0.012461937\n",
      "Iteration:  17600 , loss:  0.019165386\n",
      "Iteration:  17700 , loss:  0.0124300495\n",
      "Iteration:  17800 , loss:  0.012828317\n",
      "Iteration:  17900 , loss:  0.012399413\n",
      "Iteration:  18000 , loss:  0.012368784\n",
      "Iteration:  18100 , loss:  0.012368593\n",
      "Iteration:  18200 , loss:  0.012334941\n",
      "Iteration:  18300 , loss:  0.012349286\n",
      "Iteration:  18400 , loss:  0.012304405\n",
      "Iteration:  18500 , loss:  0.012337656\n",
      "Iteration:  18600 , loss:  0.012279883\n",
      "Iteration:  18700 , loss:  0.012266051\n",
      "Iteration:  18800 , loss:  0.0130438665\n",
      "Iteration:  18900 , loss:  0.012234187\n",
      "Iteration:  19000 , loss:  0.012205148\n",
      "Iteration:  19100 , loss:  0.012229081\n",
      "Iteration:  19200 , loss:  0.012182649\n",
      "Iteration:  19300 , loss:  0.013568673\n",
      "Iteration:  19400 , loss:  0.012152774\n",
      "Iteration:  19500 , loss:  0.014809595\n",
      "Iteration:  19600 , loss:  0.01212264\n",
      "Iteration:  19700 , loss:  0.012578232\n",
      "Iteration:  19800 , loss:  0.012090273\n",
      "Iteration:  19900 , loss:  0.014462229\n",
      "Generating 5th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.766467\n",
      "Iteration:  100 , loss:  2.399388\n",
      "Iteration:  200 , loss:  1.8437641\n",
      "Iteration:  300 , loss:  1.5234704\n",
      "Iteration:  400 , loss:  0.7754653\n",
      "Iteration:  500 , loss:  0.37133095\n",
      "Iteration:  600 , loss:  0.2467956\n",
      "Iteration:  700 , loss:  0.18663895\n",
      "Iteration:  800 , loss:  0.15307106\n",
      "Iteration:  900 , loss:  0.13792464\n",
      "Iteration:  1000 , loss:  0.12112748\n",
      "Iteration:  1100 , loss:  0.11012989\n",
      "Iteration:  1200 , loss:  0.10207867\n",
      "Iteration:  1300 , loss:  0.09336418\n",
      "Iteration:  1400 , loss:  0.08626205\n",
      "Iteration:  1500 , loss:  0.07944598\n",
      "Iteration:  1600 , loss:  0.07240971\n",
      "Iteration:  1700 , loss:  0.06611179\n",
      "Iteration:  1800 , loss:  0.060352013\n",
      "Iteration:  1900 , loss:  0.055104874\n",
      "Iteration:  2000 , loss:  0.05104121\n",
      "Iteration:  2100 , loss:  0.054331787\n",
      "Iteration:  2200 , loss:  0.044470556\n",
      "Iteration:  2300 , loss:  0.046703838\n",
      "Iteration:  2400 , loss:  0.039307993\n",
      "Iteration:  2500 , loss:  0.036949698\n",
      "Iteration:  2600 , loss:  0.035084058\n",
      "Iteration:  2700 , loss:  0.033053815\n",
      "Iteration:  2800 , loss:  0.034336343\n",
      "Iteration:  2900 , loss:  0.029775122\n",
      "Iteration:  3000 , loss:  0.028804474\n",
      "Iteration:  3100 , loss:  0.027138816\n",
      "Iteration:  3200 , loss:  0.025950829\n",
      "Iteration:  3300 , loss:  0.02501521\n",
      "Iteration:  3400 , loss:  0.024051331\n",
      "Iteration:  3500 , loss:  0.02354855\n",
      "Iteration:  3600 , loss:  0.02253792\n",
      "Iteration:  3700 , loss:  0.031597503\n",
      "Iteration:  3800 , loss:  0.021273855\n",
      "Iteration:  3900 , loss:  0.027070343\n",
      "Iteration:  4000 , loss:  0.02025026\n",
      "Iteration:  4100 , loss:  0.019745141\n",
      "Iteration:  4200 , loss:  0.019454563\n",
      "Iteration:  4300 , loss:  0.018936163\n",
      "Iteration:  4400 , loss:  0.021516304\n",
      "Iteration:  4500 , loss:  0.018242212\n",
      "Iteration:  4600 , loss:  0.017965311\n",
      "Iteration:  4700 , loss:  0.017650407\n",
      "Iteration:  4800 , loss:  0.017347401\n",
      "Iteration:  4900 , loss:  0.01715292\n",
      "Iteration:  5000 , loss:  0.016870374\n",
      "Iteration:  5100 , loss:  0.016733116\n",
      "Iteration:  5200 , loss:  0.01647307\n",
      "Iteration:  5300 , loss:  0.016615473\n",
      "Iteration:  5400 , loss:  0.016150609\n",
      "Iteration:  5500 , loss:  0.019690767\n",
      "Iteration:  5600 , loss:  0.015893228\n",
      "Iteration:  5700 , loss:  0.015755381\n",
      "Iteration:  5800 , loss:  0.015679324\n",
      "Iteration:  5900 , loss:  0.0155503005\n",
      "Iteration:  6000 , loss:  0.015712485\n",
      "Iteration:  6100 , loss:  0.01536452\n",
      "Iteration:  6200 , loss:  0.0153538585\n",
      "Iteration:  6300 , loss:  0.015198855\n",
      "Iteration:  6400 , loss:  0.016219623\n",
      "Iteration:  6500 , loss:  0.015047878\n",
      "Iteration:  6600 , loss:  0.020553764\n",
      "Iteration:  6700 , loss:  0.0149130635\n",
      "Iteration:  6800 , loss:  0.014975696\n",
      "Iteration:  6900 , loss:  0.014793579\n",
      "Iteration:  7000 , loss:  0.014712105\n",
      "Iteration:  7100 , loss:  0.014703946\n",
      "Iteration:  7200 , loss:  0.014598793\n",
      "Iteration:  7300 , loss:  0.014744115\n",
      "Iteration:  7400 , loss:  0.014491835\n",
      "Iteration:  7500 , loss:  0.015458298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  7600 , loss:  0.0143903205\n",
      "Iteration:  7700 , loss:  0.01461857\n",
      "Iteration:  7800 , loss:  0.014304964\n",
      "Iteration:  7900 , loss:  0.014238087\n",
      "Iteration:  8000 , loss:  0.014857622\n",
      "Iteration:  8100 , loss:  0.014154162\n",
      "Iteration:  8200 , loss:  0.0140965255\n",
      "Iteration:  8300 , loss:  0.014079895\n",
      "Iteration:  8400 , loss:  0.0140108615\n",
      "Iteration:  8500 , loss:  0.015008467\n",
      "Iteration:  8600 , loss:  0.01393559\n",
      "Iteration:  8700 , loss:  0.047212042\n",
      "Iteration:  8800 , loss:  0.013871428\n",
      "Iteration:  8900 , loss:  0.013826785\n",
      "Iteration:  9000 , loss:  0.013853692\n",
      "Iteration:  9100 , loss:  0.013775902\n",
      "Iteration:  9200 , loss:  0.016081672\n",
      "Iteration:  9300 , loss:  0.01373122\n",
      "Iteration:  9400 , loss:  0.013691677\n",
      "Iteration:  9500 , loss:  0.013755191\n",
      "Iteration:  9600 , loss:  0.013651732\n",
      "Iteration:  9700 , loss:  0.013620533\n",
      "Iteration:  9800 , loss:  0.013620532\n",
      "Iteration:  9900 , loss:  0.01357588\n",
      "Iteration:  10000 , loss:  0.014057605\n",
      "Iteration:  10100 , loss:  0.013548616\n",
      "Iteration:  10200 , loss:  0.0135177\n",
      "Iteration:  10300 , loss:  0.014005529\n",
      "Iteration:  10400 , loss:  0.013479654\n",
      "Iteration:  10500 , loss:  0.0145891085\n",
      "Iteration:  10600 , loss:  0.013447288\n",
      "Iteration:  10700 , loss:  0.013483521\n",
      "Iteration:  10800 , loss:  0.0134167075\n",
      "Iteration:  10900 , loss:  0.01338335\n",
      "Iteration:  11000 , loss:  0.013392196\n",
      "Iteration:  11100 , loss:  0.013354231\n",
      "Iteration:  11200 , loss:  0.0143145025\n",
      "Iteration:  11300 , loss:  0.013327024\n",
      "Iteration:  11400 , loss:  0.013300629\n",
      "Iteration:  11500 , loss:  0.013310538\n",
      "Iteration:  11600 , loss:  0.01326854\n",
      "Iteration:  11700 , loss:  0.013308593\n",
      "Iteration:  11800 , loss:  0.0132377725\n",
      "Iteration:  11900 , loss:  0.013244137\n",
      "Iteration:  12000 , loss:  0.01320664\n",
      "Iteration:  12100 , loss:  0.013308639\n",
      "Iteration:  12200 , loss:  0.013182153\n",
      "Iteration:  12300 , loss:  0.0184108\n",
      "Iteration:  12400 , loss:  0.0131549835\n",
      "Iteration:  12500 , loss:  0.019203868\n",
      "Iteration:  12600 , loss:  0.013131297\n",
      "Iteration:  12700 , loss:  0.013104032\n",
      "Iteration:  12800 , loss:  0.013111284\n",
      "Iteration:  12900 , loss:  0.013077421\n",
      "Iteration:  13000 , loss:  0.013119934\n",
      "Iteration:  13100 , loss:  0.013050557\n",
      "Iteration:  13200 , loss:  0.013186488\n",
      "Iteration:  13300 , loss:  0.013028907\n",
      "Iteration:  13400 , loss:  0.01349439\n",
      "Iteration:  13500 , loss:  0.013014993\n",
      "Iteration:  13600 , loss:  0.012985313\n",
      "Iteration:  13700 , loss:  0.013116322\n",
      "Iteration:  13800 , loss:  0.012963592\n",
      "Iteration:  13900 , loss:  0.045807593\n",
      "Iteration:  14000 , loss:  0.012945676\n",
      "Iteration:  14100 , loss:  0.012920519\n",
      "Iteration:  14200 , loss:  0.012956287\n",
      "Iteration:  14300 , loss:  0.012900756\n",
      "Iteration:  14400 , loss:  0.013765117\n",
      "Iteration:  14500 , loss:  0.01288456\n",
      "Iteration:  14600 , loss:  0.012860591\n",
      "Iteration:  14700 , loss:  0.012882963\n",
      "Iteration:  14800 , loss:  0.01283715\n",
      "Iteration:  14900 , loss:  0.012902569\n",
      "Iteration:  15000 , loss:  0.012813959\n",
      "Iteration:  15100 , loss:  0.012863828\n",
      "Iteration:  15200 , loss:  0.01279239\n",
      "Iteration:  15300 , loss:  0.013943954\n",
      "Iteration:  15400 , loss:  0.012776967\n",
      "Iteration:  15500 , loss:  0.012755606\n",
      "Iteration:  15600 , loss:  0.012798928\n",
      "Iteration:  15700 , loss:  0.012739021\n",
      "Iteration:  15800 , loss:  0.040012307\n",
      "Iteration:  15900 , loss:  0.012722241\n",
      "Iteration:  16000 , loss:  0.01270038\n",
      "Iteration:  16100 , loss:  0.012716185\n",
      "Iteration:  16200 , loss:  0.01268102\n",
      "Iteration:  16300 , loss:  0.012944133\n",
      "Iteration:  16400 , loss:  0.012665568\n",
      "Iteration:  16500 , loss:  0.01300028\n",
      "Iteration:  16600 , loss:  0.012648424\n",
      "Iteration:  16700 , loss:  0.012636657\n",
      "Iteration:  16800 , loss:  0.012629423\n",
      "Iteration:  16900 , loss:  0.0126311835\n",
      "Iteration:  17000 , loss:  0.012609082\n",
      "Iteration:  17100 , loss:  0.012585409\n",
      "Iteration:  17200 , loss:  0.012598361\n",
      "Iteration:  17300 , loss:  0.012566045\n",
      "Iteration:  17400 , loss:  0.012584701\n",
      "Iteration:  17500 , loss:  0.0125468075\n",
      "Iteration:  17600 , loss:  0.012675569\n",
      "Iteration:  17700 , loss:  0.012529129\n",
      "Iteration:  17800 , loss:  0.013329534\n",
      "Iteration:  17900 , loss:  0.012512157\n",
      "Iteration:  18000 , loss:  0.02541849\n",
      "Iteration:  18100 , loss:  0.012494434\n",
      "Iteration:  18200 , loss:  0.017111743\n",
      "Iteration:  18300 , loss:  0.012480019\n",
      "Iteration:  18400 , loss:  0.012458546\n",
      "Iteration:  18500 , loss:  0.012490398\n",
      "Iteration:  18600 , loss:  0.01244171\n",
      "Iteration:  18700 , loss:  0.012492889\n",
      "Iteration:  18800 , loss:  0.012425024\n",
      "Iteration:  18900 , loss:  0.014148073\n",
      "Iteration:  19000 , loss:  0.012404456\n",
      "Iteration:  19100 , loss:  0.012556258\n",
      "Iteration:  19200 , loss:  0.012385681\n",
      "Iteration:  19300 , loss:  0.012428073\n",
      "Iteration:  19400 , loss:  0.012365563\n",
      "Iteration:  19500 , loss:  0.012384772\n",
      "Iteration:  19600 , loss:  0.01235131\n",
      "Iteration:  19700 , loss:  0.013136225\n",
      "Iteration:  19800 , loss:  0.012334246\n",
      "Iteration:  19900 , loss:  0.012397951\n",
      "Generating 6th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.7380562\n",
      "Iteration:  100 , loss:  2.4039993\n",
      "Iteration:  200 , loss:  1.855154\n",
      "Iteration:  300 , loss:  1.5329922\n",
      "Iteration:  400 , loss:  0.93561995\n",
      "Iteration:  500 , loss:  0.4331654\n",
      "Iteration:  600 , loss:  0.2447979\n",
      "Iteration:  700 , loss:  0.17438158\n",
      "Iteration:  800 , loss:  0.13749415\n",
      "Iteration:  900 , loss:  0.110938214\n",
      "Iteration:  1000 , loss:  0.09908743\n",
      "Iteration:  1100 , loss:  0.08345833\n",
      "Iteration:  1200 , loss:  0.07110688\n",
      "Iteration:  1300 , loss:  0.06212247\n",
      "Iteration:  1400 , loss:  0.054759506\n",
      "Iteration:  1500 , loss:  0.051254466\n",
      "Iteration:  1600 , loss:  0.043663003\n",
      "Iteration:  1700 , loss:  0.03984054\n",
      "Iteration:  1800 , loss:  0.036307547\n",
      "Iteration:  1900 , loss:  0.033681646\n",
      "Iteration:  2000 , loss:  0.031256326\n",
      "Iteration:  2100 , loss:  0.029435761\n",
      "Iteration:  2200 , loss:  0.027695276\n",
      "Iteration:  2300 , loss:  0.02648709\n",
      "Iteration:  2400 , loss:  0.025143933\n",
      "Iteration:  2500 , loss:  0.024044868\n",
      "Iteration:  2600 , loss:  0.023229714\n",
      "Iteration:  2700 , loss:  0.02241364\n",
      "Iteration:  2800 , loss:  0.022178669\n",
      "Iteration:  2900 , loss:  0.021184463\n",
      "Iteration:  3000 , loss:  0.020632895\n",
      "Iteration:  3100 , loss:  0.020233577\n",
      "Iteration:  3200 , loss:  0.019791527\n",
      "Iteration:  3300 , loss:  0.02264428\n",
      "Iteration:  3400 , loss:  0.019103415\n",
      "Iteration:  3500 , loss:  0.022225004\n",
      "Iteration:  3600 , loss:  0.018537695\n",
      "Iteration:  3700 , loss:  0.018341046\n",
      "Iteration:  3800 , loss:  0.01806126\n",
      "Iteration:  3900 , loss:  0.017821893\n",
      "Iteration:  4000 , loss:  0.01766178\n",
      "Iteration:  4100 , loss:  0.017443312\n",
      "Iteration:  4200 , loss:  0.01751655\n",
      "Iteration:  4300 , loss:  0.01711179\n",
      "Iteration:  4400 , loss:  0.021833457\n",
      "Iteration:  4500 , loss:  0.016815962\n",
      "Iteration:  4600 , loss:  0.019054584\n",
      "Iteration:  4700 , loss:  0.016548915\n",
      "Iteration:  4800 , loss:  0.016403586\n",
      "Iteration:  4900 , loss:  0.016319819\n",
      "Iteration:  5000 , loss:  0.0161726\n",
      "Iteration:  5100 , loss:  0.016154852\n",
      "Iteration:  5200 , loss:  0.01596727\n",
      "Iteration:  5300 , loss:  0.021026004\n",
      "Iteration:  5400 , loss:  0.01578115\n",
      "Iteration:  5500 , loss:  0.015671909\n",
      "Iteration:  5600 , loss:  0.015619822\n",
      "Iteration:  5700 , loss:  0.015510542\n",
      "Iteration:  5800 , loss:  0.016212411\n",
      "Iteration:  5900 , loss:  0.015362761\n",
      "Iteration:  6000 , loss:  0.015271952\n",
      "Iteration:  6100 , loss:  0.0152331125\n",
      "Iteration:  6200 , loss:  0.015140731\n",
      "Iteration:  6300 , loss:  0.017001625\n",
      "Iteration:  6400 , loss:  0.015015446\n",
      "Iteration:  6500 , loss:  0.019965572\n",
      "Iteration:  6600 , loss:  0.014905184\n",
      "Iteration:  6700 , loss:  0.014830493\n",
      "Iteration:  6800 , loss:  0.0148717165\n",
      "Iteration:  6900 , loss:  0.014724504\n",
      "Iteration:  7000 , loss:  0.014976304\n",
      "Iteration:  7100 , loss:  0.014627086\n",
      "Iteration:  7200 , loss:  0.015096722\n",
      "Iteration:  7300 , loss:  0.014539917\n",
      "Iteration:  7400 , loss:  0.014481334\n",
      "Iteration:  7500 , loss:  0.01448421\n",
      "Iteration:  7600 , loss:  0.014408622\n",
      "Iteration:  7700 , loss:  0.042723283\n",
      "Iteration:  7800 , loss:  0.014334956\n",
      "Iteration:  7900 , loss:  0.014281981\n",
      "Iteration:  8000 , loss:  0.014271706\n",
      "Iteration:  8100 , loss:  0.014211405\n",
      "Iteration:  8200 , loss:  0.014459991\n",
      "Iteration:  8300 , loss:  0.014150168\n",
      "Iteration:  8400 , loss:  0.015004462\n",
      "Iteration:  8500 , loss:  0.014092807\n",
      "Iteration:  8600 , loss:  0.014045456\n",
      "Iteration:  8700 , loss:  0.014111113\n",
      "Iteration:  8800 , loss:  0.013991294\n",
      "Iteration:  8900 , loss:  0.023596294\n",
      "Iteration:  9000 , loss:  0.013936422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  9100 , loss:  0.013903583\n",
      "Iteration:  9200 , loss:  0.013902229\n",
      "Iteration:  9300 , loss:  0.013851442\n",
      "Iteration:  9400 , loss:  0.019901995\n",
      "Iteration:  9500 , loss:  0.013805989\n",
      "Iteration:  9600 , loss:  0.013768217\n",
      "Iteration:  9700 , loss:  0.013776708\n",
      "Iteration:  9800 , loss:  0.013725431\n",
      "Iteration:  9900 , loss:  0.013992773\n",
      "Iteration:  10000 , loss:  0.013683112\n",
      "Iteration:  10100 , loss:  0.029178888\n",
      "Iteration:  10200 , loss:  0.013643438\n",
      "Iteration:  10300 , loss:  0.013607963\n",
      "Iteration:  10400 , loss:  0.013621989\n",
      "Iteration:  10500 , loss:  0.01357062\n",
      "Iteration:  10600 , loss:  0.014737617\n",
      "Iteration:  10700 , loss:  0.01353428\n",
      "Iteration:  10800 , loss:  0.013516217\n",
      "Iteration:  10900 , loss:  0.0135058835\n",
      "Iteration:  11000 , loss:  0.013467837\n",
      "Iteration:  11100 , loss:  0.014397433\n",
      "Iteration:  11200 , loss:  0.013436737\n",
      "Iteration:  11300 , loss:  0.013408007\n",
      "Iteration:  11400 , loss:  0.013411913\n",
      "Iteration:  11500 , loss:  0.01337144\n",
      "Iteration:  11600 , loss:  0.013522134\n",
      "Iteration:  11700 , loss:  0.013338352\n",
      "Iteration:  11800 , loss:  0.023510851\n",
      "Iteration:  11900 , loss:  0.01330889\n",
      "Iteration:  12000 , loss:  0.013277618\n",
      "Iteration:  12100 , loss:  0.013348466\n",
      "Iteration:  12200 , loss:  0.013246598\n",
      "Iteration:  12300 , loss:  0.016286053\n",
      "Iteration:  12400 , loss:  0.0132159535\n",
      "Iteration:  12500 , loss:  0.013186183\n",
      "Iteration:  12600 , loss:  0.013200094\n",
      "Iteration:  12700 , loss:  0.013151957\n",
      "Iteration:  12800 , loss:  0.013319185\n",
      "Iteration:  12900 , loss:  0.013113043\n",
      "Iteration:  13000 , loss:  0.013137827\n",
      "Iteration:  13100 , loss:  0.013614501\n",
      "Iteration:  13200 , loss:  0.0130571835\n",
      "Iteration:  13300 , loss:  0.013625542\n",
      "Iteration:  13400 , loss:  0.01301819\n",
      "Iteration:  13500 , loss:  0.013503466\n",
      "Iteration:  13600 , loss:  0.0129751535\n",
      "Iteration:  13700 , loss:  0.013214154\n",
      "Iteration:  13800 , loss:  0.012936787\n",
      "Iteration:  13900 , loss:  0.01801867\n",
      "Iteration:  14000 , loss:  0.012897573\n",
      "Iteration:  14100 , loss:  0.013129512\n",
      "Iteration:  14200 , loss:  0.012855159\n",
      "Iteration:  14300 , loss:  0.012831918\n",
      "Iteration:  14400 , loss:  0.014098646\n",
      "Iteration:  14500 , loss:  0.012778024\n",
      "Iteration:  14600 , loss:  0.012861542\n",
      "Iteration:  14700 , loss:  0.012726983\n",
      "Iteration:  14800 , loss:  0.012741933\n",
      "Iteration:  14900 , loss:  0.012676816\n",
      "Iteration:  15000 , loss:  0.012678133\n",
      "Iteration:  15100 , loss:  0.012630051\n",
      "Iteration:  15200 , loss:  0.013004122\n",
      "Iteration:  15300 , loss:  0.012576444\n",
      "Iteration:  15400 , loss:  0.012639897\n",
      "Iteration:  15500 , loss:  0.012531576\n",
      "Iteration:  15600 , loss:  0.02266043\n",
      "Iteration:  15700 , loss:  0.012482602\n",
      "Iteration:  15800 , loss:  0.012802541\n",
      "Iteration:  15900 , loss:  0.012502415\n",
      "Iteration:  16000 , loss:  0.012400858\n",
      "Iteration:  16100 , loss:  0.012405215\n",
      "Iteration:  16200 , loss:  0.012353187\n",
      "Iteration:  16300 , loss:  0.012390623\n",
      "Iteration:  16400 , loss:  0.01230493\n",
      "Iteration:  16500 , loss:  0.012286344\n",
      "Iteration:  16600 , loss:  0.012390681\n",
      "Iteration:  16700 , loss:  0.012240017\n",
      "Iteration:  16800 , loss:  0.012269108\n",
      "Iteration:  16900 , loss:  0.012198821\n",
      "Iteration:  17000 , loss:  0.012191039\n",
      "Iteration:  17100 , loss:  0.012223961\n",
      "Iteration:  17200 , loss:  0.012399237\n",
      "Iteration:  17300 , loss:  0.012123261\n",
      "Iteration:  17400 , loss:  0.012181572\n",
      "Iteration:  17500 , loss:  0.012083465\n",
      "Iteration:  17600 , loss:  0.012082791\n",
      "Iteration:  17700 , loss:  0.0120481895\n",
      "Iteration:  17800 , loss:  0.01205559\n",
      "Iteration:  17900 , loss:  0.012018525\n",
      "Iteration:  18000 , loss:  0.012045746\n",
      "Iteration:  18100 , loss:  0.011987435\n",
      "Iteration:  18200 , loss:  0.0119754905\n",
      "Iteration:  18300 , loss:  0.012486633\n",
      "Iteration:  18400 , loss:  0.01195986\n",
      "Iteration:  18500 , loss:  0.012754639\n",
      "Iteration:  18600 , loss:  0.0119001325\n",
      "Iteration:  18700 , loss:  0.01195138\n",
      "Iteration:  18800 , loss:  0.015340451\n",
      "Iteration:  18900 , loss:  0.017758638\n",
      "Iteration:  19000 , loss:  0.011839433\n",
      "Iteration:  19100 , loss:  0.013441497\n",
      "Iteration:  19200 , loss:  0.011808308\n",
      "Iteration:  19300 , loss:  0.011847254\n",
      "Iteration:  19400 , loss:  0.011775324\n",
      "Iteration:  19500 , loss:  0.011774397\n",
      "Iteration:  19600 , loss:  0.011809475\n",
      "Iteration:  19700 , loss:  0.01640484\n",
      "Iteration:  19800 , loss:  0.011711449\n",
      "Iteration:  19900 , loss:  0.012050223\n",
      "Generating 7th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.8503969\n",
      "Iteration:  100 , loss:  2.43327\n",
      "Iteration:  200 , loss:  1.8921255\n",
      "Iteration:  300 , loss:  1.5125425\n",
      "Iteration:  400 , loss:  0.8846839\n",
      "Iteration:  500 , loss:  0.41935632\n",
      "Iteration:  600 , loss:  0.28170896\n",
      "Iteration:  700 , loss:  0.21721864\n",
      "Iteration:  800 , loss:  0.17156236\n",
      "Iteration:  900 , loss:  0.15114763\n",
      "Iteration:  1000 , loss:  0.11936761\n",
      "Iteration:  1100 , loss:  0.10365609\n",
      "Iteration:  1200 , loss:  0.09341884\n",
      "Iteration:  1300 , loss:  0.08167606\n",
      "Iteration:  1400 , loss:  0.07331188\n",
      "Iteration:  1500 , loss:  0.06651969\n",
      "Iteration:  1600 , loss:  0.061347567\n",
      "Iteration:  1700 , loss:  0.05564501\n",
      "Iteration:  1800 , loss:  0.051905017\n",
      "Iteration:  1900 , loss:  0.04825585\n",
      "Iteration:  2000 , loss:  0.04571302\n",
      "Iteration:  2100 , loss:  0.04225912\n",
      "Iteration:  2200 , loss:  0.040315766\n",
      "Iteration:  2300 , loss:  0.03736667\n",
      "Iteration:  2400 , loss:  0.057506483\n",
      "Iteration:  2500 , loss:  0.03326907\n",
      "Iteration:  2600 , loss:  0.059813637\n",
      "Iteration:  2700 , loss:  0.029894833\n",
      "Iteration:  2800 , loss:  0.028484967\n",
      "Iteration:  2900 , loss:  0.027177693\n",
      "Iteration:  3000 , loss:  0.025951482\n",
      "Iteration:  3100 , loss:  0.025084432\n",
      "Iteration:  3200 , loss:  0.024002858\n",
      "Iteration:  3300 , loss:  0.023629403\n",
      "Iteration:  3400 , loss:  0.022449303\n",
      "Iteration:  3500 , loss:  0.023625942\n",
      "Iteration:  3600 , loss:  0.021221135\n",
      "Iteration:  3700 , loss:  0.026589239\n",
      "Iteration:  3800 , loss:  0.020248983\n",
      "Iteration:  3900 , loss:  0.021027448\n",
      "Iteration:  4000 , loss:  0.019485777\n",
      "Iteration:  4100 , loss:  0.01910509\n",
      "Iteration:  4200 , loss:  0.018896878\n",
      "Iteration:  4300 , loss:  0.018550187\n",
      "Iteration:  4400 , loss:  0.051339258\n",
      "Iteration:  4500 , loss:  0.018066674\n",
      "Iteration:  4600 , loss:  0.017814852\n",
      "Iteration:  4700 , loss:  0.017661212\n",
      "Iteration:  4800 , loss:  0.017427985\n",
      "Iteration:  4900 , loss:  0.01733381\n",
      "Iteration:  5000 , loss:  0.017088413\n",
      "Iteration:  5100 , loss:  0.017174497\n",
      "Iteration:  5200 , loss:  0.016818611\n",
      "Iteration:  5300 , loss:  0.016650833\n",
      "Iteration:  5400 , loss:  0.016741242\n",
      "Iteration:  5500 , loss:  0.016409442\n",
      "Iteration:  5600 , loss:  0.04696359\n",
      "Iteration:  5700 , loss:  0.016201444\n",
      "Iteration:  5800 , loss:  0.01606591\n",
      "Iteration:  5900 , loss:  0.016195722\n",
      "Iteration:  6000 , loss:  0.0158788\n",
      "Iteration:  6100 , loss:  0.0197858\n",
      "Iteration:  6200 , loss:  0.015705619\n",
      "Iteration:  6300 , loss:  0.0156023\n",
      "Iteration:  6400 , loss:  0.015561577\n",
      "Iteration:  6500 , loss:  0.015451101\n",
      "Iteration:  6600 , loss:  0.015620749\n",
      "Iteration:  6700 , loss:  0.015314616\n",
      "Iteration:  6800 , loss:  0.0152263045\n",
      "Iteration:  6900 , loss:  0.015193373\n",
      "Iteration:  7000 , loss:  0.015089408\n",
      "Iteration:  7100 , loss:  0.015165299\n",
      "Iteration:  7200 , loss:  0.014969768\n",
      "Iteration:  7300 , loss:  0.01635003\n",
      "Iteration:  7400 , loss:  0.014848296\n",
      "Iteration:  7500 , loss:  0.015705813\n",
      "Iteration:  7600 , loss:  0.014736586\n",
      "Iteration:  7700 , loss:  0.014650015\n",
      "Iteration:  7800 , loss:  0.014646048\n",
      "Iteration:  7900 , loss:  0.014538616\n",
      "Iteration:  8000 , loss:  0.03393522\n",
      "Iteration:  8100 , loss:  0.014462855\n",
      "Iteration:  8200 , loss:  0.01437225\n",
      "Iteration:  8300 , loss:  0.014294989\n",
      "Iteration:  8400 , loss:  0.014315151\n",
      "Iteration:  8500 , loss:  0.01418083\n",
      "Iteration:  8600 , loss:  0.015476025\n",
      "Iteration:  8700 , loss:  0.014060945\n",
      "Iteration:  8800 , loss:  0.015106371\n",
      "Iteration:  8900 , loss:  0.013946019\n",
      "Iteration:  9000 , loss:  0.013860559\n",
      "Iteration:  9100 , loss:  0.013859907\n",
      "Iteration:  9200 , loss:  0.013741225\n",
      "Iteration:  9300 , loss:  0.016362874\n",
      "Iteration:  9400 , loss:  0.013616507\n",
      "Iteration:  9500 , loss:  0.013566437\n",
      "Iteration:  9600 , loss:  0.013496815\n",
      "Iteration:  9700 , loss:  0.013403944\n",
      "Iteration:  9800 , loss:  0.013409159\n",
      "Iteration:  9900 , loss:  0.013278941\n",
      "Iteration:  10000 , loss:  0.0151655\n",
      "Iteration:  10100 , loss:  0.013173115\n",
      "Iteration:  10200 , loss:  0.013090092\n",
      "Iteration:  10300 , loss:  0.013182435\n",
      "Iteration:  10400 , loss:  0.0133730415\n",
      "Iteration:  10500 , loss:  0.012933571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  10600 , loss:  0.012860108\n",
      "Iteration:  10700 , loss:  0.012836637\n",
      "Iteration:  10800 , loss:  0.012757141\n",
      "Iteration:  10900 , loss:  0.012893753\n",
      "Iteration:  11000 , loss:  0.012671695\n",
      "Iteration:  11100 , loss:  0.024418183\n",
      "Iteration:  11200 , loss:  0.012584824\n",
      "Iteration:  11300 , loss:  0.012548186\n",
      "Iteration:  11400 , loss:  0.012516493\n",
      "Iteration:  11500 , loss:  0.012450214\n",
      "Iteration:  11600 , loss:  0.012533718\n",
      "Iteration:  11700 , loss:  0.012384224\n",
      "Iteration:  11800 , loss:  0.018095233\n",
      "Iteration:  11900 , loss:  0.01231723\n",
      "Iteration:  12000 , loss:  0.012262682\n",
      "Iteration:  12100 , loss:  0.01226306\n",
      "Iteration:  12200 , loss:  0.012204395\n",
      "Iteration:  12300 , loss:  0.012661046\n",
      "Iteration:  12400 , loss:  0.01217737\n",
      "Iteration:  12500 , loss:  0.012124637\n",
      "Iteration:  12600 , loss:  0.012135322\n",
      "Iteration:  12700 , loss:  0.01207201\n",
      "Iteration:  12800 , loss:  0.012026548\n",
      "Iteration:  12900 , loss:  0.012022629\n",
      "Iteration:  13000 , loss:  0.012502847\n",
      "Iteration:  13100 , loss:  0.02265551\n",
      "Iteration:  13200 , loss:  0.01192282\n",
      "Iteration:  13300 , loss:  0.012051053\n",
      "Iteration:  13400 , loss:  0.011871895\n",
      "Iteration:  13500 , loss:  0.0120635955\n",
      "Iteration:  13600 , loss:  0.011826003\n",
      "Iteration:  13700 , loss:  0.012980185\n",
      "Iteration:  13800 , loss:  0.011874281\n",
      "Iteration:  13900 , loss:  0.011764124\n",
      "Iteration:  14000 , loss:  0.011956068\n",
      "Iteration:  14100 , loss:  0.011707911\n",
      "Iteration:  14200 , loss:  0.011707903\n",
      "Iteration:  14300 , loss:  0.011663055\n",
      "Iteration:  14400 , loss:  0.011681188\n",
      "Iteration:  14500 , loss:  0.011630075\n",
      "Iteration:  14600 , loss:  0.012127344\n",
      "Iteration:  14700 , loss:  0.0115983905\n",
      "Iteration:  14800 , loss:  0.011576505\n",
      "Iteration:  14900 , loss:  0.011568531\n",
      "Iteration:  15000 , loss:  0.011818472\n",
      "Iteration:  15100 , loss:  0.01151781\n",
      "Iteration:  15200 , loss:  0.011574662\n",
      "Iteration:  15300 , loss:  0.0115167955\n",
      "Iteration:  15400 , loss:  0.011483904\n",
      "Iteration:  15500 , loss:  0.011445632\n",
      "Iteration:  15600 , loss:  0.0114476895\n",
      "Iteration:  15700 , loss:  0.011425843\n",
      "Iteration:  15800 , loss:  0.011422141\n",
      "Iteration:  15900 , loss:  0.011385696\n",
      "Iteration:  16000 , loss:  0.011373062\n",
      "Iteration:  16100 , loss:  0.011671349\n",
      "Iteration:  16200 , loss:  0.011340557\n",
      "Iteration:  16300 , loss:  0.011531137\n",
      "Iteration:  16400 , loss:  0.011310287\n",
      "Iteration:  16500 , loss:  0.011538578\n",
      "Iteration:  16600 , loss:  0.011286505\n",
      "Iteration:  16700 , loss:  0.012888169\n",
      "Iteration:  16800 , loss:  0.011254806\n",
      "Iteration:  16900 , loss:  0.011802519\n",
      "Iteration:  17000 , loss:  0.011236405\n",
      "Iteration:  17100 , loss:  0.01324572\n",
      "Iteration:  17200 , loss:  0.011196718\n",
      "Iteration:  17300 , loss:  0.011223432\n",
      "Iteration:  17400 , loss:  0.011170432\n",
      "Iteration:  17500 , loss:  0.011210022\n",
      "Iteration:  17600 , loss:  0.0111558465\n",
      "Iteration:  17700 , loss:  0.01119303\n",
      "Iteration:  17800 , loss:  0.01112844\n",
      "Iteration:  17900 , loss:  0.011162292\n",
      "Iteration:  18000 , loss:  0.011100116\n",
      "Iteration:  18100 , loss:  0.011099749\n",
      "Iteration:  18200 , loss:  0.011102254\n",
      "Iteration:  18300 , loss:  0.033015158\n",
      "Iteration:  18400 , loss:  0.011064559\n",
      "Iteration:  18500 , loss:  0.011830409\n",
      "Iteration:  18600 , loss:  0.011283487\n",
      "Iteration:  18700 , loss:  0.014506163\n",
      "Iteration:  18800 , loss:  0.011013355\n",
      "Iteration:  18900 , loss:  0.011126107\n",
      "Iteration:  19000 , loss:  0.010996212\n",
      "Iteration:  19100 , loss:  0.010995185\n",
      "Iteration:  19200 , loss:  0.017515201\n",
      "Iteration:  19300 , loss:  0.01990746\n",
      "Iteration:  19400 , loss:  0.010952469\n",
      "Iteration:  19500 , loss:  0.011309156\n",
      "Iteration:  19600 , loss:  0.010938799\n",
      "Iteration:  19700 , loss:  0.011074191\n",
      "Iteration:  19800 , loss:  0.010914042\n",
      "Iteration:  19900 , loss:  0.010921566\n",
      "Generating 8th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.8152657\n",
      "Iteration:  100 , loss:  2.3755562\n",
      "Iteration:  200 , loss:  1.8204055\n",
      "Iteration:  300 , loss:  1.4112659\n",
      "Iteration:  400 , loss:  0.6771599\n",
      "Iteration:  500 , loss:  0.39380145\n",
      "Iteration:  600 , loss:  0.25877517\n",
      "Iteration:  700 , loss:  0.18637508\n",
      "Iteration:  800 , loss:  0.15439932\n",
      "Iteration:  900 , loss:  0.12993021\n",
      "Iteration:  1000 , loss:  0.11411753\n",
      "Iteration:  1100 , loss:  0.1002914\n",
      "Iteration:  1200 , loss:  0.08591598\n",
      "Iteration:  1300 , loss:  0.07651201\n",
      "Iteration:  1400 , loss:  0.06838705\n",
      "Iteration:  1500 , loss:  0.06203926\n",
      "Iteration:  1600 , loss:  0.07287\n",
      "Iteration:  1700 , loss:  0.050045602\n",
      "Iteration:  1800 , loss:  0.04567777\n",
      "Iteration:  1900 , loss:  0.04239555\n",
      "Iteration:  2000 , loss:  0.038653135\n",
      "Iteration:  2100 , loss:  0.03751566\n",
      "Iteration:  2200 , loss:  0.033629533\n",
      "Iteration:  2300 , loss:  0.03177409\n",
      "Iteration:  2400 , loss:  0.030098297\n",
      "Iteration:  2500 , loss:  0.030021403\n",
      "Iteration:  2600 , loss:  0.027546663\n",
      "Iteration:  2700 , loss:  0.03437034\n",
      "Iteration:  2800 , loss:  0.025641058\n",
      "Iteration:  2900 , loss:  0.024829367\n",
      "Iteration:  3000 , loss:  0.02417131\n",
      "Iteration:  3100 , loss:  0.023508674\n",
      "Iteration:  3200 , loss:  0.023022722\n",
      "Iteration:  3300 , loss:  0.022457663\n",
      "Iteration:  3400 , loss:  0.022977479\n",
      "Iteration:  3500 , loss:  0.021597462\n",
      "Iteration:  3600 , loss:  0.040972255\n",
      "Iteration:  3700 , loss:  0.0208702\n",
      "Iteration:  3800 , loss:  0.020534469\n",
      "Iteration:  3900 , loss:  0.020264875\n",
      "Iteration:  4000 , loss:  0.019954331\n",
      "Iteration:  4100 , loss:  0.020266911\n",
      "Iteration:  4200 , loss:  0.019454459\n",
      "Iteration:  4300 , loss:  0.02417327\n",
      "Iteration:  4400 , loss:  0.019018972\n",
      "Iteration:  4500 , loss:  0.018796148\n",
      "Iteration:  4600 , loss:  0.018666081\n",
      "Iteration:  4700 , loss:  0.01845054\n",
      "Iteration:  4800 , loss:  0.018263653\n",
      "Iteration:  4900 , loss:  0.018326694\n",
      "Iteration:  5000 , loss:  0.017960247\n",
      "Iteration:  5100 , loss:  0.019259019\n",
      "Iteration:  5200 , loss:  0.017677395\n",
      "Iteration:  5300 , loss:  0.017524116\n",
      "Iteration:  5400 , loss:  0.017419487\n",
      "Iteration:  5500 , loss:  0.0172754\n",
      "Iteration:  5600 , loss:  0.017620431\n",
      "Iteration:  5700 , loss:  0.017047582\n",
      "Iteration:  5800 , loss:  0.018628929\n",
      "Iteration:  5900 , loss:  0.016821861\n",
      "Iteration:  6000 , loss:  0.01781651\n",
      "Iteration:  6100 , loss:  0.016625235\n",
      "Iteration:  6200 , loss:  0.016523868\n",
      "Iteration:  6300 , loss:  0.01644194\n",
      "Iteration:  6400 , loss:  0.016335446\n",
      "Iteration:  6500 , loss:  0.0168027\n",
      "Iteration:  6600 , loss:  0.016163198\n",
      "Iteration:  6700 , loss:  0.054066785\n",
      "Iteration:  6800 , loss:  0.016005434\n",
      "Iteration:  6900 , loss:  0.015912313\n",
      "Iteration:  7000 , loss:  0.015870081\n",
      "Iteration:  7100 , loss:  0.015757062\n",
      "Iteration:  7200 , loss:  0.018778153\n",
      "Iteration:  7300 , loss:  0.015608635\n",
      "Iteration:  7400 , loss:  0.015542811\n",
      "Iteration:  7500 , loss:  0.015472726\n",
      "Iteration:  7600 , loss:  0.015381664\n",
      "Iteration:  7700 , loss:  0.015473042\n",
      "Iteration:  7800 , loss:  0.015240318\n",
      "Iteration:  7900 , loss:  0.015154715\n",
      "Iteration:  8000 , loss:  0.015098281\n",
      "Iteration:  8100 , loss:  0.014999971\n",
      "Iteration:  8200 , loss:  0.015943952\n",
      "Iteration:  8300 , loss:  0.014843287\n",
      "Iteration:  8400 , loss:  0.014767587\n",
      "Iteration:  8500 , loss:  0.014691593\n",
      "Iteration:  8600 , loss:  0.014596729\n",
      "Iteration:  8700 , loss:  0.014574267\n",
      "Iteration:  8800 , loss:  0.0144491\n",
      "Iteration:  8900 , loss:  0.014600703\n",
      "Iteration:  9000 , loss:  0.014318123\n",
      "Iteration:  9100 , loss:  0.026280489\n",
      "Iteration:  9200 , loss:  0.014202863\n",
      "Iteration:  9300 , loss:  0.014609886\n",
      "Iteration:  9400 , loss:  0.0141042005\n",
      "Iteration:  9500 , loss:  0.016925404\n",
      "Iteration:  9600 , loss:  0.014017514\n",
      "Iteration:  9700 , loss:  0.013984356\n",
      "Iteration:  9800 , loss:  0.013943956\n",
      "Iteration:  9900 , loss:  0.013894446\n",
      "Iteration:  10000 , loss:  0.0138689\n",
      "Iteration:  10100 , loss:  0.013822444\n",
      "Iteration:  10200 , loss:  0.013900532\n",
      "Iteration:  10300 , loss:  0.013755765\n",
      "Iteration:  10400 , loss:  0.0141566135\n",
      "Iteration:  10500 , loss:  0.013693455\n",
      "Iteration:  10600 , loss:  0.013744114\n",
      "Iteration:  10700 , loss:  0.013633864\n",
      "Iteration:  10800 , loss:  0.013719961\n",
      "Iteration:  10900 , loss:  0.013581531\n",
      "Iteration:  11000 , loss:  0.022236792\n",
      "Iteration:  11100 , loss:  0.013529312\n",
      "Iteration:  11200 , loss:  0.014097203\n",
      "Iteration:  11300 , loss:  0.013477611\n",
      "Iteration:  11400 , loss:  0.015566239\n",
      "Iteration:  11500 , loss:  0.013433989\n",
      "Iteration:  11600 , loss:  0.015632506\n",
      "Iteration:  11700 , loss:  0.014026653\n",
      "Iteration:  11800 , loss:  0.013366848\n",
      "Iteration:  11900 , loss:  0.015131113\n",
      "Iteration:  12000 , loss:  0.01332473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  12100 , loss:  0.014129729\n",
      "Iteration:  12200 , loss:  0.013281465\n",
      "Iteration:  12300 , loss:  0.01329657\n",
      "Iteration:  12400 , loss:  0.013241028\n",
      "Iteration:  12500 , loss:  0.013235653\n",
      "Iteration:  12600 , loss:  0.01320442\n",
      "Iteration:  12700 , loss:  0.013330447\n",
      "Iteration:  12800 , loss:  0.013168777\n",
      "Iteration:  12900 , loss:  0.041324824\n",
      "Iteration:  13000 , loss:  0.013145877\n",
      "Iteration:  13100 , loss:  0.013115965\n",
      "Iteration:  13200 , loss:  0.013129353\n",
      "Iteration:  13300 , loss:  0.013091694\n",
      "Iteration:  13400 , loss:  0.014908126\n",
      "Iteration:  13500 , loss:  0.013047887\n",
      "Iteration:  13600 , loss:  0.0130425\n",
      "Iteration:  13700 , loss:  0.014223104\n",
      "Iteration:  13800 , loss:  0.012996207\n",
      "Iteration:  13900 , loss:  0.013084188\n",
      "Iteration:  14000 , loss:  0.013259517\n",
      "Iteration:  14100 , loss:  0.012978607\n",
      "Iteration:  14200 , loss:  0.012938\n",
      "Iteration:  14300 , loss:  0.014867967\n",
      "Iteration:  14400 , loss:  0.0129622985\n",
      "Iteration:  14500 , loss:  0.012887216\n",
      "Iteration:  14600 , loss:  0.01376963\n",
      "Iteration:  14700 , loss:  0.012851576\n",
      "Iteration:  14800 , loss:  0.012921315\n",
      "Iteration:  14900 , loss:  0.013058508\n",
      "Iteration:  15000 , loss:  0.012802574\n",
      "Iteration:  15100 , loss:  0.01279545\n",
      "Iteration:  15200 , loss:  0.016798133\n",
      "Iteration:  15300 , loss:  0.01275779\n",
      "Iteration:  15400 , loss:  0.013427904\n",
      "Iteration:  15500 , loss:  0.012725\n",
      "Iteration:  15600 , loss:  0.012842923\n",
      "Iteration:  15700 , loss:  0.012696419\n",
      "Iteration:  15800 , loss:  0.015771944\n",
      "Iteration:  15900 , loss:  0.012663273\n",
      "Iteration:  16000 , loss:  0.016339384\n",
      "Iteration:  16100 , loss:  0.012633715\n",
      "Iteration:  16200 , loss:  0.013689412\n",
      "Iteration:  16300 , loss:  0.012604581\n",
      "Iteration:  16400 , loss:  0.012897439\n",
      "Iteration:  16500 , loss:  0.012613751\n",
      "Iteration:  16600 , loss:  0.01254871\n",
      "Iteration:  16700 , loss:  0.012621647\n",
      "Iteration:  16800 , loss:  0.012519872\n",
      "Iteration:  16900 , loss:  0.012507372\n",
      "Iteration:  17000 , loss:  0.016185177\n",
      "Iteration:  17100 , loss:  0.012698\n",
      "Iteration:  17200 , loss:  0.012450647\n",
      "Iteration:  17300 , loss:  0.013421649\n",
      "Iteration:  17400 , loss:  0.01241465\n",
      "Iteration:  17500 , loss:  0.012555742\n",
      "Iteration:  17600 , loss:  0.012378553\n",
      "Iteration:  17700 , loss:  0.012372413\n",
      "Iteration:  17800 , loss:  0.012385139\n",
      "Iteration:  17900 , loss:  0.016576633\n",
      "Iteration:  18000 , loss:  0.012310074\n",
      "Iteration:  18100 , loss:  0.012359953\n",
      "Iteration:  18200 , loss:  0.012962775\n",
      "Iteration:  18300 , loss:  0.012796702\n",
      "Iteration:  18400 , loss:  0.012327313\n",
      "Iteration:  18500 , loss:  0.012227762\n",
      "Iteration:  18600 , loss:  0.012247217\n",
      "Iteration:  18700 , loss:  0.013349922\n",
      "Iteration:  18800 , loss:  0.012235532\n",
      "Iteration:  18900 , loss:  0.015722176\n",
      "Iteration:  19000 , loss:  0.012147888\n",
      "Iteration:  19100 , loss:  0.02019145\n",
      "Iteration:  19200 , loss:  0.012120596\n",
      "Iteration:  19300 , loss:  0.013742197\n",
      "Iteration:  19400 , loss:  0.019851252\n",
      "Iteration:  19500 , loss:  0.0120794065\n",
      "Iteration:  19600 , loss:  0.0120706605\n",
      "Iteration:  19700 , loss:  0.012075037\n",
      "Iteration:  19800 , loss:  0.012500128\n",
      "Iteration:  19900 , loss:  0.013573596\n",
      "Generating 9th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.7064364\n",
      "Iteration:  100 , loss:  2.3659909\n",
      "Iteration:  200 , loss:  1.8071704\n",
      "Iteration:  300 , loss:  1.3627353\n",
      "Iteration:  400 , loss:  0.5591134\n",
      "Iteration:  500 , loss:  0.3029983\n",
      "Iteration:  600 , loss:  0.21294485\n",
      "Iteration:  700 , loss:  0.15743972\n",
      "Iteration:  800 , loss:  0.13215563\n",
      "Iteration:  900 , loss:  0.112237945\n",
      "Iteration:  1000 , loss:  0.10890038\n",
      "Iteration:  1100 , loss:  0.08822568\n",
      "Iteration:  1200 , loss:  0.079423696\n",
      "Iteration:  1300 , loss:  0.075482756\n",
      "Iteration:  1400 , loss:  0.06349613\n",
      "Iteration:  1500 , loss:  0.057381503\n",
      "Iteration:  1600 , loss:  0.053457998\n",
      "Iteration:  1700 , loss:  0.047592103\n",
      "Iteration:  1800 , loss:  0.044204913\n",
      "Iteration:  1900 , loss:  0.041082762\n",
      "Iteration:  2000 , loss:  0.038783267\n",
      "Iteration:  2100 , loss:  0.03658094\n",
      "Iteration:  2200 , loss:  0.035220798\n",
      "Iteration:  2300 , loss:  0.033234276\n",
      "Iteration:  2400 , loss:  0.032087598\n",
      "Iteration:  2500 , loss:  0.030524358\n",
      "Iteration:  2600 , loss:  0.032744613\n",
      "Iteration:  2700 , loss:  0.0283644\n",
      "Iteration:  2800 , loss:  0.027482236\n",
      "Iteration:  2900 , loss:  0.026567074\n",
      "Iteration:  3000 , loss:  0.025715318\n",
      "Iteration:  3100 , loss:  0.025045373\n",
      "Iteration:  3200 , loss:  0.024315557\n",
      "Iteration:  3300 , loss:  0.023848359\n",
      "Iteration:  3400 , loss:  0.023110054\n",
      "Iteration:  3500 , loss:  0.022976607\n",
      "Iteration:  3600 , loss:  0.022095876\n",
      "Iteration:  3700 , loss:  0.034054957\n",
      "Iteration:  3800 , loss:  0.021230824\n",
      "Iteration:  3900 , loss:  0.020804923\n",
      "Iteration:  4000 , loss:  0.020491902\n",
      "Iteration:  4100 , loss:  0.02009898\n",
      "Iteration:  4200 , loss:  0.01984144\n",
      "Iteration:  4300 , loss:  0.019488633\n",
      "Iteration:  4400 , loss:  0.04203779\n",
      "Iteration:  4500 , loss:  0.018944876\n",
      "Iteration:  4600 , loss:  0.018668545\n",
      "Iteration:  4700 , loss:  0.018492907\n",
      "Iteration:  4800 , loss:  0.018224938\n",
      "Iteration:  4900 , loss:  0.01813995\n",
      "Iteration:  5000 , loss:  0.017848002\n",
      "Iteration:  5100 , loss:  0.0390248\n",
      "Iteration:  5200 , loss:  0.017512415\n",
      "Iteration:  5300 , loss:  0.0173341\n",
      "Iteration:  5400 , loss:  0.017298032\n",
      "Iteration:  5500 , loss:  0.017056312\n",
      "Iteration:  5600 , loss:  0.016903304\n",
      "Iteration:  5700 , loss:  0.016844083\n",
      "Iteration:  5800 , loss:  0.016665112\n",
      "Iteration:  5900 , loss:  0.016595539\n",
      "Iteration:  6000 , loss:  0.016454482\n",
      "Iteration:  6100 , loss:  0.016706865\n",
      "Iteration:  6200 , loss:  0.016253354\n",
      "Iteration:  6300 , loss:  0.016137768\n",
      "Iteration:  6400 , loss:  0.016158387\n",
      "Iteration:  6500 , loss:  0.015956126\n",
      "Iteration:  6600 , loss:  0.026462195\n",
      "Iteration:  6700 , loss:  0.015789893\n",
      "Iteration:  6800 , loss:  0.015708383\n",
      "Iteration:  6900 , loss:  0.015625115\n",
      "Iteration:  7000 , loss:  0.018863278\n",
      "Iteration:  7100 , loss:  0.01546813\n",
      "Iteration:  7200 , loss:  0.033401906\n",
      "Iteration:  7300 , loss:  0.015327744\n",
      "Iteration:  7400 , loss:  0.015238652\n",
      "Iteration:  7500 , loss:  0.0153885055\n",
      "Iteration:  7600 , loss:  0.01511526\n",
      "Iteration:  7700 , loss:  0.015040237\n",
      "Iteration:  7800 , loss:  0.014983796\n",
      "Iteration:  7900 , loss:  0.014899004\n",
      "Iteration:  8000 , loss:  0.014932867\n",
      "Iteration:  8100 , loss:  0.014773877\n",
      "Iteration:  8200 , loss:  0.021416467\n",
      "Iteration:  8300 , loss:  0.014645885\n",
      "Iteration:  8400 , loss:  0.027730383\n",
      "Iteration:  8500 , loss:  0.014527381\n",
      "Iteration:  8600 , loss:  0.014498817\n",
      "Iteration:  8700 , loss:  0.01442335\n",
      "Iteration:  8800 , loss:  0.01434814\n",
      "Iteration:  8900 , loss:  0.014314922\n",
      "Iteration:  9000 , loss:  0.01424402\n",
      "Iteration:  9100 , loss:  0.014249492\n",
      "Iteration:  9200 , loss:  0.014151808\n",
      "Iteration:  9300 , loss:  0.015781334\n",
      "Iteration:  9400 , loss:  0.014058214\n",
      "Iteration:  9500 , loss:  0.014974212\n",
      "Iteration:  9600 , loss:  0.013968354\n",
      "Iteration:  9700 , loss:  0.014106327\n",
      "Iteration:  9800 , loss:  0.013886934\n",
      "Iteration:  9900 , loss:  0.014065037\n",
      "Iteration:  10000 , loss:  0.01380461\n",
      "Iteration:  10100 , loss:  0.03835873\n",
      "Iteration:  10200 , loss:  0.013742851\n",
      "Iteration:  10300 , loss:  0.013690032\n",
      "Iteration:  10400 , loss:  0.0149538815\n",
      "Iteration:  10500 , loss:  0.013622483\n",
      "Iteration:  10600 , loss:  0.014629746\n",
      "Iteration:  10700 , loss:  0.013557589\n",
      "Iteration:  10800 , loss:  0.013513177\n",
      "Iteration:  10900 , loss:  0.01349993\n",
      "Iteration:  11000 , loss:  0.013447211\n",
      "Iteration:  11100 , loss:  0.013491113\n",
      "Iteration:  11200 , loss:  0.013387899\n",
      "Iteration:  11300 , loss:  0.015249338\n",
      "Iteration:  11400 , loss:  0.01333113\n",
      "Iteration:  11500 , loss:  0.02198904\n",
      "Iteration:  11600 , loss:  0.013272937\n",
      "Iteration:  11700 , loss:  0.015461162\n",
      "Iteration:  11800 , loss:  0.013220845\n",
      "Iteration:  11900 , loss:  0.0131848\n",
      "Iteration:  12000 , loss:  0.013176669\n",
      "Iteration:  12100 , loss:  0.013130368\n",
      "Iteration:  12200 , loss:  0.013121473\n",
      "Iteration:  12300 , loss:  0.013078401\n",
      "Iteration:  12400 , loss:  0.01309019\n",
      "Iteration:  12500 , loss:  0.013028624\n",
      "Iteration:  12600 , loss:  0.013062016\n",
      "Iteration:  12700 , loss:  0.012980165\n",
      "Iteration:  12800 , loss:  0.013010047\n",
      "Iteration:  12900 , loss:  0.0129340375\n",
      "Iteration:  13000 , loss:  0.013030198\n",
      "Iteration:  13100 , loss:  0.012887774\n",
      "Iteration:  13200 , loss:  0.013873035\n",
      "Iteration:  13300 , loss:  0.012853358\n",
      "Iteration:  13400 , loss:  0.012821301\n",
      "Iteration:  13500 , loss:  0.013122659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  13600 , loss:  0.012783751\n",
      "Iteration:  13700 , loss:  0.03049939\n",
      "Iteration:  13800 , loss:  0.012747489\n",
      "Iteration:  13900 , loss:  0.012716012\n",
      "Iteration:  14000 , loss:  0.012719068\n",
      "Iteration:  14100 , loss:  0.012678559\n",
      "Iteration:  14200 , loss:  0.012747827\n",
      "Iteration:  14300 , loss:  0.012643179\n",
      "Iteration:  14400 , loss:  0.017851641\n",
      "Iteration:  14500 , loss:  0.012608014\n",
      "Iteration:  14600 , loss:  0.012583095\n",
      "Iteration:  14700 , loss:  0.012585444\n",
      "Iteration:  14800 , loss:  0.012552535\n",
      "Iteration:  14900 , loss:  0.015338983\n",
      "Iteration:  15000 , loss:  0.012522774\n",
      "Iteration:  15100 , loss:  0.012500935\n",
      "Iteration:  15200 , loss:  0.012496317\n",
      "Iteration:  15300 , loss:  0.012464098\n",
      "Iteration:  15400 , loss:  0.012469554\n",
      "Iteration:  15500 , loss:  0.012434635\n",
      "Iteration:  15600 , loss:  0.012511109\n",
      "Iteration:  15700 , loss:  0.0124026425\n",
      "Iteration:  15800 , loss:  0.012436291\n",
      "Iteration:  15900 , loss:  0.012372177\n",
      "Iteration:  16000 , loss:  0.012417704\n",
      "Iteration:  16100 , loss:  0.012344535\n",
      "Iteration:  16200 , loss:  0.012616258\n",
      "Iteration:  16300 , loss:  0.012317219\n",
      "Iteration:  16400 , loss:  0.012874873\n",
      "Iteration:  16500 , loss:  0.012291195\n",
      "Iteration:  16600 , loss:  0.012304717\n",
      "Iteration:  16700 , loss:  0.012420502\n",
      "Iteration:  16800 , loss:  0.01224662\n",
      "Iteration:  16900 , loss:  0.012365531\n",
      "Iteration:  17000 , loss:  0.012221163\n",
      "Iteration:  17100 , loss:  0.012331859\n",
      "Iteration:  17200 , loss:  0.012195527\n",
      "Iteration:  17300 , loss:  0.012442321\n",
      "Iteration:  17400 , loss:  0.012169317\n",
      "Iteration:  17500 , loss:  0.012305217\n",
      "Iteration:  17600 , loss:  0.012146009\n",
      "Iteration:  17700 , loss:  0.012715312\n",
      "Iteration:  17800 , loss:  0.0121268425\n",
      "Iteration:  17900 , loss:  0.013407691\n",
      "Iteration:  18000 , loss:  0.015940612\n",
      "Iteration:  18100 , loss:  0.01208352\n",
      "Iteration:  18200 , loss:  0.012088678\n",
      "Iteration:  18300 , loss:  0.017605837\n",
      "Iteration:  18400 , loss:  0.012049645\n",
      "Iteration:  18500 , loss:  0.012658218\n",
      "Iteration:  18600 , loss:  0.012029229\n",
      "Iteration:  18700 , loss:  0.033187106\n",
      "Iteration:  18800 , loss:  0.0120088495\n",
      "Iteration:  18900 , loss:  0.014786104\n",
      "Iteration:  19000 , loss:  0.01198779\n",
      "Iteration:  19100 , loss:  0.03202559\n",
      "Iteration:  19200 , loss:  0.011962888\n",
      "Iteration:  19300 , loss:  0.021120649\n",
      "Iteration:  19400 , loss:  0.011943357\n",
      "Iteration:  19500 , loss:  0.013826041\n",
      "Iteration:  19600 , loss:  0.027256122\n",
      "Iteration:  19700 , loss:  0.011908731\n",
      "Iteration:  19800 , loss:  0.03288336\n",
      "Iteration:  19900 , loss:  0.011889029\n",
      "Generating 10th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  4.1737084\n",
      "Iteration:  100 , loss:  2.4086232\n",
      "Iteration:  200 , loss:  1.8904405\n",
      "Iteration:  300 , loss:  1.5952001\n",
      "Iteration:  400 , loss:  1.1199169\n",
      "Iteration:  500 , loss:  0.56039155\n",
      "Iteration:  600 , loss:  0.33449748\n",
      "Iteration:  700 , loss:  0.24805659\n",
      "Iteration:  800 , loss:  0.19396819\n",
      "Iteration:  900 , loss:  0.15695192\n",
      "Iteration:  1000 , loss:  0.13226399\n",
      "Iteration:  1100 , loss:  0.11408768\n",
      "Iteration:  1200 , loss:  0.12374673\n",
      "Iteration:  1300 , loss:  0.086306706\n",
      "Iteration:  1400 , loss:  0.076203495\n",
      "Iteration:  1500 , loss:  0.067383125\n",
      "Iteration:  1600 , loss:  0.059456397\n",
      "Iteration:  1700 , loss:  0.053208902\n",
      "Iteration:  1800 , loss:  0.04785018\n",
      "Iteration:  1900 , loss:  0.044832986\n",
      "Iteration:  2000 , loss:  0.03965227\n",
      "Iteration:  2100 , loss:  0.03708194\n",
      "Iteration:  2200 , loss:  0.034690123\n",
      "Iteration:  2300 , loss:  0.03306362\n",
      "Iteration:  2400 , loss:  0.03135775\n",
      "Iteration:  2500 , loss:  0.0327278\n",
      "Iteration:  2600 , loss:  0.028759787\n",
      "Iteration:  2700 , loss:  0.02758355\n",
      "Iteration:  2800 , loss:  0.026702229\n",
      "Iteration:  2900 , loss:  0.025743278\n",
      "Iteration:  3000 , loss:  0.025167838\n",
      "Iteration:  3100 , loss:  0.024291623\n",
      "Iteration:  3200 , loss:  0.02498047\n",
      "Iteration:  3300 , loss:  0.023109306\n",
      "Iteration:  3400 , loss:  0.022553476\n",
      "Iteration:  3500 , loss:  0.022142118\n",
      "Iteration:  3600 , loss:  0.021633718\n",
      "Iteration:  3700 , loss:  0.02201266\n",
      "Iteration:  3800 , loss:  0.020867258\n",
      "Iteration:  3900 , loss:  0.058782857\n",
      "Iteration:  4000 , loss:  0.020237876\n",
      "Iteration:  4100 , loss:  0.01989787\n",
      "Iteration:  4200 , loss:  0.020457389\n",
      "Iteration:  4300 , loss:  0.019392503\n",
      "Iteration:  4400 , loss:  0.031268544\n",
      "Iteration:  4500 , loss:  0.018946335\n",
      "Iteration:  4600 , loss:  0.018707741\n",
      "Iteration:  4700 , loss:  0.018591398\n",
      "Iteration:  4800 , loss:  0.018366631\n",
      "Iteration:  4900 , loss:  0.01971179\n",
      "Iteration:  5000 , loss:  0.018073695\n",
      "Iteration:  5100 , loss:  0.017890934\n",
      "Iteration:  5200 , loss:  0.0208259\n",
      "Iteration:  5300 , loss:  0.017640997\n",
      "Iteration:  5400 , loss:  0.017485723\n",
      "Iteration:  5500 , loss:  0.017616032\n",
      "Iteration:  5600 , loss:  0.017274257\n",
      "Iteration:  5700 , loss:  0.017353408\n",
      "Iteration:  5800 , loss:  0.017080795\n",
      "Iteration:  5900 , loss:  0.016948914\n",
      "Iteration:  6000 , loss:  0.017048\n",
      "Iteration:  6100 , loss:  0.016783448\n",
      "Iteration:  6200 , loss:  0.016674444\n",
      "Iteration:  6300 , loss:  0.016644903\n",
      "Iteration:  6400 , loss:  0.016519064\n",
      "Iteration:  6500 , loss:  0.018276129\n",
      "Iteration:  6600 , loss:  0.01638167\n",
      "Iteration:  6700 , loss:  0.016288925\n",
      "Iteration:  6800 , loss:  0.016271006\n",
      "Iteration:  6900 , loss:  0.016157923\n",
      "Iteration:  7000 , loss:  0.016352037\n",
      "Iteration:  7100 , loss:  0.01603305\n",
      "Iteration:  7200 , loss:  0.016702488\n",
      "Iteration:  7300 , loss:  0.015925836\n",
      "Iteration:  7400 , loss:  0.015845982\n",
      "Iteration:  7500 , loss:  0.015885118\n",
      "Iteration:  7600 , loss:  0.015742008\n",
      "Iteration:  7700 , loss:  0.016396923\n",
      "Iteration:  7800 , loss:  0.015646048\n",
      "Iteration:  7900 , loss:  0.015575688\n",
      "Iteration:  8000 , loss:  0.015565887\n",
      "Iteration:  8100 , loss:  0.015484046\n",
      "Iteration:  8200 , loss:  0.017083691\n",
      "Iteration:  8300 , loss:  0.015398646\n",
      "Iteration:  8400 , loss:  0.015516618\n",
      "Iteration:  8500 , loss:  0.01531878\n",
      "Iteration:  8600 , loss:  0.015252082\n",
      "Iteration:  8700 , loss:  0.015287774\n",
      "Iteration:  8800 , loss:  0.015173494\n",
      "Iteration:  8900 , loss:  0.016613279\n",
      "Iteration:  9000 , loss:  0.015092946\n",
      "Iteration:  9100 , loss:  0.016191281\n",
      "Iteration:  9200 , loss:  0.015020074\n",
      "Iteration:  9300 , loss:  0.014963994\n",
      "Iteration:  9400 , loss:  0.014970372\n",
      "Iteration:  9500 , loss:  0.014891037\n",
      "Iteration:  9600 , loss:  0.015949402\n",
      "Iteration:  9700 , loss:  0.0148286745\n",
      "Iteration:  9800 , loss:  0.014776198\n",
      "Iteration:  9900 , loss:  0.014788967\n",
      "Iteration:  10000 , loss:  0.014708664\n",
      "Iteration:  10100 , loss:  0.014998775\n",
      "Iteration:  10200 , loss:  0.01464344\n",
      "Iteration:  10300 , loss:  0.017623302\n",
      "Iteration:  10400 , loss:  0.01458145\n",
      "Iteration:  10500 , loss:  0.060826894\n",
      "Iteration:  10600 , loss:  0.014531478\n",
      "Iteration:  10700 , loss:  0.014479342\n",
      "Iteration:  10800 , loss:  0.014652999\n",
      "Iteration:  10900 , loss:  0.014435147\n",
      "Iteration:  11000 , loss:  0.014391432\n",
      "Iteration:  11100 , loss:  0.014482553\n",
      "Iteration:  11200 , loss:  0.014344681\n",
      "Iteration:  11300 , loss:  0.029187635\n",
      "Iteration:  11400 , loss:  0.014297258\n",
      "Iteration:  11500 , loss:  0.014853977\n",
      "Iteration:  11600 , loss:  0.014257925\n",
      "Iteration:  11700 , loss:  0.014209276\n",
      "Iteration:  11800 , loss:  0.014273789\n",
      "Iteration:  11900 , loss:  0.01416371\n",
      "Iteration:  12000 , loss:  0.014479545\n",
      "Iteration:  12100 , loss:  0.014121879\n",
      "Iteration:  12200 , loss:  0.023329463\n",
      "Iteration:  12300 , loss:  0.01407917\n",
      "Iteration:  12400 , loss:  0.03684132\n",
      "Iteration:  12500 , loss:  0.014042465\n",
      "Iteration:  12600 , loss:  0.01400068\n",
      "Iteration:  12700 , loss:  0.014138976\n",
      "Iteration:  12800 , loss:  0.013968897\n",
      "Iteration:  12900 , loss:  0.013939494\n",
      "Iteration:  13000 , loss:  0.013947687\n",
      "Iteration:  13100 , loss:  0.013901271\n",
      "Iteration:  13200 , loss:  0.014139546\n",
      "Iteration:  13300 , loss:  0.013869513\n",
      "Iteration:  13400 , loss:  0.013878357\n",
      "Iteration:  13500 , loss:  0.013854703\n",
      "Iteration:  13600 , loss:  0.013806654\n",
      "Iteration:  13700 , loss:  0.014941953\n",
      "Iteration:  13800 , loss:  0.013784133\n",
      "Iteration:  13900 , loss:  0.013749564\n",
      "Iteration:  14000 , loss:  0.014116782\n",
      "Iteration:  14100 , loss:  0.013721171\n",
      "Iteration:  14200 , loss:  0.046212155\n",
      "Iteration:  14300 , loss:  0.013693903\n",
      "Iteration:  14400 , loss:  0.013661101\n",
      "Iteration:  14500 , loss:  0.01368122\n",
      "Iteration:  14600 , loss:  0.013627788\n",
      "Iteration:  14700 , loss:  0.013731843\n",
      "Iteration:  14800 , loss:  0.013595855\n",
      "Iteration:  14900 , loss:  0.01381075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  15000 , loss:  0.013564998\n",
      "Iteration:  15100 , loss:  0.017020335\n",
      "Iteration:  15200 , loss:  0.0135392565\n",
      "Iteration:  15300 , loss:  0.013509799\n",
      "Iteration:  15400 , loss:  0.01353256\n",
      "Iteration:  15500 , loss:  0.013484182\n",
      "Iteration:  15600 , loss:  0.014848737\n",
      "Iteration:  15700 , loss:  0.013459509\n",
      "Iteration:  15800 , loss:  0.013847008\n",
      "Iteration:  15900 , loss:  0.013436157\n",
      "Iteration:  16000 , loss:  0.013402719\n",
      "Iteration:  16100 , loss:  0.013454426\n",
      "Iteration:  16200 , loss:  0.013377206\n",
      "Iteration:  16300 , loss:  0.013752349\n",
      "Iteration:  16400 , loss:  0.013355473\n",
      "Iteration:  16500 , loss:  0.013328229\n",
      "Iteration:  16600 , loss:  0.013372945\n",
      "Iteration:  16700 , loss:  0.013308128\n",
      "Iteration:  16800 , loss:  0.039657705\n",
      "Iteration:  16900 , loss:  0.013286425\n",
      "Iteration:  17000 , loss:  0.013300847\n",
      "Iteration:  17100 , loss:  0.013268489\n",
      "Iteration:  17200 , loss:  0.013234558\n",
      "Iteration:  17300 , loss:  0.013284927\n",
      "Iteration:  17400 , loss:  0.013210908\n",
      "Iteration:  17500 , loss:  0.013853196\n",
      "Iteration:  17600 , loss:  0.013186207\n",
      "Iteration:  17700 , loss:  0.015654624\n",
      "Iteration:  17800 , loss:  0.013167331\n",
      "Iteration:  17900 , loss:  0.013144742\n",
      "Iteration:  18000 , loss:  0.013155483\n",
      "Iteration:  18100 , loss:  0.013119127\n",
      "Iteration:  18200 , loss:  0.013145765\n",
      "Iteration:  18300 , loss:  0.013095235\n",
      "Iteration:  18400 , loss:  0.013161869\n",
      "Iteration:  18500 , loss:  0.013073539\n",
      "Iteration:  18600 , loss:  0.013723508\n",
      "Iteration:  18700 , loss:  0.013054205\n",
      "Iteration:  18800 , loss:  0.013277123\n",
      "Iteration:  18900 , loss:  0.013034526\n",
      "Iteration:  19000 , loss:  0.013126494\n",
      "Iteration:  19100 , loss:  0.013021866\n",
      "Iteration:  19200 , loss:  0.012991203\n",
      "Iteration:  19300 , loss:  0.013186721\n",
      "Iteration:  19400 , loss:  0.012973522\n",
      "Iteration:  19500 , loss:  0.017886274\n",
      "Iteration:  19600 , loss:  0.012953304\n",
      "Iteration:  19700 , loss:  0.017517766\n",
      "Iteration:  19800 , loss:  0.012932874\n",
      "Iteration:  19900 , loss:  0.027272755\n",
      "Generating 11th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  5.5043206\n",
      "Iteration:  100 , loss:  2.606709\n",
      "Iteration:  200 , loss:  2.1062407\n",
      "Iteration:  300 , loss:  1.7809087\n",
      "Iteration:  400 , loss:  1.465626\n",
      "Iteration:  500 , loss:  0.96563536\n",
      "Iteration:  600 , loss:  0.581121\n",
      "Iteration:  700 , loss:  0.4097455\n",
      "Iteration:  800 , loss:  0.31924868\n",
      "Iteration:  900 , loss:  0.2503736\n",
      "Iteration:  1000 , loss:  0.20499642\n",
      "Iteration:  1100 , loss:  0.17366487\n",
      "Iteration:  1200 , loss:  0.14496596\n",
      "Iteration:  1300 , loss:  0.123198606\n",
      "Iteration:  1400 , loss:  0.10684334\n",
      "Iteration:  1500 , loss:  0.09847367\n",
      "Iteration:  1600 , loss:  0.08481057\n",
      "Iteration:  1700 , loss:  0.0945261\n",
      "Iteration:  1800 , loss:  0.07004525\n",
      "Iteration:  1900 , loss:  0.06947089\n",
      "Iteration:  2000 , loss:  0.059579745\n",
      "Iteration:  2100 , loss:  0.07624687\n",
      "Iteration:  2200 , loss:  0.051822416\n",
      "Iteration:  2300 , loss:  0.04828985\n",
      "Iteration:  2400 , loss:  0.045461256\n",
      "Iteration:  2500 , loss:  0.042618643\n",
      "Iteration:  2600 , loss:  0.040368643\n",
      "Iteration:  2700 , loss:  0.038097236\n",
      "Iteration:  2800 , loss:  0.03697202\n",
      "Iteration:  2900 , loss:  0.03438837\n",
      "Iteration:  3000 , loss:  0.03992098\n",
      "Iteration:  3100 , loss:  0.031352434\n",
      "Iteration:  3200 , loss:  0.031287324\n",
      "Iteration:  3300 , loss:  0.028892918\n",
      "Iteration:  3400 , loss:  0.027734885\n",
      "Iteration:  3500 , loss:  0.026917502\n",
      "Iteration:  3600 , loss:  0.025972955\n",
      "Iteration:  3700 , loss:  0.025327813\n",
      "Iteration:  3800 , loss:  0.02452822\n",
      "Iteration:  3900 , loss:  0.024199022\n",
      "Iteration:  4000 , loss:  0.023369677\n",
      "Iteration:  4100 , loss:  0.028270643\n",
      "Iteration:  4200 , loss:  0.022408454\n",
      "Iteration:  4300 , loss:  0.021932404\n",
      "Iteration:  4400 , loss:  0.021624703\n",
      "Iteration:  4500 , loss:  0.021201154\n",
      "Iteration:  4600 , loss:  0.023595931\n",
      "Iteration:  4700 , loss:  0.020553619\n",
      "Iteration:  4800 , loss:  0.069111176\n",
      "Iteration:  4900 , loss:  0.01998419\n",
      "Iteration:  5000 , loss:  0.019671734\n",
      "Iteration:  5100 , loss:  0.01948753\n",
      "Iteration:  5200 , loss:  0.019197717\n",
      "Iteration:  5300 , loss:  0.019160466\n",
      "Iteration:  5400 , loss:  0.018764159\n",
      "Iteration:  5500 , loss:  0.01853884\n",
      "Iteration:  5600 , loss:  0.018397387\n",
      "Iteration:  5700 , loss:  0.018168224\n",
      "Iteration:  5800 , loss:  0.02863388\n",
      "Iteration:  5900 , loss:  0.017864384\n",
      "Iteration:  6000 , loss:  0.01767771\n",
      "Iteration:  6100 , loss:  0.023213424\n",
      "Iteration:  6200 , loss:  0.017435499\n",
      "Iteration:  6300 , loss:  0.017272428\n",
      "Iteration:  6400 , loss:  0.018009014\n",
      "Iteration:  6500 , loss:  0.021271601\n",
      "Iteration:  6600 , loss:  0.016901536\n",
      "Iteration:  6700 , loss:  0.018023843\n",
      "Iteration:  6800 , loss:  0.016693298\n",
      "Iteration:  6900 , loss:  0.016580943\n",
      "Iteration:  7000 , loss:  0.01648554\n",
      "Iteration:  7100 , loss:  0.018847706\n",
      "Iteration:  7200 , loss:  0.016308613\n",
      "Iteration:  7300 , loss:  0.016189445\n",
      "Iteration:  7400 , loss:  0.021604802\n",
      "Iteration:  7500 , loss:  0.01601729\n",
      "Iteration:  7600 , loss:  0.016385715\n",
      "Iteration:  7700 , loss:  0.01585353\n",
      "Iteration:  7800 , loss:  0.016028479\n",
      "Iteration:  7900 , loss:  0.015667472\n",
      "Iteration:  8000 , loss:  0.016438833\n",
      "Iteration:  8100 , loss:  0.015529003\n",
      "Iteration:  8200 , loss:  0.01543924\n",
      "Iteration:  8300 , loss:  0.015557934\n",
      "Iteration:  8400 , loss:  0.0153004415\n",
      "Iteration:  8500 , loss:  0.015340187\n",
      "Iteration:  8600 , loss:  0.015170609\n",
      "Iteration:  8700 , loss:  0.015081113\n",
      "Iteration:  8800 , loss:  0.01534652\n",
      "Iteration:  8900 , loss:  0.014950106\n",
      "Iteration:  9000 , loss:  0.015196683\n",
      "Iteration:  9100 , loss:  0.01483286\n",
      "Iteration:  9200 , loss:  0.014759019\n",
      "Iteration:  9300 , loss:  0.014744931\n",
      "Iteration:  9400 , loss:  0.014646767\n",
      "Iteration:  9500 , loss:  0.015017768\n",
      "Iteration:  9600 , loss:  0.014539599\n",
      "Iteration:  9700 , loss:  0.014475353\n",
      "Iteration:  9800 , loss:  0.014475541\n",
      "Iteration:  9900 , loss:  0.014386612\n",
      "Iteration:  10000 , loss:  0.014324324\n",
      "Iteration:  10100 , loss:  0.014523067\n",
      "Iteration:  10200 , loss:  0.014230989\n",
      "Iteration:  10300 , loss:  0.014245195\n",
      "Iteration:  10400 , loss:  0.0141403135\n",
      "Iteration:  10500 , loss:  0.0149122225\n",
      "Iteration:  10600 , loss:  0.014031805\n",
      "Iteration:  10700 , loss:  0.024216622\n",
      "Iteration:  10800 , loss:  0.013934351\n",
      "Iteration:  10900 , loss:  0.013912305\n",
      "Iteration:  11000 , loss:  0.014363889\n",
      "Iteration:  11100 , loss:  0.013855314\n",
      "Iteration:  11200 , loss:  0.014980651\n",
      "Iteration:  11300 , loss:  0.01372185\n",
      "Iteration:  11400 , loss:  0.025610914\n",
      "Iteration:  11500 , loss:  0.013634339\n",
      "Iteration:  11600 , loss:  0.013724644\n",
      "Iteration:  11700 , loss:  0.013556528\n",
      "Iteration:  11800 , loss:  0.0135349445\n",
      "Iteration:  11900 , loss:  0.013517521\n",
      "Iteration:  12000 , loss:  0.013447649\n",
      "Iteration:  12100 , loss:  0.01343577\n",
      "Iteration:  12200 , loss:  0.013483582\n",
      "Iteration:  12300 , loss:  0.01427551\n",
      "Iteration:  12400 , loss:  0.013334384\n",
      "Iteration:  12500 , loss:  0.015356986\n",
      "Iteration:  12600 , loss:  0.013256522\n",
      "Iteration:  12700 , loss:  0.013244746\n",
      "Iteration:  12800 , loss:  0.013200651\n",
      "Iteration:  12900 , loss:  0.013203341\n",
      "Iteration:  13000 , loss:  0.013152375\n",
      "Iteration:  13100 , loss:  0.01511183\n",
      "Iteration:  13200 , loss:  0.013104845\n",
      "Iteration:  13300 , loss:  0.0139774345\n",
      "Iteration:  13400 , loss:  0.013054192\n",
      "Iteration:  13500 , loss:  0.013470888\n",
      "Iteration:  13600 , loss:  0.013008474\n",
      "Iteration:  13700 , loss:  0.01433526\n",
      "Iteration:  13800 , loss:  0.012964551\n",
      "Iteration:  13900 , loss:  0.013462115\n",
      "Iteration:  14000 , loss:  0.012926354\n",
      "Iteration:  14100 , loss:  0.014741177\n",
      "Iteration:  14200 , loss:  0.012919387\n",
      "Iteration:  14300 , loss:  0.013113225\n",
      "Iteration:  14400 , loss:  0.012850938\n",
      "Iteration:  14500 , loss:  0.013012408\n",
      "Iteration:  14600 , loss:  0.01294308\n",
      "Iteration:  14700 , loss:  0.013379155\n",
      "Iteration:  14800 , loss:  0.012780976\n",
      "Iteration:  14900 , loss:  0.012755798\n",
      "Iteration:  15000 , loss:  0.014558576\n",
      "Iteration:  15100 , loss:  0.012728255\n",
      "Iteration:  15200 , loss:  0.013844831\n",
      "Iteration:  15300 , loss:  0.012712907\n",
      "Iteration:  15400 , loss:  0.012715325\n",
      "Iteration:  15500 , loss:  0.012886476\n",
      "Iteration:  15600 , loss:  0.0126314\n",
      "Iteration:  15700 , loss:  0.012680285\n",
      "Iteration:  15800 , loss:  0.019023929\n",
      "Iteration:  15900 , loss:  0.012589397\n",
      "Iteration:  16000 , loss:  0.0126080355\n",
      "Iteration:  16100 , loss:  0.012557659\n",
      "Iteration:  16200 , loss:  0.012535946\n",
      "Iteration:  16300 , loss:  0.0125294905\n",
      "Iteration:  16400 , loss:  0.012875708\n",
      "Iteration:  16500 , loss:  0.012492618\n",
      "Iteration:  16600 , loss:  0.016675543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  16700 , loss:  0.012458753\n",
      "Iteration:  16800 , loss:  0.0127488095\n",
      "Iteration:  16900 , loss:  0.012429837\n",
      "Iteration:  17000 , loss:  0.01280264\n",
      "Iteration:  17100 , loss:  0.012397308\n",
      "Iteration:  17200 , loss:  0.0124326795\n",
      "Iteration:  17300 , loss:  0.01237206\n",
      "Iteration:  17400 , loss:  0.012637369\n",
      "Iteration:  17500 , loss:  0.0123500265\n",
      "Iteration:  17600 , loss:  0.012329886\n",
      "Iteration:  17700 , loss:  0.0123215355\n",
      "Iteration:  17800 , loss:  0.017554348\n",
      "Iteration:  17900 , loss:  0.012288959\n",
      "Iteration:  18000 , loss:  0.012285358\n",
      "Iteration:  18100 , loss:  0.0123486705\n",
      "Iteration:  18200 , loss:  0.012509889\n",
      "Iteration:  18300 , loss:  0.012231323\n",
      "Iteration:  18400 , loss:  0.012250183\n",
      "Iteration:  18500 , loss:  0.012482313\n",
      "Iteration:  18600 , loss:  0.012190048\n",
      "Iteration:  18700 , loss:  0.012524489\n",
      "Iteration:  18800 , loss:  0.012165606\n",
      "Iteration:  18900 , loss:  0.01220679\n",
      "Iteration:  19000 , loss:  0.013144977\n",
      "Iteration:  19100 , loss:  0.0121217165\n",
      "Iteration:  19200 , loss:  0.012282474\n",
      "Iteration:  19300 , loss:  0.01210798\n",
      "Iteration:  19400 , loss:  0.012080828\n",
      "Iteration:  19500 , loss:  0.012205558\n",
      "Iteration:  19600 , loss:  0.012320209\n",
      "Iteration:  19700 , loss:  0.012102113\n",
      "Iteration:  19800 , loss:  0.012023719\n",
      "Iteration:  19900 , loss:  0.01201355\n",
      "Generating 12th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  4.3240757\n",
      "Iteration:  100 , loss:  2.6020827\n",
      "Iteration:  200 , loss:  2.17413\n",
      "Iteration:  300 , loss:  1.8250114\n",
      "Iteration:  400 , loss:  1.53315\n",
      "Iteration:  500 , loss:  1.1611232\n",
      "Iteration:  600 , loss:  0.73234475\n",
      "Iteration:  700 , loss:  0.41424292\n",
      "Iteration:  800 , loss:  0.29934177\n",
      "Iteration:  900 , loss:  0.2352359\n",
      "Iteration:  1000 , loss:  0.18687862\n",
      "Iteration:  1100 , loss:  0.1504651\n",
      "Iteration:  1200 , loss:  0.12033153\n",
      "Iteration:  1300 , loss:  0.110380694\n",
      "Iteration:  1400 , loss:  0.082895234\n",
      "Iteration:  1500 , loss:  0.07554804\n",
      "Iteration:  1600 , loss:  0.0640519\n",
      "Iteration:  1700 , loss:  0.056802474\n",
      "Iteration:  1800 , loss:  0.052037064\n",
      "Iteration:  1900 , loss:  0.04826134\n",
      "Iteration:  2000 , loss:  0.053113714\n",
      "Iteration:  2100 , loss:  0.04218488\n",
      "Iteration:  2200 , loss:  0.039681174\n",
      "Iteration:  2300 , loss:  0.037705176\n",
      "Iteration:  2400 , loss:  0.040397972\n",
      "Iteration:  2500 , loss:  0.034119256\n",
      "Iteration:  2600 , loss:  0.032740086\n",
      "Iteration:  2700 , loss:  0.031259\n",
      "Iteration:  2800 , loss:  0.030125132\n",
      "Iteration:  2900 , loss:  0.028946726\n",
      "Iteration:  3000 , loss:  0.028375274\n",
      "Iteration:  3100 , loss:  0.027044969\n",
      "Iteration:  3200 , loss:  0.028897475\n",
      "Iteration:  3300 , loss:  0.025508342\n",
      "Iteration:  3400 , loss:  0.024777811\n",
      "Iteration:  3500 , loss:  0.024171226\n",
      "Iteration:  3600 , loss:  0.023733415\n",
      "Iteration:  3700 , loss:  0.023076717\n",
      "Iteration:  3800 , loss:  0.022603666\n",
      "Iteration:  3900 , loss:  0.024781745\n",
      "Iteration:  4000 , loss:  0.021714417\n",
      "Iteration:  4100 , loss:  0.021529702\n",
      "Iteration:  4200 , loss:  0.020932395\n",
      "Iteration:  4300 , loss:  0.020663895\n",
      "Iteration:  4400 , loss:  0.022195227\n",
      "Iteration:  4500 , loss:  0.019979045\n",
      "Iteration:  4600 , loss:  0.01987762\n",
      "Iteration:  4700 , loss:  0.023390425\n",
      "Iteration:  4800 , loss:  0.019173048\n",
      "Iteration:  4900 , loss:  0.018956855\n",
      "Iteration:  5000 , loss:  0.01983059\n",
      "Iteration:  5100 , loss:  0.018494722\n",
      "Iteration:  5200 , loss:  0.018392524\n",
      "Iteration:  5300 , loss:  0.0181195\n",
      "Iteration:  5400 , loss:  0.018111907\n",
      "Iteration:  5500 , loss:  0.017758172\n",
      "Iteration:  5600 , loss:  0.017641777\n",
      "Iteration:  5700 , loss:  0.017423775\n",
      "Iteration:  5800 , loss:  0.017341422\n",
      "Iteration:  5900 , loss:  0.017144714\n",
      "Iteration:  6000 , loss:  0.017380914\n",
      "Iteration:  6100 , loss:  0.016868958\n",
      "Iteration:  6200 , loss:  0.018644819\n",
      "Iteration:  6300 , loss:  0.01660416\n",
      "Iteration:  6400 , loss:  0.017652603\n",
      "Iteration:  6500 , loss:  0.016368244\n",
      "Iteration:  6600 , loss:  0.021593569\n",
      "Iteration:  6700 , loss:  0.016152948\n",
      "Iteration:  6800 , loss:  0.052269522\n",
      "Iteration:  6900 , loss:  0.015945526\n",
      "Iteration:  7000 , loss:  0.034832\n",
      "Iteration:  7100 , loss:  0.015748875\n",
      "Iteration:  7200 , loss:  0.017538719\n",
      "Iteration:  7300 , loss:  0.015564572\n",
      "Iteration:  7400 , loss:  0.016969416\n",
      "Iteration:  7500 , loss:  0.015395416\n",
      "Iteration:  7600 , loss:  0.016541833\n",
      "Iteration:  7700 , loss:  0.015247308\n",
      "Iteration:  7800 , loss:  0.02137628\n",
      "Iteration:  7900 , loss:  0.01510428\n",
      "Iteration:  8000 , loss:  0.024644421\n",
      "Iteration:  8100 , loss:  0.014977011\n",
      "Iteration:  8200 , loss:  0.014883002\n",
      "Iteration:  8300 , loss:  0.014852742\n",
      "Iteration:  8400 , loss:  0.014757981\n",
      "Iteration:  8500 , loss:  0.014774261\n",
      "Iteration:  8600 , loss:  0.014650116\n",
      "Iteration:  8700 , loss:  0.015007423\n",
      "Iteration:  8800 , loss:  0.014538582\n",
      "Iteration:  8900 , loss:  0.014942335\n",
      "Iteration:  9000 , loss:  0.01443156\n",
      "Iteration:  9100 , loss:  0.014981845\n",
      "Iteration:  9200 , loss:  0.01433219\n",
      "Iteration:  9300 , loss:  0.016521806\n",
      "Iteration:  9400 , loss:  0.014248763\n",
      "Iteration:  9500 , loss:  0.014185075\n",
      "Iteration:  9600 , loss:  0.014166083\n",
      "Iteration:  9700 , loss:  0.0140872225\n",
      "Iteration:  9800 , loss:  0.014133038\n",
      "Iteration:  9900 , loss:  0.014019068\n",
      "Iteration:  10000 , loss:  0.04988988\n",
      "Iteration:  10100 , loss:  0.013945181\n",
      "Iteration:  10200 , loss:  0.013881382\n",
      "Iteration:  10300 , loss:  0.013885301\n",
      "Iteration:  10400 , loss:  0.013812076\n",
      "Iteration:  10500 , loss:  0.014019987\n",
      "Iteration:  10600 , loss:  0.013737765\n",
      "Iteration:  10700 , loss:  0.0140372515\n",
      "Iteration:  10800 , loss:  0.013676299\n",
      "Iteration:  10900 , loss:  0.043827623\n",
      "Iteration:  11000 , loss:  0.013607675\n",
      "Iteration:  11100 , loss:  0.03452393\n",
      "Iteration:  11200 , loss:  0.01354557\n",
      "Iteration:  11300 , loss:  0.013507477\n",
      "Iteration:  11400 , loss:  0.013482286\n",
      "Iteration:  11500 , loss:  0.013434121\n",
      "Iteration:  11600 , loss:  0.013422245\n",
      "Iteration:  11700 , loss:  0.013362085\n",
      "Iteration:  11800 , loss:  0.013384738\n",
      "Iteration:  11900 , loss:  0.013311516\n",
      "Iteration:  12000 , loss:  0.013610974\n",
      "Iteration:  12100 , loss:  0.013252709\n",
      "Iteration:  12200 , loss:  0.014200674\n",
      "Iteration:  12300 , loss:  0.013196167\n",
      "Iteration:  12400 , loss:  0.013726067\n",
      "Iteration:  12500 , loss:  0.013135159\n",
      "Iteration:  12600 , loss:  0.0134128425\n",
      "Iteration:  12700 , loss:  0.013083072\n",
      "Iteration:  12800 , loss:  0.023969393\n",
      "Iteration:  12900 , loss:  0.013044251\n",
      "Iteration:  13000 , loss:  0.012994845\n",
      "Iteration:  13100 , loss:  0.013258466\n",
      "Iteration:  13200 , loss:  0.01295412\n",
      "Iteration:  13300 , loss:  0.013684215\n",
      "Iteration:  13400 , loss:  0.01290376\n",
      "Iteration:  13500 , loss:  0.013598062\n",
      "Iteration:  13600 , loss:  0.012848912\n",
      "Iteration:  13700 , loss:  0.012808336\n",
      "Iteration:  13800 , loss:  0.012816807\n",
      "Iteration:  13900 , loss:  0.012761494\n",
      "Iteration:  14000 , loss:  0.014406154\n",
      "Iteration:  14100 , loss:  0.012714537\n",
      "Iteration:  14200 , loss:  0.013628063\n",
      "Iteration:  14300 , loss:  0.012680663\n",
      "Iteration:  14400 , loss:  0.01263159\n",
      "Iteration:  14500 , loss:  0.012766628\n",
      "Iteration:  14600 , loss:  0.012575385\n",
      "Iteration:  14700 , loss:  0.012629892\n",
      "Iteration:  14800 , loss:  0.012525103\n",
      "Iteration:  14900 , loss:  0.012645833\n",
      "Iteration:  15000 , loss:  0.012471997\n",
      "Iteration:  15100 , loss:  0.012974485\n",
      "Iteration:  15200 , loss:  0.012423853\n",
      "Iteration:  15300 , loss:  0.03130886\n",
      "Iteration:  15400 , loss:  0.012374557\n",
      "Iteration:  15500 , loss:  0.012335449\n",
      "Iteration:  15600 , loss:  0.012333494\n",
      "Iteration:  15700 , loss:  0.012283819\n",
      "Iteration:  15800 , loss:  0.012304755\n",
      "Iteration:  15900 , loss:  0.012271784\n",
      "Iteration:  16000 , loss:  0.012198871\n",
      "Iteration:  16100 , loss:  0.0121936975\n",
      "Iteration:  16200 , loss:  0.012145082\n",
      "Iteration:  16300 , loss:  0.012177911\n",
      "Iteration:  16400 , loss:  0.012091677\n",
      "Iteration:  16500 , loss:  0.012178557\n",
      "Iteration:  16600 , loss:  0.012041977\n",
      "Iteration:  16700 , loss:  0.012402399\n",
      "Iteration:  16800 , loss:  0.011991256\n",
      "Iteration:  16900 , loss:  0.018815598\n",
      "Iteration:  17000 , loss:  0.011946412\n",
      "Iteration:  17100 , loss:  0.011906714\n",
      "Iteration:  17200 , loss:  0.011897145\n",
      "Iteration:  17300 , loss:  0.025960546\n",
      "Iteration:  17400 , loss:  0.011842746\n",
      "Iteration:  17500 , loss:  0.011865558\n",
      "Iteration:  17600 , loss:  0.011792795\n",
      "Iteration:  17700 , loss:  0.015650434\n",
      "Iteration:  17800 , loss:  0.011743568\n",
      "Iteration:  17900 , loss:  0.012363914\n",
      "Iteration:  18000 , loss:  0.011695038\n",
      "Iteration:  18100 , loss:  0.013539449\n",
      "Iteration:  18200 , loss:  0.011653707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  18300 , loss:  0.011617585\n",
      "Iteration:  18400 , loss:  0.01160439\n",
      "Iteration:  18500 , loss:  0.012156774\n",
      "Iteration:  18600 , loss:  0.011559195\n",
      "Iteration:  18700 , loss:  0.014866378\n",
      "Iteration:  18800 , loss:  0.011505034\n",
      "Iteration:  18900 , loss:  0.011513936\n",
      "Iteration:  19000 , loss:  0.011463221\n",
      "Iteration:  19100 , loss:  0.011487342\n",
      "Iteration:  19200 , loss:  0.011423492\n",
      "Iteration:  19300 , loss:  0.01141167\n",
      "Iteration:  19400 , loss:  0.012133032\n",
      "Iteration:  19500 , loss:  0.011364695\n",
      "Iteration:  19600 , loss:  0.0116511565\n",
      "Iteration:  19700 , loss:  0.012148336\n",
      "Iteration:  19800 , loss:  0.013124869\n",
      "Iteration:  19900 , loss:  0.011286601\n",
      "Generating 13th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.8234568\n",
      "Iteration:  100 , loss:  2.4308324\n",
      "Iteration:  200 , loss:  1.8800313\n",
      "Iteration:  300 , loss:  1.5108838\n",
      "Iteration:  400 , loss:  0.8046363\n",
      "Iteration:  500 , loss:  0.3411052\n",
      "Iteration:  600 , loss:  0.21291916\n",
      "Iteration:  700 , loss:  0.15653722\n",
      "Iteration:  800 , loss:  0.1260843\n",
      "Iteration:  900 , loss:  0.11574696\n",
      "Iteration:  1000 , loss:  0.09607455\n",
      "Iteration:  1100 , loss:  0.084545724\n",
      "Iteration:  1200 , loss:  0.07656367\n",
      "Iteration:  1300 , loss:  0.07066631\n",
      "Iteration:  1400 , loss:  0.06494899\n",
      "Iteration:  1500 , loss:  0.06087573\n",
      "Iteration:  1600 , loss:  0.056876976\n",
      "Iteration:  1700 , loss:  0.053586952\n",
      "Iteration:  1800 , loss:  0.050402116\n",
      "Iteration:  1900 , loss:  0.04756964\n",
      "Iteration:  2000 , loss:  0.04485581\n",
      "Iteration:  2100 , loss:  0.04269417\n",
      "Iteration:  2200 , loss:  0.04029748\n",
      "Iteration:  2300 , loss:  0.038316857\n",
      "Iteration:  2400 , loss:  0.03648491\n",
      "Iteration:  2500 , loss:  0.03475763\n",
      "Iteration:  2600 , loss:  0.034891874\n",
      "Iteration:  2700 , loss:  0.031634685\n",
      "Iteration:  2800 , loss:  0.030175082\n",
      "Iteration:  2900 , loss:  0.029137926\n",
      "Iteration:  3000 , loss:  0.027521351\n",
      "Iteration:  3100 , loss:  0.026461987\n",
      "Iteration:  3200 , loss:  0.049820676\n",
      "Iteration:  3300 , loss:  0.024541473\n",
      "Iteration:  3400 , loss:  0.032715704\n",
      "Iteration:  3500 , loss:  0.02296897\n",
      "Iteration:  3600 , loss:  0.0222443\n",
      "Iteration:  3700 , loss:  0.021707663\n",
      "Iteration:  3800 , loss:  0.021079736\n",
      "Iteration:  3900 , loss:  0.020893298\n",
      "Iteration:  4000 , loss:  0.020075815\n",
      "Iteration:  4100 , loss:  0.019817691\n",
      "Iteration:  4200 , loss:  0.019185808\n",
      "Iteration:  4300 , loss:  0.018855872\n",
      "Iteration:  4400 , loss:  0.0423036\n",
      "Iteration:  4500 , loss:  0.018161215\n",
      "Iteration:  4600 , loss:  0.0643575\n",
      "Iteration:  4700 , loss:  0.01764103\n",
      "Iteration:  4800 , loss:  0.01738177\n",
      "Iteration:  4900 , loss:  0.01743511\n",
      "Iteration:  5000 , loss:  0.016953727\n",
      "Iteration:  5100 , loss:  0.017210163\n",
      "Iteration:  5200 , loss:  0.016567066\n",
      "Iteration:  5300 , loss:  0.022580853\n",
      "Iteration:  5400 , loss:  0.016209133\n",
      "Iteration:  5500 , loss:  0.016084649\n",
      "Iteration:  5600 , loss:  0.015925365\n",
      "Iteration:  5700 , loss:  0.015690792\n",
      "Iteration:  5800 , loss:  0.015623677\n",
      "Iteration:  5900 , loss:  0.015405575\n",
      "Iteration:  6000 , loss:  0.015314123\n",
      "Iteration:  6100 , loss:  0.015159561\n",
      "Iteration:  6200 , loss:  0.015174611\n",
      "Iteration:  6300 , loss:  0.014953071\n",
      "Iteration:  6400 , loss:  0.014973836\n",
      "Iteration:  6500 , loss:  0.0147687225\n",
      "Iteration:  6600 , loss:  0.014659552\n",
      "Iteration:  6700 , loss:  0.014612256\n",
      "Iteration:  6800 , loss:  0.014505821\n",
      "Iteration:  6900 , loss:  0.0145013835\n",
      "Iteration:  7000 , loss:  0.014372302\n",
      "Iteration:  7100 , loss:  0.016178949\n",
      "Iteration:  7200 , loss:  0.014258921\n",
      "Iteration:  7300 , loss:  0.014183368\n",
      "Iteration:  7400 , loss:  0.014173813\n",
      "Iteration:  7500 , loss:  0.014077688\n",
      "Iteration:  7600 , loss:  0.0154153835\n",
      "Iteration:  7700 , loss:  0.013990898\n",
      "Iteration:  7800 , loss:  0.013927124\n",
      "Iteration:  7900 , loss:  0.0139257135\n",
      "Iteration:  8000 , loss:  0.013846173\n",
      "Iteration:  8100 , loss:  0.033376914\n",
      "Iteration:  8200 , loss:  0.013767574\n",
      "Iteration:  8300 , loss:  0.01371086\n",
      "Iteration:  8400 , loss:  0.013724957\n",
      "Iteration:  8500 , loss:  0.013646325\n",
      "Iteration:  8600 , loss:  0.01366302\n",
      "Iteration:  8700 , loss:  0.0135965515\n",
      "Iteration:  8800 , loss:  0.013539089\n",
      "Iteration:  8900 , loss:  0.017976567\n",
      "Iteration:  9000 , loss:  0.0134781245\n",
      "Iteration:  9100 , loss:  0.013431666\n",
      "Iteration:  9200 , loss:  0.01342811\n",
      "Iteration:  9300 , loss:  0.013375999\n",
      "Iteration:  9400 , loss:  0.013400564\n",
      "Iteration:  9500 , loss:  0.013322132\n",
      "Iteration:  9600 , loss:  0.014850452\n",
      "Iteration:  9700 , loss:  0.013273337\n",
      "Iteration:  9800 , loss:  0.013232615\n",
      "Iteration:  9900 , loss:  0.013242122\n",
      "Iteration:  10000 , loss:  0.01318516\n",
      "Iteration:  10100 , loss:  0.013218401\n",
      "Iteration:  10200 , loss:  0.013132941\n",
      "Iteration:  10300 , loss:  0.01364916\n",
      "Iteration:  10400 , loss:  0.013081414\n",
      "Iteration:  10500 , loss:  0.013301844\n",
      "Iteration:  10600 , loss:  0.013039101\n",
      "Iteration:  10700 , loss:  0.0365163\n",
      "Iteration:  10800 , loss:  0.012996288\n",
      "Iteration:  10900 , loss:  0.012961522\n",
      "Iteration:  11000 , loss:  0.0129645355\n",
      "Iteration:  11100 , loss:  0.012921959\n",
      "Iteration:  11200 , loss:  0.013663629\n",
      "Iteration:  11300 , loss:  0.012882246\n",
      "Iteration:  11400 , loss:  0.025954504\n",
      "Iteration:  11500 , loss:  0.012832468\n",
      "Iteration:  11600 , loss:  0.013234735\n",
      "Iteration:  11700 , loss:  0.012789487\n",
      "Iteration:  11800 , loss:  0.013804235\n",
      "Iteration:  11900 , loss:  0.012757133\n",
      "Iteration:  12000 , loss:  0.012724895\n",
      "Iteration:  12100 , loss:  0.0127482815\n",
      "Iteration:  12200 , loss:  0.012685614\n",
      "Iteration:  12300 , loss:  0.01325574\n",
      "Iteration:  12400 , loss:  0.012650675\n",
      "Iteration:  12500 , loss:  0.023140755\n",
      "Iteration:  12600 , loss:  0.012615006\n",
      "Iteration:  12700 , loss:  0.012583075\n",
      "Iteration:  12800 , loss:  0.012584477\n",
      "Iteration:  12900 , loss:  0.01254468\n",
      "Iteration:  13000 , loss:  0.012547994\n",
      "Iteration:  13100 , loss:  0.012502065\n",
      "Iteration:  13200 , loss:  0.012506108\n",
      "Iteration:  13300 , loss:  0.012467951\n",
      "Iteration:  13400 , loss:  0.012930771\n",
      "Iteration:  13500 , loss:  0.01242853\n",
      "Iteration:  13600 , loss:  0.01331762\n",
      "Iteration:  13700 , loss:  0.012390468\n",
      "Iteration:  13800 , loss:  0.012814684\n",
      "Iteration:  13900 , loss:  0.01235371\n",
      "Iteration:  14000 , loss:  0.013531094\n",
      "Iteration:  14100 , loss:  0.020305688\n",
      "Iteration:  14200 , loss:  0.012292223\n",
      "Iteration:  14300 , loss:  0.014332495\n",
      "Iteration:  14400 , loss:  0.012254255\n",
      "Iteration:  14500 , loss:  0.016558077\n",
      "Iteration:  14600 , loss:  0.012214959\n",
      "Iteration:  14700 , loss:  0.023896877\n",
      "Iteration:  14800 , loss:  0.01217486\n",
      "Iteration:  14900 , loss:  0.012378715\n",
      "Iteration:  15000 , loss:  0.012134591\n",
      "Iteration:  15100 , loss:  0.012407575\n",
      "Iteration:  15200 , loss:  0.012094982\n",
      "Iteration:  15300 , loss:  0.012118097\n",
      "Iteration:  15400 , loss:  0.012056097\n",
      "Iteration:  15500 , loss:  0.012074802\n",
      "Iteration:  15600 , loss:  0.012017424\n",
      "Iteration:  15700 , loss:  0.012047376\n",
      "Iteration:  15800 , loss:  0.011980558\n",
      "Iteration:  15900 , loss:  0.0131941745\n",
      "Iteration:  16000 , loss:  0.0119448695\n",
      "Iteration:  16100 , loss:  0.012426854\n",
      "Iteration:  16200 , loss:  0.011910426\n",
      "Iteration:  16300 , loss:  0.01191506\n",
      "Iteration:  16400 , loss:  0.011875773\n",
      "Iteration:  16500 , loss:  0.011931676\n",
      "Iteration:  16600 , loss:  0.0118367355\n",
      "Iteration:  16700 , loss:  0.0119570745\n",
      "Iteration:  16800 , loss:  0.011931114\n",
      "Iteration:  16900 , loss:  0.011779582\n",
      "Iteration:  17000 , loss:  0.011778731\n",
      "Iteration:  17100 , loss:  0.012969576\n",
      "Iteration:  17200 , loss:  0.011723938\n",
      "Iteration:  17300 , loss:  0.011706764\n",
      "Iteration:  17400 , loss:  0.011702318\n",
      "Iteration:  17500 , loss:  0.011928719\n",
      "Iteration:  17600 , loss:  0.0116583025\n",
      "Iteration:  17700 , loss:  0.01164341\n",
      "Iteration:  17800 , loss:  0.011627534\n",
      "Iteration:  17900 , loss:  0.011625632\n",
      "Iteration:  18000 , loss:  0.011603171\n",
      "Iteration:  18100 , loss:  0.011572602\n",
      "Iteration:  18200 , loss:  0.011555772\n",
      "Iteration:  18300 , loss:  0.011597012\n",
      "Iteration:  18400 , loss:  0.011517525\n",
      "Iteration:  18500 , loss:  0.011522781\n",
      "Iteration:  18600 , loss:  0.012265831\n",
      "Iteration:  18700 , loss:  0.011468785\n",
      "Iteration:  18800 , loss:  0.011486908\n",
      "Iteration:  18900 , loss:  0.01507033\n",
      "Iteration:  19000 , loss:  0.011421379\n",
      "Iteration:  19100 , loss:  0.011406656\n",
      "Iteration:  19200 , loss:  0.011393294\n",
      "Iteration:  19300 , loss:  0.011385247\n",
      "Iteration:  19400 , loss:  0.011528963\n",
      "Iteration:  19500 , loss:  0.011340802\n",
      "Iteration:  19600 , loss:  0.011332376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  19700 , loss:  0.011311319\n",
      "Iteration:  19800 , loss:  0.011333713\n",
      "Iteration:  19900 , loss:  0.011409648\n",
      "Generating 14th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.609731\n",
      "Iteration:  100 , loss:  2.2966828\n",
      "Iteration:  200 , loss:  1.81075\n",
      "Iteration:  300 , loss:  1.4136574\n",
      "Iteration:  400 , loss:  0.81332475\n",
      "Iteration:  500 , loss:  0.376015\n",
      "Iteration:  600 , loss:  0.21204263\n",
      "Iteration:  700 , loss:  0.14644505\n",
      "Iteration:  800 , loss:  0.11286181\n",
      "Iteration:  900 , loss:  0.0933285\n",
      "Iteration:  1000 , loss:  0.07880995\n",
      "Iteration:  1100 , loss:  0.07105072\n",
      "Iteration:  1200 , loss:  0.06253808\n",
      "Iteration:  1300 , loss:  0.058310285\n",
      "Iteration:  1400 , loss:  0.054972805\n",
      "Iteration:  1500 , loss:  0.049028307\n",
      "Iteration:  1600 , loss:  0.04569254\n",
      "Iteration:  1700 , loss:  0.042838406\n",
      "Iteration:  1800 , loss:  0.04026606\n",
      "Iteration:  1900 , loss:  0.0384591\n",
      "Iteration:  2000 , loss:  0.036322255\n",
      "Iteration:  2100 , loss:  0.034815356\n",
      "Iteration:  2200 , loss:  0.03259229\n",
      "Iteration:  2300 , loss:  0.031030659\n",
      "Iteration:  2400 , loss:  0.029777948\n",
      "Iteration:  2500 , loss:  0.043091178\n",
      "Iteration:  2600 , loss:  0.028409485\n",
      "Iteration:  2700 , loss:  0.026338402\n",
      "Iteration:  2800 , loss:  0.035728656\n",
      "Iteration:  2900 , loss:  0.024619246\n",
      "Iteration:  3000 , loss:  0.024891201\n",
      "Iteration:  3100 , loss:  0.023298329\n",
      "Iteration:  3200 , loss:  0.023211462\n",
      "Iteration:  3300 , loss:  0.022200363\n",
      "Iteration:  3400 , loss:  0.021775989\n",
      "Iteration:  3500 , loss:  0.021298893\n",
      "Iteration:  3600 , loss:  0.020963281\n",
      "Iteration:  3700 , loss:  0.027971078\n",
      "Iteration:  3800 , loss:  0.020272769\n",
      "Iteration:  3900 , loss:  0.019928705\n",
      "Iteration:  4000 , loss:  0.019708905\n",
      "Iteration:  4100 , loss:  0.019393753\n",
      "Iteration:  4200 , loss:  0.019272447\n",
      "Iteration:  4300 , loss:  0.018932872\n",
      "Iteration:  4400 , loss:  0.034379363\n",
      "Iteration:  4500 , loss:  0.01849606\n",
      "Iteration:  4600 , loss:  0.018827654\n",
      "Iteration:  4700 , loss:  0.01811839\n",
      "Iteration:  4800 , loss:  0.020165265\n",
      "Iteration:  4900 , loss:  0.017783992\n",
      "Iteration:  5000 , loss:  0.025817994\n",
      "Iteration:  5100 , loss:  0.0174774\n",
      "Iteration:  5200 , loss:  0.022803605\n",
      "Iteration:  5300 , loss:  0.01719863\n",
      "Iteration:  5400 , loss:  0.018393267\n",
      "Iteration:  5500 , loss:  0.016939985\n",
      "Iteration:  5600 , loss:  0.01700469\n",
      "Iteration:  5700 , loss:  0.01671088\n",
      "Iteration:  5800 , loss:  0.016810227\n",
      "Iteration:  5900 , loss:  0.016494542\n",
      "Iteration:  6000 , loss:  0.016440293\n",
      "Iteration:  6100 , loss:  0.017619317\n",
      "Iteration:  6200 , loss:  0.016231617\n",
      "Iteration:  6300 , loss:  0.018988326\n",
      "Iteration:  6400 , loss:  0.01607003\n",
      "Iteration:  6500 , loss:  0.015975846\n",
      "Iteration:  6600 , loss:  0.01591983\n",
      "Iteration:  6700 , loss:  0.04795643\n",
      "Iteration:  6800 , loss:  0.015763164\n",
      "Iteration:  6900 , loss:  0.016412267\n",
      "Iteration:  7000 , loss:  0.0156309\n",
      "Iteration:  7100 , loss:  0.016233504\n",
      "Iteration:  7200 , loss:  0.015505563\n",
      "Iteration:  7300 , loss:  0.015875902\n",
      "Iteration:  7400 , loss:  0.015392039\n",
      "Iteration:  7500 , loss:  0.015509949\n",
      "Iteration:  7600 , loss:  0.015284171\n",
      "Iteration:  7700 , loss:  0.0153162535\n",
      "Iteration:  7800 , loss:  0.015179042\n",
      "Iteration:  7900 , loss:  0.015169624\n",
      "Iteration:  8000 , loss:  0.016507745\n",
      "Iteration:  8100 , loss:  0.015067762\n",
      "Iteration:  8200 , loss:  0.014995038\n",
      "Iteration:  8300 , loss:  0.01503934\n",
      "Iteration:  8400 , loss:  0.014920137\n",
      "Iteration:  8500 , loss:  0.015771715\n",
      "Iteration:  8600 , loss:  0.014838528\n",
      "Iteration:  8700 , loss:  0.015098858\n",
      "Iteration:  8800 , loss:  0.014760468\n",
      "Iteration:  8900 , loss:  0.014787714\n",
      "Iteration:  9000 , loss:  0.014683975\n",
      "Iteration:  9100 , loss:  0.014672466\n",
      "Iteration:  9200 , loss:  0.042442784\n",
      "Iteration:  9300 , loss:  0.014595898\n",
      "Iteration:  9400 , loss:  0.022061087\n",
      "Iteration:  9500 , loss:  0.014522487\n",
      "Iteration:  9600 , loss:  0.015146705\n",
      "Iteration:  9700 , loss:  0.0144557655\n",
      "Iteration:  9800 , loss:  0.014633777\n",
      "Iteration:  9900 , loss:  0.014396977\n",
      "Iteration:  10000 , loss:  0.014890384\n",
      "Iteration:  10100 , loss:  0.0143409595\n",
      "Iteration:  10200 , loss:  0.0150253065\n",
      "Iteration:  10300 , loss:  0.014279284\n",
      "Iteration:  10400 , loss:  0.014381414\n",
      "Iteration:  10500 , loss:  0.014231969\n",
      "Iteration:  10600 , loss:  0.014677297\n",
      "Iteration:  10700 , loss:  0.014178434\n",
      "Iteration:  10800 , loss:  0.015021665\n",
      "Iteration:  10900 , loss:  0.014127863\n",
      "Iteration:  11000 , loss:  0.01491238\n",
      "Iteration:  11100 , loss:  0.014077226\n",
      "Iteration:  11200 , loss:  0.014882099\n",
      "Iteration:  11300 , loss:  0.01403022\n",
      "Iteration:  11400 , loss:  0.01481265\n",
      "Iteration:  11500 , loss:  0.013985095\n",
      "Iteration:  11600 , loss:  0.014956392\n",
      "Iteration:  11700 , loss:  0.013938589\n",
      "Iteration:  11800 , loss:  0.01397372\n",
      "Iteration:  11900 , loss:  0.013888129\n",
      "Iteration:  12000 , loss:  0.013911541\n",
      "Iteration:  12100 , loss:  0.013845898\n",
      "Iteration:  12200 , loss:  0.013852527\n",
      "Iteration:  12300 , loss:  0.013804668\n",
      "Iteration:  12400 , loss:  0.013811646\n",
      "Iteration:  12500 , loss:  0.03492474\n",
      "Iteration:  12600 , loss:  0.013761733\n",
      "Iteration:  12700 , loss:  0.013744419\n",
      "Iteration:  12800 , loss:  0.013739089\n",
      "Iteration:  12900 , loss:  0.013689986\n",
      "Iteration:  13000 , loss:  0.013729916\n",
      "Iteration:  13100 , loss:  0.0136504425\n",
      "Iteration:  13200 , loss:  0.013698133\n",
      "Iteration:  13300 , loss:  0.013614626\n",
      "Iteration:  13400 , loss:  0.013614901\n",
      "Iteration:  13500 , loss:  0.019480538\n",
      "Iteration:  13600 , loss:  0.013568093\n",
      "Iteration:  13700 , loss:  0.013972897\n",
      "Iteration:  13800 , loss:  0.013532583\n",
      "Iteration:  13900 , loss:  0.016217876\n",
      "Iteration:  14000 , loss:  0.0134949945\n",
      "Iteration:  14100 , loss:  0.013725694\n",
      "Iteration:  14200 , loss:  0.013455256\n",
      "Iteration:  14300 , loss:  0.013462614\n",
      "Iteration:  14400 , loss:  0.042148337\n",
      "Iteration:  14500 , loss:  0.013410623\n",
      "Iteration:  14600 , loss:  0.013654952\n",
      "Iteration:  14700 , loss:  0.013370097\n",
      "Iteration:  14800 , loss:  0.013379252\n",
      "Iteration:  14900 , loss:  0.017216947\n",
      "Iteration:  15000 , loss:  0.013336184\n",
      "Iteration:  15100 , loss:  0.039058086\n",
      "Iteration:  15200 , loss:  0.013302771\n",
      "Iteration:  15300 , loss:  0.04555462\n",
      "Iteration:  15400 , loss:  0.013266594\n",
      "Iteration:  15500 , loss:  0.015477346\n",
      "Iteration:  15600 , loss:  0.013226928\n",
      "Iteration:  15700 , loss:  0.0133160185\n",
      "Iteration:  15800 , loss:  0.013192652\n",
      "Iteration:  15900 , loss:  0.0132427635\n",
      "Iteration:  16000 , loss:  0.01315866\n",
      "Iteration:  16100 , loss:  0.013176626\n",
      "Iteration:  16200 , loss:  0.013126431\n",
      "Iteration:  16300 , loss:  0.013148146\n",
      "Iteration:  16400 , loss:  0.013095647\n",
      "Iteration:  16500 , loss:  0.013124371\n",
      "Iteration:  16600 , loss:  0.013063636\n",
      "Iteration:  16700 , loss:  0.0132205635\n",
      "Iteration:  16800 , loss:  0.013038634\n",
      "Iteration:  16900 , loss:  0.017011307\n",
      "Iteration:  17000 , loss:  0.013007608\n",
      "Iteration:  17100 , loss:  0.016110292\n",
      "Iteration:  17200 , loss:  0.012980125\n",
      "Iteration:  17300 , loss:  0.012999279\n",
      "Iteration:  17400 , loss:  0.01294914\n",
      "Iteration:  17500 , loss:  0.0129149165\n",
      "Iteration:  17600 , loss:  0.012922376\n",
      "Iteration:  17700 , loss:  0.012880459\n",
      "Iteration:  17800 , loss:  0.012880754\n",
      "Iteration:  17900 , loss:  0.01290549\n",
      "Iteration:  18000 , loss:  0.012844077\n",
      "Iteration:  18100 , loss:  0.012806859\n",
      "Iteration:  18200 , loss:  0.01281506\n",
      "Iteration:  18300 , loss:  0.012771481\n",
      "Iteration:  18400 , loss:  0.012799938\n",
      "Iteration:  18500 , loss:  0.012737308\n",
      "Iteration:  18600 , loss:  0.012872092\n",
      "Iteration:  18700 , loss:  0.012698626\n",
      "Iteration:  18800 , loss:  0.012858845\n",
      "Iteration:  18900 , loss:  0.012654788\n",
      "Iteration:  19000 , loss:  0.012660103\n",
      "Iteration:  19100 , loss:  0.012626035\n",
      "Iteration:  19200 , loss:  0.012607171\n",
      "Iteration:  19300 , loss:  0.020522468\n",
      "Iteration:  19400 , loss:  0.012557849\n",
      "Iteration:  19500 , loss:  0.013261236\n",
      "Iteration:  19600 , loss:  0.012514856\n",
      "Iteration:  19700 , loss:  0.012581401\n",
      "Iteration:  19800 , loss:  0.012471642\n",
      "Iteration:  19900 , loss:  0.012532521\n",
      "Generating 15th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  5.1367087\n",
      "Iteration:  100 , loss:  2.6400385\n",
      "Iteration:  200 , loss:  2.1949573\n",
      "Iteration:  300 , loss:  1.8497267\n",
      "Iteration:  400 , loss:  1.5700017\n",
      "Iteration:  500 , loss:  1.1436377\n",
      "Iteration:  600 , loss:  0.68031377\n",
      "Iteration:  700 , loss:  0.45297438\n",
      "Iteration:  800 , loss:  0.32734787\n",
      "Iteration:  900 , loss:  0.24482757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1000 , loss:  0.19428174\n",
      "Iteration:  1100 , loss:  0.1593022\n",
      "Iteration:  1200 , loss:  0.12832573\n",
      "Iteration:  1300 , loss:  0.11056567\n",
      "Iteration:  1400 , loss:  0.09989671\n",
      "Iteration:  1500 , loss:  0.10299632\n",
      "Iteration:  1600 , loss:  0.078614414\n",
      "Iteration:  1700 , loss:  0.071179375\n",
      "Iteration:  1800 , loss:  0.06503768\n",
      "Iteration:  1900 , loss:  0.060694125\n",
      "Iteration:  2000 , loss:  0.06501752\n",
      "Iteration:  2100 , loss:  0.0517718\n",
      "Iteration:  2200 , loss:  0.048956074\n",
      "Iteration:  2300 , loss:  0.045719456\n",
      "Iteration:  2400 , loss:  0.043449756\n",
      "Iteration:  2500 , loss:  0.041013032\n",
      "Iteration:  2600 , loss:  0.038931753\n",
      "Iteration:  2700 , loss:  0.03720069\n",
      "Iteration:  2800 , loss:  0.035457112\n",
      "Iteration:  2900 , loss:  0.034039512\n",
      "Iteration:  3000 , loss:  0.03261835\n",
      "Iteration:  3100 , loss:  0.031560965\n",
      "Iteration:  3200 , loss:  0.030354114\n",
      "Iteration:  3300 , loss:  0.03217444\n",
      "Iteration:  3400 , loss:  0.02842877\n",
      "Iteration:  3500 , loss:  0.03305043\n",
      "Iteration:  3600 , loss:  0.026834263\n",
      "Iteration:  3700 , loss:  0.026055379\n",
      "Iteration:  3800 , loss:  0.02547672\n",
      "Iteration:  3900 , loss:  0.024780218\n",
      "Iteration:  4000 , loss:  0.029194739\n",
      "Iteration:  4100 , loss:  0.023646722\n",
      "Iteration:  4200 , loss:  0.023118366\n",
      "Iteration:  4300 , loss:  0.022635719\n",
      "Iteration:  4400 , loss:  0.022109501\n",
      "Iteration:  4500 , loss:  0.02173288\n",
      "Iteration:  4600 , loss:  0.021247335\n",
      "Iteration:  4700 , loss:  0.021011673\n",
      "Iteration:  4800 , loss:  0.020463917\n",
      "Iteration:  4900 , loss:  0.039236464\n",
      "Iteration:  5000 , loss:  0.01976325\n",
      "Iteration:  5100 , loss:  0.019396493\n",
      "Iteration:  5200 , loss:  0.019177444\n",
      "Iteration:  5300 , loss:  0.018826464\n",
      "Iteration:  5400 , loss:  0.024060769\n",
      "Iteration:  5500 , loss:  0.018304527\n",
      "Iteration:  5600 , loss:  0.018024147\n",
      "Iteration:  5700 , loss:  0.017881276\n",
      "Iteration:  5800 , loss:  0.01759639\n",
      "Iteration:  5900 , loss:  0.018734295\n",
      "Iteration:  6000 , loss:  0.01722741\n",
      "Iteration:  6100 , loss:  0.017016595\n",
      "Iteration:  6200 , loss:  0.016915169\n",
      "Iteration:  6300 , loss:  0.01670304\n",
      "Iteration:  6400 , loss:  0.016739555\n",
      "Iteration:  6500 , loss:  0.01642514\n",
      "Iteration:  6600 , loss:  0.016261462\n",
      "Iteration:  6700 , loss:  0.016221382\n",
      "Iteration:  6800 , loss:  0.016025778\n",
      "Iteration:  6900 , loss:  0.017879004\n",
      "Iteration:  7000 , loss:  0.015810413\n",
      "Iteration:  7100 , loss:  0.035724804\n",
      "Iteration:  7200 , loss:  0.015610065\n",
      "Iteration:  7300 , loss:  0.015650567\n",
      "Iteration:  7400 , loss:  0.015435684\n",
      "Iteration:  7500 , loss:  0.015317074\n",
      "Iteration:  7600 , loss:  0.015295329\n",
      "Iteration:  7700 , loss:  0.015166071\n",
      "Iteration:  7800 , loss:  0.045512997\n",
      "Iteration:  7900 , loss:  0.015013792\n",
      "Iteration:  8000 , loss:  0.015442543\n",
      "Iteration:  8100 , loss:  0.014883047\n",
      "Iteration:  8200 , loss:  0.014785456\n",
      "Iteration:  8300 , loss:  0.014830627\n",
      "Iteration:  8400 , loss:  0.014659412\n",
      "Iteration:  8500 , loss:  0.021451067\n",
      "Iteration:  8600 , loss:  0.014550654\n",
      "Iteration:  8700 , loss:  0.014473958\n",
      "Iteration:  8800 , loss:  0.014499789\n",
      "Iteration:  8900 , loss:  0.014371596\n",
      "Iteration:  9000 , loss:  0.014426908\n",
      "Iteration:  9100 , loss:  0.014296124\n",
      "Iteration:  9200 , loss:  0.014237592\n",
      "Iteration:  9300 , loss:  0.01422584\n",
      "Iteration:  9400 , loss:  0.014158668\n",
      "Iteration:  9500 , loss:  0.014185144\n",
      "Iteration:  9600 , loss:  0.014086539\n",
      "Iteration:  9700 , loss:  0.014128668\n",
      "Iteration:  9800 , loss:  0.014016439\n",
      "Iteration:  9900 , loss:  0.01410022\n",
      "Iteration:  10000 , loss:  0.013950441\n",
      "Iteration:  10100 , loss:  0.014164213\n",
      "Iteration:  10200 , loss:  0.013893158\n",
      "Iteration:  10300 , loss:  0.015948456\n",
      "Iteration:  10400 , loss:  0.0138378795\n",
      "Iteration:  10500 , loss:  0.014010375\n",
      "Iteration:  10600 , loss:  0.013797054\n",
      "Iteration:  10700 , loss:  0.013749184\n",
      "Iteration:  10800 , loss:  0.014910833\n",
      "Iteration:  10900 , loss:  0.013705333\n",
      "Iteration:  11000 , loss:  0.013709722\n",
      "Iteration:  11100 , loss:  0.013664061\n",
      "Iteration:  11200 , loss:  0.013618998\n",
      "Iteration:  11300 , loss:  0.0136497775\n",
      "Iteration:  11400 , loss:  0.013579701\n",
      "Iteration:  11500 , loss:  0.016593546\n",
      "Iteration:  11600 , loss:  0.01353483\n",
      "Iteration:  11700 , loss:  0.016321858\n",
      "Iteration:  11800 , loss:  0.013495365\n",
      "Iteration:  11900 , loss:  0.016104005\n",
      "Iteration:  12000 , loss:  0.013458429\n",
      "Iteration:  12100 , loss:  0.013422685\n",
      "Iteration:  12200 , loss:  0.01343132\n",
      "Iteration:  12300 , loss:  0.013383251\n",
      "Iteration:  12400 , loss:  0.013426391\n",
      "Iteration:  12500 , loss:  0.013349193\n",
      "Iteration:  12600 , loss:  0.013821658\n",
      "Iteration:  12700 , loss:  0.013311253\n",
      "Iteration:  12800 , loss:  0.013728975\n",
      "Iteration:  12900 , loss:  0.013278445\n",
      "Iteration:  13000 , loss:  0.017002944\n",
      "Iteration:  13100 , loss:  0.013240194\n",
      "Iteration:  13200 , loss:  0.015083255\n",
      "Iteration:  13300 , loss:  0.013205968\n",
      "Iteration:  13400 , loss:  0.015377532\n",
      "Iteration:  13500 , loss:  0.013173109\n",
      "Iteration:  13600 , loss:  0.015033741\n",
      "Iteration:  13700 , loss:  0.013139963\n",
      "Iteration:  13800 , loss:  0.030184431\n",
      "Iteration:  13900 , loss:  0.013112258\n",
      "Iteration:  14000 , loss:  0.013083462\n",
      "Iteration:  14100 , loss:  0.013092992\n",
      "Iteration:  14200 , loss:  0.013050836\n",
      "Iteration:  14300 , loss:  0.0130729005\n",
      "Iteration:  14400 , loss:  0.013022059\n",
      "Iteration:  14500 , loss:  0.013125939\n",
      "Iteration:  14600 , loss:  0.012989721\n",
      "Iteration:  14700 , loss:  0.013146515\n",
      "Iteration:  14800 , loss:  0.012969666\n",
      "Iteration:  14900 , loss:  0.015966525\n",
      "Iteration:  15000 , loss:  0.012930876\n",
      "Iteration:  15100 , loss:  0.012985917\n",
      "Iteration:  15200 , loss:  0.01289979\n",
      "Iteration:  15300 , loss:  0.012905403\n",
      "Iteration:  15400 , loss:  0.012899175\n",
      "Iteration:  15500 , loss:  0.01287481\n",
      "Iteration:  15600 , loss:  0.012844052\n",
      "Iteration:  15700 , loss:  0.012849538\n",
      "Iteration:  15800 , loss:  0.012816308\n",
      "Iteration:  15900 , loss:  0.012817684\n",
      "Iteration:  16000 , loss:  0.012990374\n",
      "Iteration:  16100 , loss:  0.012783663\n",
      "Iteration:  16200 , loss:  0.022502044\n",
      "Iteration:  16300 , loss:  0.012759221\n",
      "Iteration:  16400 , loss:  0.012806394\n",
      "Iteration:  16500 , loss:  0.012733746\n",
      "Iteration:  16600 , loss:  0.012722943\n",
      "Iteration:  16700 , loss:  0.012712195\n",
      "Iteration:  16800 , loss:  0.012786754\n",
      "Iteration:  16900 , loss:  0.012679243\n",
      "Iteration:  17000 , loss:  0.012669971\n",
      "Iteration:  17100 , loss:  0.04957521\n",
      "Iteration:  17200 , loss:  0.012660082\n",
      "Iteration:  17300 , loss:  0.01263047\n",
      "Iteration:  17400 , loss:  0.014507076\n",
      "Iteration:  17500 , loss:  0.012604862\n",
      "Iteration:  17600 , loss:  0.01280487\n",
      "Iteration:  17700 , loss:  0.012581807\n",
      "Iteration:  17800 , loss:  0.013039063\n",
      "Iteration:  17900 , loss:  0.012561772\n",
      "Iteration:  18000 , loss:  0.016296454\n",
      "Iteration:  18100 , loss:  0.012536673\n",
      "Iteration:  18200 , loss:  0.012661752\n",
      "Iteration:  18300 , loss:  0.01251409\n",
      "Iteration:  18400 , loss:  0.012622623\n",
      "Iteration:  18500 , loss:  0.012493014\n",
      "Iteration:  18600 , loss:  0.012873648\n",
      "Iteration:  18700 , loss:  0.0124681555\n",
      "Iteration:  18800 , loss:  0.012534879\n",
      "Iteration:  18900 , loss:  0.012450462\n",
      "Iteration:  19000 , loss:  0.013546898\n",
      "Iteration:  19100 , loss:  0.012430111\n",
      "Iteration:  19200 , loss:  0.017628882\n",
      "Iteration:  19300 , loss:  0.0124139525\n",
      "Iteration:  19400 , loss:  0.013248564\n",
      "Iteration:  19500 , loss:  0.012385683\n",
      "Iteration:  19600 , loss:  0.012501046\n",
      "Iteration:  19700 , loss:  0.012363569\n",
      "Iteration:  19800 , loss:  0.012379203\n",
      "Iteration:  19900 , loss:  0.012343643\n",
      "Generating 16th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.6075468\n",
      "Iteration:  100 , loss:  2.2479146\n",
      "Iteration:  200 , loss:  1.7178719\n",
      "Iteration:  300 , loss:  1.0712155\n",
      "Iteration:  400 , loss:  0.3649246\n",
      "Iteration:  500 , loss:  0.21398017\n",
      "Iteration:  600 , loss:  0.16402802\n",
      "Iteration:  700 , loss:  0.13511257\n",
      "Iteration:  800 , loss:  0.11916494\n",
      "Iteration:  900 , loss:  0.100405306\n",
      "Iteration:  1000 , loss:  0.08837533\n",
      "Iteration:  1100 , loss:  0.075221255\n",
      "Iteration:  1200 , loss:  0.06669199\n",
      "Iteration:  1300 , loss:  0.058662005\n",
      "Iteration:  1400 , loss:  0.053616893\n",
      "Iteration:  1500 , loss:  0.048409168\n",
      "Iteration:  1600 , loss:  0.04412342\n",
      "Iteration:  1700 , loss:  0.041639227\n",
      "Iteration:  1800 , loss:  0.038297012\n",
      "Iteration:  1900 , loss:  0.037478104\n",
      "Iteration:  2000 , loss:  0.033994317\n",
      "Iteration:  2100 , loss:  0.032269202\n",
      "Iteration:  2200 , loss:  0.030630898\n",
      "Iteration:  2300 , loss:  0.02937359\n",
      "Iteration:  2400 , loss:  0.027993392\n",
      "Iteration:  2500 , loss:  0.026961569\n",
      "Iteration:  2600 , loss:  0.025845358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2700 , loss:  0.025005382\n",
      "Iteration:  2800 , loss:  0.02410444\n",
      "Iteration:  2900 , loss:  0.024995968\n",
      "Iteration:  3000 , loss:  0.022656132\n",
      "Iteration:  3100 , loss:  0.021984307\n",
      "Iteration:  3200 , loss:  0.021456376\n",
      "Iteration:  3300 , loss:  0.020875901\n",
      "Iteration:  3400 , loss:  0.02048283\n",
      "Iteration:  3500 , loss:  0.019954113\n",
      "Iteration:  3600 , loss:  0.01993752\n",
      "Iteration:  3700 , loss:  0.019195989\n",
      "Iteration:  3800 , loss:  0.019800304\n",
      "Iteration:  3900 , loss:  0.018659452\n",
      "Iteration:  4000 , loss:  0.018312031\n",
      "Iteration:  4100 , loss:  0.018771745\n",
      "Iteration:  4200 , loss:  0.017769953\n",
      "Iteration:  4300 , loss:  0.03075061\n",
      "Iteration:  4400 , loss:  0.01734915\n",
      "Iteration:  4500 , loss:  0.017135253\n",
      "Iteration:  4600 , loss:  0.016997663\n",
      "Iteration:  4700 , loss:  0.016786736\n",
      "Iteration:  4800 , loss:  0.01673742\n",
      "Iteration:  4900 , loss:  0.016489098\n",
      "Iteration:  5000 , loss:  0.016344782\n",
      "Iteration:  5100 , loss:  0.016223958\n",
      "Iteration:  5200 , loss:  0.016073905\n",
      "Iteration:  5300 , loss:  0.016042305\n",
      "Iteration:  5400 , loss:  0.01583391\n",
      "Iteration:  5500 , loss:  0.015768431\n",
      "Iteration:  5600 , loss:  0.015620459\n",
      "Iteration:  5700 , loss:  0.01561014\n",
      "Iteration:  5800 , loss:  0.01543123\n",
      "Iteration:  5900 , loss:  0.016011363\n",
      "Iteration:  6000 , loss:  0.015264313\n",
      "Iteration:  6100 , loss:  0.016264994\n",
      "Iteration:  6200 , loss:  0.015117057\n",
      "Iteration:  6300 , loss:  0.015026582\n",
      "Iteration:  6400 , loss:  0.015041446\n",
      "Iteration:  6500 , loss:  0.014890234\n",
      "Iteration:  6600 , loss:  0.014899898\n",
      "Iteration:  6700 , loss:  0.014770042\n",
      "Iteration:  6800 , loss:  0.017393997\n",
      "Iteration:  6900 , loss:  0.014657937\n",
      "Iteration:  7000 , loss:  0.022028308\n",
      "Iteration:  7100 , loss:  0.014566474\n",
      "Iteration:  7200 , loss:  0.014500348\n",
      "Iteration:  7300 , loss:  0.01550537\n",
      "Iteration:  7400 , loss:  0.014407821\n",
      "Iteration:  7500 , loss:  0.015731746\n",
      "Iteration:  7600 , loss:  0.014322279\n",
      "Iteration:  7700 , loss:  0.0396392\n",
      "Iteration:  7800 , loss:  0.014248971\n",
      "Iteration:  7900 , loss:  0.014197223\n",
      "Iteration:  8000 , loss:  0.014217753\n",
      "Iteration:  8100 , loss:  0.014124696\n",
      "Iteration:  8200 , loss:  0.0142387\n",
      "Iteration:  8300 , loss:  0.014057368\n",
      "Iteration:  8400 , loss:  0.015244411\n",
      "Iteration:  8500 , loss:  0.014000001\n",
      "Iteration:  8600 , loss:  0.013956897\n",
      "Iteration:  8700 , loss:  0.013997661\n",
      "Iteration:  8800 , loss:  0.013898694\n",
      "Iteration:  8900 , loss:  0.014655096\n",
      "Iteration:  9000 , loss:  0.013847853\n",
      "Iteration:  9100 , loss:  0.0138095245\n",
      "Iteration:  9200 , loss:  0.013805877\n",
      "Iteration:  9300 , loss:  0.013754632\n",
      "Iteration:  9400 , loss:  0.013771769\n",
      "Iteration:  9500 , loss:  0.0137035195\n",
      "Iteration:  9600 , loss:  0.013763655\n",
      "Iteration:  9700 , loss:  0.013653442\n",
      "Iteration:  9800 , loss:  0.014000516\n",
      "Iteration:  9900 , loss:  0.013607643\n",
      "Iteration:  10000 , loss:  0.016030477\n",
      "Iteration:  10100 , loss:  0.013562815\n",
      "Iteration:  10200 , loss:  0.01355139\n",
      "Iteration:  10300 , loss:  0.013523232\n",
      "Iteration:  10400 , loss:  0.013485827\n",
      "Iteration:  10500 , loss:  0.013540755\n",
      "Iteration:  10600 , loss:  0.013448125\n",
      "Iteration:  10700 , loss:  0.02246409\n",
      "Iteration:  10800 , loss:  0.01341209\n",
      "Iteration:  10900 , loss:  0.013383752\n",
      "Iteration:  11000 , loss:  0.013382154\n",
      "Iteration:  11100 , loss:  0.013342906\n",
      "Iteration:  11200 , loss:  0.01339331\n",
      "Iteration:  11300 , loss:  0.01330911\n",
      "Iteration:  11400 , loss:  0.014979209\n",
      "Iteration:  11500 , loss:  0.013280179\n",
      "Iteration:  11600 , loss:  0.013253106\n",
      "Iteration:  11700 , loss:  0.013327824\n",
      "Iteration:  11800 , loss:  0.013224797\n",
      "Iteration:  11900 , loss:  0.013203902\n",
      "Iteration:  12000 , loss:  0.01321963\n",
      "Iteration:  12100 , loss:  0.013177976\n",
      "Iteration:  12200 , loss:  0.013174005\n",
      "Iteration:  12300 , loss:  0.013155306\n",
      "Iteration:  12400 , loss:  0.013131021\n",
      "Iteration:  12500 , loss:  0.013129059\n",
      "Iteration:  12600 , loss:  0.01309669\n",
      "Iteration:  12700 , loss:  0.013133573\n",
      "Iteration:  12800 , loss:  0.013070125\n",
      "Iteration:  12900 , loss:  0.013134135\n",
      "Iteration:  13000 , loss:  0.013044158\n",
      "Iteration:  13100 , loss:  0.01317902\n",
      "Iteration:  13200 , loss:  0.013018538\n",
      "Iteration:  13300 , loss:  0.013033323\n",
      "Iteration:  13400 , loss:  0.0130135305\n",
      "Iteration:  13500 , loss:  0.012979427\n",
      "Iteration:  13600 , loss:  0.012989286\n",
      "Iteration:  13700 , loss:  0.012962395\n",
      "Iteration:  13800 , loss:  0.012936478\n",
      "Iteration:  13900 , loss:  0.012943862\n",
      "Iteration:  14000 , loss:  0.012912339\n",
      "Iteration:  14100 , loss:  0.0129810255\n",
      "Iteration:  14200 , loss:  0.012891566\n",
      "Iteration:  14300 , loss:  0.013229408\n",
      "Iteration:  14400 , loss:  0.012870566\n",
      "Iteration:  14500 , loss:  0.01587847\n",
      "Iteration:  14600 , loss:  0.012851248\n",
      "Iteration:  14700 , loss:  0.012829272\n",
      "Iteration:  14800 , loss:  0.012839097\n",
      "Iteration:  14900 , loss:  0.012808399\n",
      "Iteration:  15000 , loss:  0.012825912\n",
      "Iteration:  15100 , loss:  0.01278614\n",
      "Iteration:  15200 , loss:  0.012874596\n",
      "Iteration:  15300 , loss:  0.012767859\n",
      "Iteration:  15400 , loss:  0.022925926\n",
      "Iteration:  15500 , loss:  0.01275086\n",
      "Iteration:  15600 , loss:  0.0127309365\n",
      "Iteration:  15700 , loss:  0.012746222\n",
      "Iteration:  15800 , loss:  0.0127127785\n",
      "Iteration:  15900 , loss:  0.01344692\n",
      "Iteration:  16000 , loss:  0.012693697\n",
      "Iteration:  16100 , loss:  0.013122059\n",
      "Iteration:  16200 , loss:  0.0126761105\n",
      "Iteration:  16300 , loss:  0.013053897\n",
      "Iteration:  16400 , loss:  0.012661325\n",
      "Iteration:  16500 , loss:  0.012639076\n",
      "Iteration:  16600 , loss:  0.0126534365\n",
      "Iteration:  16700 , loss:  0.012620816\n",
      "Iteration:  16800 , loss:  0.01301806\n",
      "Iteration:  16900 , loss:  0.012609765\n",
      "Iteration:  17000 , loss:  0.012591166\n",
      "Iteration:  17100 , loss:  0.012629617\n",
      "Iteration:  17200 , loss:  0.01256996\n",
      "Iteration:  17300 , loss:  0.01258507\n",
      "Iteration:  17400 , loss:  0.012553833\n",
      "Iteration:  17500 , loss:  0.01413708\n",
      "Iteration:  17600 , loss:  0.012537515\n",
      "Iteration:  17700 , loss:  0.024850033\n",
      "Iteration:  17800 , loss:  0.012521437\n",
      "Iteration:  17900 , loss:  0.012502907\n",
      "Iteration:  18000 , loss:  0.012526457\n",
      "Iteration:  18100 , loss:  0.012488461\n",
      "Iteration:  18200 , loss:  0.013065238\n",
      "Iteration:  18300 , loss:  0.0124749765\n",
      "Iteration:  18400 , loss:  0.012457218\n",
      "Iteration:  18500 , loss:  0.012483709\n",
      "Iteration:  18600 , loss:  0.012439873\n",
      "Iteration:  18700 , loss:  0.012470687\n",
      "Iteration:  18800 , loss:  0.012421748\n",
      "Iteration:  18900 , loss:  0.012487652\n",
      "Iteration:  19000 , loss:  0.012402372\n",
      "Iteration:  19100 , loss:  0.012433419\n",
      "Iteration:  19200 , loss:  0.0123881865\n",
      "Iteration:  19300 , loss:  0.021723099\n",
      "Iteration:  19400 , loss:  0.012375621\n",
      "Iteration:  19500 , loss:  0.012357028\n",
      "Iteration:  19600 , loss:  0.012388086\n",
      "Iteration:  19700 , loss:  0.012339967\n",
      "Iteration:  19800 , loss:  0.012346864\n",
      "Iteration:  19900 , loss:  0.012355873\n",
      "Generating 17th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.5973327\n",
      "Iteration:  100 , loss:  2.2196333\n",
      "Iteration:  200 , loss:  1.6990955\n",
      "Iteration:  300 , loss:  0.983975\n",
      "Iteration:  400 , loss:  0.30197573\n",
      "Iteration:  500 , loss:  0.19407912\n",
      "Iteration:  600 , loss:  0.15205608\n",
      "Iteration:  700 , loss:  0.12471224\n",
      "Iteration:  800 , loss:  0.10314772\n",
      "Iteration:  900 , loss:  0.086464435\n",
      "Iteration:  1000 , loss:  0.07415187\n",
      "Iteration:  1100 , loss:  0.06477061\n",
      "Iteration:  1200 , loss:  0.05790747\n",
      "Iteration:  1300 , loss:  0.08251004\n",
      "Iteration:  1400 , loss:  0.04651839\n",
      "Iteration:  1500 , loss:  0.042909697\n",
      "Iteration:  1600 , loss:  0.039472014\n",
      "Iteration:  1700 , loss:  0.036919694\n",
      "Iteration:  1800 , loss:  0.058580525\n",
      "Iteration:  1900 , loss:  0.032706663\n",
      "Iteration:  2000 , loss:  0.03304783\n",
      "Iteration:  2100 , loss:  0.029465698\n",
      "Iteration:  2200 , loss:  0.03224556\n",
      "Iteration:  2300 , loss:  0.026985265\n",
      "Iteration:  2400 , loss:  0.025895858\n",
      "Iteration:  2500 , loss:  0.026216596\n",
      "Iteration:  2600 , loss:  0.02417574\n",
      "Iteration:  2700 , loss:  0.023392845\n",
      "Iteration:  2800 , loss:  0.022784036\n",
      "Iteration:  2900 , loss:  0.02213462\n",
      "Iteration:  3000 , loss:  0.021682302\n",
      "Iteration:  3100 , loss:  0.021122366\n",
      "Iteration:  3200 , loss:  0.020785443\n",
      "Iteration:  3300 , loss:  0.020310262\n",
      "Iteration:  3400 , loss:  0.02156761\n",
      "Iteration:  3500 , loss:  0.019645536\n",
      "Iteration:  3600 , loss:  0.024214385\n",
      "Iteration:  3700 , loss:  0.019097365\n",
      "Iteration:  3800 , loss:  0.026951885\n",
      "Iteration:  3900 , loss:  0.018643256\n",
      "Iteration:  4000 , loss:  0.018441655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4100 , loss:  0.018266428\n",
      "Iteration:  4200 , loss:  0.018063232\n",
      "Iteration:  4300 , loss:  0.018185819\n",
      "Iteration:  4400 , loss:  0.017771356\n",
      "Iteration:  4500 , loss:  0.017620925\n",
      "Iteration:  4600 , loss:  0.017523771\n",
      "Iteration:  4700 , loss:  0.017365746\n",
      "Iteration:  4800 , loss:  0.018953465\n",
      "Iteration:  4900 , loss:  0.017154843\n",
      "Iteration:  5000 , loss:  0.017028507\n",
      "Iteration:  5100 , loss:  0.016978387\n",
      "Iteration:  5200 , loss:  0.01684013\n",
      "Iteration:  5300 , loss:  0.016803103\n",
      "Iteration:  5400 , loss:  0.016672563\n",
      "Iteration:  5500 , loss:  0.018160528\n",
      "Iteration:  5600 , loss:  0.016515361\n",
      "Iteration:  5700 , loss:  0.02500832\n",
      "Iteration:  5800 , loss:  0.016373726\n",
      "Iteration:  5900 , loss:  0.016281575\n",
      "Iteration:  6000 , loss:  0.016248286\n",
      "Iteration:  6100 , loss:  0.016151119\n",
      "Iteration:  6200 , loss:  0.01618679\n",
      "Iteration:  6300 , loss:  0.01603685\n",
      "Iteration:  6400 , loss:  0.017700689\n",
      "Iteration:  6500 , loss:  0.015933933\n",
      "Iteration:  6600 , loss:  0.015856702\n",
      "Iteration:  6700 , loss:  0.015939645\n",
      "Iteration:  6800 , loss:  0.01575824\n",
      "Iteration:  6900 , loss:  0.017264301\n",
      "Iteration:  7000 , loss:  0.015671171\n",
      "Iteration:  7100 , loss:  0.015599571\n",
      "Iteration:  7200 , loss:  0.015851649\n",
      "Iteration:  7300 , loss:  0.015511736\n",
      "Iteration:  7400 , loss:  0.015621139\n",
      "Iteration:  7500 , loss:  0.015431405\n",
      "Iteration:  7600 , loss:  0.0153706\n",
      "Iteration:  7700 , loss:  0.015380379\n",
      "Iteration:  7800 , loss:  0.015299503\n",
      "Iteration:  7900 , loss:  0.015386549\n",
      "Iteration:  8000 , loss:  0.015235079\n",
      "Iteration:  8100 , loss:  0.01517235\n",
      "Iteration:  8200 , loss:  0.015302584\n",
      "Iteration:  8300 , loss:  0.015097724\n",
      "Iteration:  8400 , loss:  0.015153567\n",
      "Iteration:  8500 , loss:  0.01502886\n",
      "Iteration:  8600 , loss:  0.02548631\n",
      "Iteration:  8700 , loss:  0.014961496\n",
      "Iteration:  8800 , loss:  0.015955929\n",
      "Iteration:  8900 , loss:  0.014899032\n",
      "Iteration:  9000 , loss:  0.014846818\n",
      "Iteration:  9100 , loss:  0.014848089\n",
      "Iteration:  9200 , loss:  0.01478451\n",
      "Iteration:  9300 , loss:  0.014829387\n",
      "Iteration:  9400 , loss:  0.014724862\n",
      "Iteration:  9500 , loss:  0.016596738\n",
      "Iteration:  9600 , loss:  0.014676563\n",
      "Iteration:  9700 , loss:  0.014632195\n",
      "Iteration:  9800 , loss:  0.014675359\n",
      "Iteration:  9900 , loss:  0.014576699\n",
      "Iteration:  10000 , loss:  0.01458006\n",
      "Iteration:  10100 , loss:  0.014522994\n",
      "Iteration:  10200 , loss:  0.014603902\n",
      "Iteration:  10300 , loss:  0.014470816\n",
      "Iteration:  10400 , loss:  0.014953686\n",
      "Iteration:  10500 , loss:  0.014422791\n",
      "Iteration:  10600 , loss:  0.031592738\n",
      "Iteration:  10700 , loss:  0.014384087\n",
      "Iteration:  10800 , loss:  0.01434424\n",
      "Iteration:  10900 , loss:  0.014445735\n",
      "Iteration:  11000 , loss:  0.014301282\n",
      "Iteration:  11100 , loss:  0.015884029\n",
      "Iteration:  11200 , loss:  0.01426151\n",
      "Iteration:  11300 , loss:  0.014495755\n",
      "Iteration:  11400 , loss:  0.014233202\n",
      "Iteration:  11500 , loss:  0.014192216\n",
      "Iteration:  11600 , loss:  0.014632819\n",
      "Iteration:  11700 , loss:  0.014151981\n",
      "Iteration:  11800 , loss:  0.015019355\n",
      "Iteration:  11900 , loss:  0.014114183\n",
      "Iteration:  12000 , loss:  0.01818325\n",
      "Iteration:  12100 , loss:  0.01407807\n",
      "Iteration:  12200 , loss:  0.036927238\n",
      "Iteration:  12300 , loss:  0.014047513\n",
      "Iteration:  12400 , loss:  0.014013318\n",
      "Iteration:  12500 , loss:  0.014030773\n",
      "Iteration:  12600 , loss:  0.013976409\n",
      "Iteration:  12700 , loss:  0.0140029155\n",
      "Iteration:  12800 , loss:  0.013943161\n",
      "Iteration:  12900 , loss:  0.013994743\n",
      "Iteration:  13000 , loss:  0.013905659\n",
      "Iteration:  13100 , loss:  0.013912016\n",
      "Iteration:  13200 , loss:  0.013872668\n",
      "Iteration:  13300 , loss:  0.014046829\n",
      "Iteration:  13400 , loss:  0.013839556\n",
      "Iteration:  13500 , loss:  0.013974508\n",
      "Iteration:  13600 , loss:  0.013807765\n",
      "Iteration:  13700 , loss:  0.015706338\n",
      "Iteration:  13800 , loss:  0.01378111\n",
      "Iteration:  13900 , loss:  0.013749803\n",
      "Iteration:  14000 , loss:  0.013763615\n",
      "Iteration:  14100 , loss:  0.013718497\n",
      "Iteration:  14200 , loss:  0.014674613\n",
      "Iteration:  14300 , loss:  0.013694938\n",
      "Iteration:  14400 , loss:  0.013664957\n",
      "Iteration:  14500 , loss:  0.013732381\n",
      "Iteration:  14600 , loss:  0.013635104\n",
      "Iteration:  14700 , loss:  0.014565916\n",
      "Iteration:  14800 , loss:  0.013605537\n",
      "Iteration:  14900 , loss:  0.01368474\n",
      "Iteration:  15000 , loss:  0.013584003\n",
      "Iteration:  15100 , loss:  0.013546944\n",
      "Iteration:  15200 , loss:  0.013997255\n",
      "Iteration:  15300 , loss:  0.013518294\n",
      "Iteration:  15400 , loss:  0.025758555\n",
      "Iteration:  15500 , loss:  0.013490368\n",
      "Iteration:  15600 , loss:  0.013458163\n",
      "Iteration:  15700 , loss:  0.01347952\n",
      "Iteration:  15800 , loss:  0.013425041\n",
      "Iteration:  15900 , loss:  0.013513086\n",
      "Iteration:  16000 , loss:  0.013394416\n",
      "Iteration:  16100 , loss:  0.0143900085\n",
      "Iteration:  16200 , loss:  0.013365114\n",
      "Iteration:  16300 , loss:  0.013408982\n",
      "Iteration:  16400 , loss:  0.013344009\n",
      "Iteration:  16500 , loss:  0.013307404\n",
      "Iteration:  16600 , loss:  0.013341107\n",
      "Iteration:  16700 , loss:  0.013274895\n",
      "Iteration:  16800 , loss:  0.013665685\n",
      "Iteration:  16900 , loss:  0.013242394\n",
      "Iteration:  17000 , loss:  0.013506174\n",
      "Iteration:  17100 , loss:  0.0132092815\n",
      "Iteration:  17200 , loss:  0.013704067\n",
      "Iteration:  17300 , loss:  0.013175609\n",
      "Iteration:  17400 , loss:  0.013974028\n",
      "Iteration:  17500 , loss:  0.013140814\n",
      "Iteration:  17600 , loss:  0.0139773665\n",
      "Iteration:  17700 , loss:  0.013111033\n",
      "Iteration:  17800 , loss:  0.03620471\n",
      "Iteration:  17900 , loss:  0.013081548\n",
      "Iteration:  18000 , loss:  0.013058977\n",
      "Iteration:  18100 , loss:  0.013051422\n",
      "Iteration:  18200 , loss:  0.013067588\n",
      "Iteration:  18300 , loss:  0.013012886\n",
      "Iteration:  18400 , loss:  0.012989152\n",
      "Iteration:  18500 , loss:  0.012982924\n",
      "Iteration:  18600 , loss:  0.012948832\n",
      "Iteration:  18700 , loss:  0.012996849\n",
      "Iteration:  18800 , loss:  0.012915134\n",
      "Iteration:  18900 , loss:  0.013214242\n",
      "Iteration:  19000 , loss:  0.012877262\n",
      "Iteration:  19100 , loss:  0.013243932\n",
      "Iteration:  19200 , loss:  0.012843935\n",
      "Iteration:  19300 , loss:  0.013209312\n",
      "Iteration:  19400 , loss:  0.012810093\n",
      "Iteration:  19500 , loss:  0.012774188\n",
      "Iteration:  19600 , loss:  0.012784505\n",
      "Iteration:  19700 , loss:  0.012735033\n",
      "Iteration:  19800 , loss:  0.013023096\n",
      "Iteration:  19900 , loss:  0.012697476\n",
      "Generating 18th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  4.3520074\n",
      "Iteration:  100 , loss:  2.6713822\n",
      "Iteration:  200 , loss:  2.0475745\n",
      "Iteration:  300 , loss:  1.663002\n",
      "Iteration:  400 , loss:  1.1926934\n",
      "Iteration:  500 , loss:  0.6700817\n",
      "Iteration:  600 , loss:  0.44729146\n",
      "Iteration:  700 , loss:  0.33386242\n",
      "Iteration:  800 , loss:  0.26849756\n",
      "Iteration:  900 , loss:  0.22337876\n",
      "Iteration:  1000 , loss:  0.18748084\n",
      "Iteration:  1100 , loss:  0.15596282\n",
      "Iteration:  1200 , loss:  0.1415546\n",
      "Iteration:  1300 , loss:  0.101568975\n",
      "Iteration:  1400 , loss:  0.086307734\n",
      "Iteration:  1500 , loss:  0.07444265\n",
      "Iteration:  1600 , loss:  0.06729768\n",
      "Iteration:  1700 , loss:  0.05787616\n",
      "Iteration:  1800 , loss:  0.05212267\n",
      "Iteration:  1900 , loss:  0.047736257\n",
      "Iteration:  2000 , loss:  0.043232176\n",
      "Iteration:  2100 , loss:  0.039987374\n",
      "Iteration:  2200 , loss:  0.036799707\n",
      "Iteration:  2300 , loss:  0.034727726\n",
      "Iteration:  2400 , loss:  0.03207117\n",
      "Iteration:  2500 , loss:  0.033885524\n",
      "Iteration:  2600 , loss:  0.02868759\n",
      "Iteration:  2700 , loss:  0.027256047\n",
      "Iteration:  2800 , loss:  0.026208876\n",
      "Iteration:  2900 , loss:  0.025005084\n",
      "Iteration:  3000 , loss:  0.024289325\n",
      "Iteration:  3100 , loss:  0.023229197\n",
      "Iteration:  3200 , loss:  0.024964392\n",
      "Iteration:  3300 , loss:  0.021789113\n",
      "Iteration:  3400 , loss:  0.021130186\n",
      "Iteration:  3500 , loss:  0.020633984\n",
      "Iteration:  3600 , loss:  0.020070666\n",
      "Iteration:  3700 , loss:  0.019694544\n",
      "Iteration:  3800 , loss:  0.019193966\n",
      "Iteration:  3900 , loss:  0.020135595\n",
      "Iteration:  4000 , loss:  0.018468821\n",
      "Iteration:  4100 , loss:  0.018092226\n",
      "Iteration:  4200 , loss:  0.017939603\n",
      "Iteration:  4300 , loss:  0.017573921\n",
      "Iteration:  4400 , loss:  0.017276188\n",
      "Iteration:  4500 , loss:  0.01719067\n",
      "Iteration:  4600 , loss:  0.016823135\n",
      "Iteration:  4700 , loss:  0.038313642\n",
      "Iteration:  4800 , loss:  0.016431592\n",
      "Iteration:  4900 , loss:  0.016208757\n",
      "Iteration:  5000 , loss:  0.016127627\n",
      "Iteration:  5100 , loss:  0.015881341\n",
      "Iteration:  5200 , loss:  0.016814789\n",
      "Iteration:  5300 , loss:  0.015595667\n",
      "Iteration:  5400 , loss:  0.015436364\n",
      "Iteration:  5500 , loss:  0.015361184\n",
      "Iteration:  5600 , loss:  0.015211102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  5700 , loss:  0.016058931\n",
      "Iteration:  5800 , loss:  0.015008982\n",
      "Iteration:  5900 , loss:  0.026722776\n",
      "Iteration:  6000 , loss:  0.014848068\n",
      "Iteration:  6100 , loss:  0.014741201\n",
      "Iteration:  6200 , loss:  0.014737451\n",
      "Iteration:  6300 , loss:  0.014601608\n",
      "Iteration:  6400 , loss:  0.018495101\n",
      "Iteration:  6500 , loss:  0.014475724\n",
      "Iteration:  6600 , loss:  0.04478153\n",
      "Iteration:  6700 , loss:  0.014363025\n",
      "Iteration:  6800 , loss:  0.014292993\n",
      "Iteration:  6900 , loss:  0.014279606\n",
      "Iteration:  7000 , loss:  0.0141978\n",
      "Iteration:  7100 , loss:  0.015418267\n",
      "Iteration:  7200 , loss:  0.01411251\n",
      "Iteration:  7300 , loss:  0.014487782\n",
      "Iteration:  7400 , loss:  0.014040454\n",
      "Iteration:  7500 , loss:  0.01397383\n",
      "Iteration:  7600 , loss:  0.014460599\n",
      "Iteration:  7700 , loss:  0.013906224\n",
      "Iteration:  7800 , loss:  0.013847976\n",
      "Iteration:  7900 , loss:  0.013866481\n",
      "Iteration:  8000 , loss:  0.013797285\n",
      "Iteration:  8100 , loss:  0.013743414\n",
      "Iteration:  8200 , loss:  0.013768601\n",
      "Iteration:  8300 , loss:  0.0136960745\n",
      "Iteration:  8400 , loss:  0.015865767\n",
      "Iteration:  8500 , loss:  0.013637363\n",
      "Iteration:  8600 , loss:  0.01359176\n",
      "Iteration:  8700 , loss:  0.013585258\n",
      "Iteration:  8800 , loss:  0.013530764\n",
      "Iteration:  8900 , loss:  0.013585467\n",
      "Iteration:  9000 , loss:  0.013483306\n",
      "Iteration:  9100 , loss:  0.026573189\n",
      "Iteration:  9200 , loss:  0.01344002\n",
      "Iteration:  9300 , loss:  0.013390545\n",
      "Iteration:  9400 , loss:  0.013463477\n",
      "Iteration:  9500 , loss:  0.0133469775\n",
      "Iteration:  9600 , loss:  0.0198951\n",
      "Iteration:  9700 , loss:  0.013300012\n",
      "Iteration:  9800 , loss:  0.013255209\n",
      "Iteration:  9900 , loss:  0.013260985\n",
      "Iteration:  10000 , loss:  0.013204702\n",
      "Iteration:  10100 , loss:  0.01328495\n",
      "Iteration:  10200 , loss:  0.013155564\n",
      "Iteration:  10300 , loss:  0.014417681\n",
      "Iteration:  10400 , loss:  0.013108144\n",
      "Iteration:  10500 , loss:  0.03174147\n",
      "Iteration:  10600 , loss:  0.013066094\n",
      "Iteration:  10700 , loss:  0.013017774\n",
      "Iteration:  10800 , loss:  0.013059668\n",
      "Iteration:  10900 , loss:  0.01298281\n",
      "Iteration:  11000 , loss:  0.013230656\n",
      "Iteration:  11100 , loss:  0.012948321\n",
      "Iteration:  11200 , loss:  0.012899996\n",
      "Iteration:  11300 , loss:  0.012946794\n",
      "Iteration:  11400 , loss:  0.012860652\n",
      "Iteration:  11500 , loss:  0.015744384\n",
      "Iteration:  11600 , loss:  0.01283622\n",
      "Iteration:  11700 , loss:  0.012791158\n",
      "Iteration:  11800 , loss:  0.01366547\n",
      "Iteration:  11900 , loss:  0.012769993\n",
      "Iteration:  12000 , loss:  0.0127268685\n",
      "Iteration:  12100 , loss:  0.012838108\n",
      "Iteration:  12200 , loss:  0.012690493\n",
      "Iteration:  12300 , loss:  0.012674155\n",
      "Iteration:  12400 , loss:  0.013026817\n",
      "Iteration:  12500 , loss:  0.0126292175\n",
      "Iteration:  12600 , loss:  0.01305409\n",
      "Iteration:  12700 , loss:  0.012590729\n",
      "Iteration:  12800 , loss:  0.013180106\n",
      "Iteration:  12900 , loss:  0.012549389\n",
      "Iteration:  13000 , loss:  0.0132683795\n",
      "Iteration:  13100 , loss:  0.012513899\n",
      "Iteration:  13200 , loss:  0.012499944\n",
      "Iteration:  13300 , loss:  0.012509302\n",
      "Iteration:  13400 , loss:  0.0124548\n",
      "Iteration:  13500 , loss:  0.012417723\n",
      "Iteration:  13600 , loss:  0.012421397\n",
      "Iteration:  13700 , loss:  0.012374823\n",
      "Iteration:  13800 , loss:  0.012445429\n",
      "Iteration:  13900 , loss:  0.012333348\n",
      "Iteration:  14000 , loss:  0.013144489\n",
      "Iteration:  14100 , loss:  0.012294523\n",
      "Iteration:  14200 , loss:  0.016695835\n",
      "Iteration:  14300 , loss:  0.012231741\n",
      "Iteration:  14400 , loss:  0.012278826\n",
      "Iteration:  14500 , loss:  0.012178624\n",
      "Iteration:  14600 , loss:  0.012235542\n",
      "Iteration:  14700 , loss:  0.01213008\n",
      "Iteration:  14800 , loss:  0.012357544\n",
      "Iteration:  14900 , loss:  0.012072941\n",
      "Iteration:  15000 , loss:  0.012175798\n",
      "Iteration:  15100 , loss:  0.012027527\n",
      "Iteration:  15200 , loss:  0.015010997\n",
      "Iteration:  15300 , loss:  0.011983508\n",
      "Iteration:  15400 , loss:  0.011934912\n",
      "Iteration:  15500 , loss:  0.01194408\n",
      "Iteration:  15600 , loss:  0.011890781\n",
      "Iteration:  15700 , loss:  0.012295031\n",
      "Iteration:  15800 , loss:  0.011855442\n",
      "Iteration:  15900 , loss:  0.0118078645\n",
      "Iteration:  16000 , loss:  0.011839049\n",
      "Iteration:  16100 , loss:  0.01176987\n",
      "Iteration:  16200 , loss:  0.013660781\n",
      "Iteration:  16300 , loss:  0.011723796\n",
      "Iteration:  16400 , loss:  0.015823286\n",
      "Iteration:  16500 , loss:  0.011814921\n",
      "Iteration:  16600 , loss:  0.011614287\n",
      "Iteration:  16700 , loss:  0.0116144195\n",
      "Iteration:  16800 , loss:  0.011580698\n",
      "Iteration:  16900 , loss:  0.011530622\n",
      "Iteration:  17000 , loss:  0.011551051\n",
      "Iteration:  17100 , loss:  0.0114685455\n",
      "Iteration:  17200 , loss:  0.011471254\n",
      "Iteration:  17300 , loss:  0.011412518\n",
      "Iteration:  17400 , loss:  0.01143905\n",
      "Iteration:  17500 , loss:  0.011356372\n",
      "Iteration:  17600 , loss:  0.01138041\n",
      "Iteration:  17700 , loss:  0.011315318\n",
      "Iteration:  17800 , loss:  0.013320454\n",
      "Iteration:  17900 , loss:  0.011282228\n",
      "Iteration:  18000 , loss:  0.013120377\n",
      "Iteration:  18100 , loss:  0.011284837\n",
      "Iteration:  18200 , loss:  0.011209174\n",
      "Iteration:  18300 , loss:  0.011164671\n",
      "Iteration:  18400 , loss:  0.011185173\n",
      "Iteration:  18500 , loss:  0.011136368\n",
      "Iteration:  18600 , loss:  0.011250667\n",
      "Iteration:  18700 , loss:  0.011088823\n",
      "Iteration:  18800 , loss:  0.011141957\n",
      "Iteration:  18900 , loss:  0.011058556\n",
      "Iteration:  19000 , loss:  0.013848385\n",
      "Iteration:  19100 , loss:  0.011041793\n",
      "Iteration:  19200 , loss:  0.01125429\n",
      "Iteration:  19300 , loss:  0.0109864\n",
      "Iteration:  19400 , loss:  0.010989346\n",
      "Iteration:  19500 , loss:  0.01096292\n",
      "Iteration:  19600 , loss:  0.010971541\n",
      "Iteration:  19700 , loss:  0.010930418\n",
      "Iteration:  19800 , loss:  0.010933315\n",
      "Iteration:  19900 , loss:  0.010912511\n",
      "Generating 19th sample by deep ensemble...\n",
      "Iteration:  0 , loss:  3.6004128\n",
      "Iteration:  100 , loss:  2.1291184\n",
      "Iteration:  200 , loss:  1.6102369\n",
      "Iteration:  300 , loss:  0.7945204\n",
      "Iteration:  400 , loss:  0.28457955\n",
      "Iteration:  500 , loss:  0.19664836\n",
      "Iteration:  600 , loss:  0.15239488\n",
      "Iteration:  700 , loss:  0.12431401\n",
      "Iteration:  800 , loss:  0.10428265\n",
      "Iteration:  900 , loss:  0.09104527\n",
      "Iteration:  1000 , loss:  0.081218444\n",
      "Iteration:  1100 , loss:  0.07296057\n",
      "Iteration:  1200 , loss:  0.066327095\n",
      "Iteration:  1300 , loss:  0.058758914\n",
      "Iteration:  1400 , loss:  0.053281397\n",
      "Iteration:  1500 , loss:  0.048409745\n",
      "Iteration:  1600 , loss:  0.044521466\n",
      "Iteration:  1700 , loss:  0.04126595\n",
      "Iteration:  1800 , loss:  0.040440682\n",
      "Iteration:  1900 , loss:  0.036467183\n",
      "Iteration:  2000 , loss:  0.035975084\n",
      "Iteration:  2100 , loss:  0.033038598\n",
      "Iteration:  2200 , loss:  0.03428705\n",
      "Iteration:  2300 , loss:  0.03046057\n",
      "Iteration:  2400 , loss:  0.029611984\n",
      "Iteration:  2500 , loss:  0.028399374\n",
      "Iteration:  2600 , loss:  0.027459268\n",
      "Iteration:  2700 , loss:  0.026782867\n",
      "Iteration:  2800 , loss:  0.02592177\n",
      "Iteration:  2900 , loss:  0.026996244\n",
      "Iteration:  3000 , loss:  0.024685454\n",
      "Iteration:  3100 , loss:  0.02409051\n",
      "Iteration:  3200 , loss:  0.023530327\n",
      "Iteration:  3300 , loss:  0.023264227\n",
      "Iteration:  3400 , loss:  0.022586111\n",
      "Iteration:  3500 , loss:  0.027135879\n",
      "Iteration:  3600 , loss:  0.021759422\n",
      "Iteration:  3700 , loss:  0.021706749\n",
      "Iteration:  3800 , loss:  0.021036254\n",
      "Iteration:  3900 , loss:  0.020910393\n",
      "Iteration:  4000 , loss:  0.020404903\n",
      "Iteration:  4100 , loss:  0.02008492\n",
      "Iteration:  4200 , loss:  0.019903978\n",
      "Iteration:  4300 , loss:  0.019541662\n",
      "Iteration:  4400 , loss:  0.019548688\n",
      "Iteration:  4500 , loss:  0.019043146\n",
      "Iteration:  4600 , loss:  0.018784579\n",
      "Iteration:  4700 , loss:  0.0185785\n",
      "Iteration:  4800 , loss:  0.018325351\n",
      "Iteration:  4900 , loss:  0.018284744\n",
      "Iteration:  5000 , loss:  0.017911995\n",
      "Iteration:  5100 , loss:  0.017734308\n",
      "Iteration:  5200 , loss:  0.017534468\n",
      "Iteration:  5300 , loss:  0.017329674\n",
      "Iteration:  5400 , loss:  0.017413089\n",
      "Iteration:  5500 , loss:  0.017002322\n",
      "Iteration:  5600 , loss:  0.019104775\n",
      "Iteration:  5700 , loss:  0.016712246\n",
      "Iteration:  5800 , loss:  0.01668828\n",
      "Iteration:  5900 , loss:  0.01648277\n",
      "Iteration:  6000 , loss:  0.016334591\n",
      "Iteration:  6100 , loss:  0.017113239\n",
      "Iteration:  6200 , loss:  0.016123924\n",
      "Iteration:  6300 , loss:  0.016013868\n",
      "Iteration:  6400 , loss:  0.015937693\n",
      "Iteration:  6500 , loss:  0.015826155\n",
      "Iteration:  6600 , loss:  0.016238375\n",
      "Iteration:  6700 , loss:  0.015668405\n",
      "Iteration:  6800 , loss:  0.015576362\n",
      "Iteration:  6900 , loss:  0.015548219\n",
      "Iteration:  7000 , loss:  0.01543729\n",
      "Iteration:  7100 , loss:  0.017112587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  7200 , loss:  0.015309487\n",
      "Iteration:  7300 , loss:  0.01525708\n",
      "Iteration:  7400 , loss:  0.015219556\n",
      "Iteration:  7500 , loss:  0.0151382815\n",
      "Iteration:  7600 , loss:  0.0152850095\n",
      "Iteration:  7700 , loss:  0.015039195\n",
      "Iteration:  7800 , loss:  0.014976362\n",
      "Iteration:  7900 , loss:  0.014959408\n",
      "Iteration:  8000 , loss:  0.014891927\n",
      "Iteration:  8100 , loss:  0.017443547\n",
      "Iteration:  8200 , loss:  0.014809785\n",
      "Iteration:  8300 , loss:  0.03736512\n",
      "Iteration:  8400 , loss:  0.014733597\n",
      "Iteration:  8500 , loss:  0.0147046335\n",
      "Iteration:  8600 , loss:  0.014667729\n",
      "Iteration:  8700 , loss:  0.014617804\n",
      "Iteration:  8800 , loss:  0.014732528\n",
      "Iteration:  8900 , loss:  0.014556955\n",
      "Iteration:  9000 , loss:  0.04525865\n",
      "Iteration:  9100 , loss:  0.014503401\n",
      "Iteration:  9200 , loss:  0.014462518\n",
      "Iteration:  9300 , loss:  0.014605549\n",
      "Iteration:  9400 , loss:  0.014411472\n",
      "Iteration:  9500 , loss:  0.030621115\n",
      "Iteration:  9600 , loss:  0.014362238\n",
      "Iteration:  9700 , loss:  0.014326694\n",
      "Iteration:  9800 , loss:  0.0143231\n",
      "Iteration:  9900 , loss:  0.014278475\n",
      "Iteration:  10000 , loss:  0.014634761\n",
      "Iteration:  10100 , loss:  0.01423416\n",
      "Iteration:  10200 , loss:  0.027091091\n",
      "Iteration:  10300 , loss:  0.014198681\n",
      "Iteration:  10400 , loss:  0.014164472\n",
      "Iteration:  10500 , loss:  0.014270954\n",
      "Iteration:  10600 , loss:  0.014121965\n",
      "Iteration:  10700 , loss:  0.014626455\n",
      "Iteration:  10800 , loss:  0.014080881\n",
      "Iteration:  10900 , loss:  0.014296956\n",
      "Iteration:  11000 , loss:  0.014045555\n",
      "Iteration:  11100 , loss:  0.014018377\n",
      "Iteration:  11200 , loss:  0.014027156\n",
      "Iteration:  11300 , loss:  0.013981565\n",
      "Iteration:  11400 , loss:  0.014141144\n",
      "Iteration:  11500 , loss:  0.013947035\n",
      "Iteration:  11600 , loss:  0.018714976\n",
      "Iteration:  11700 , loss:  0.013912965\n",
      "Iteration:  11800 , loss:  0.013890166\n",
      "Iteration:  11900 , loss:  0.013896105\n",
      "Iteration:  12000 , loss:  0.013860086\n",
      "Iteration:  12100 , loss:  0.022866527\n",
      "Iteration:  12200 , loss:  0.01382933\n",
      "Iteration:  12300 , loss:  0.0138089275\n",
      "Iteration:  12400 , loss:  0.013802053\n",
      "Iteration:  12500 , loss:  0.013772296\n",
      "Iteration:  12600 , loss:  0.014005814\n",
      "Iteration:  12700 , loss:  0.013740048\n",
      "Iteration:  12800 , loss:  0.015719956\n",
      "Iteration:  12900 , loss:  0.013708378\n",
      "Iteration:  13000 , loss:  0.014068295\n",
      "Iteration:  13100 , loss:  0.0136755\n",
      "Iteration:  13200 , loss:  0.028231118\n",
      "Iteration:  13300 , loss:  0.0136421025\n",
      "Iteration:  13400 , loss:  0.03391315\n",
      "Iteration:  13500 , loss:  0.013609318\n",
      "Iteration:  13600 , loss:  0.013631225\n",
      "Iteration:  13700 , loss:  0.0135822175\n",
      "Iteration:  13800 , loss:  0.013550543\n",
      "Iteration:  13900 , loss:  0.013597235\n",
      "Iteration:  14000 , loss:  0.013514016\n",
      "Iteration:  14100 , loss:  0.0135614015\n",
      "Iteration:  14200 , loss:  0.013477717\n",
      "Iteration:  14300 , loss:  0.01355007\n",
      "Iteration:  14400 , loss:  0.013444938\n",
      "Iteration:  14500 , loss:  0.013431342\n",
      "Iteration:  14600 , loss:  0.013414931\n",
      "Iteration:  14700 , loss:  0.013381489\n",
      "Iteration:  14800 , loss:  0.013521803\n",
      "Iteration:  14900 , loss:  0.013346604\n",
      "Iteration:  15000 , loss:  0.014673945\n",
      "Iteration:  15100 , loss:  0.013310984\n",
      "Iteration:  15200 , loss:  0.0132817505\n",
      "Iteration:  15300 , loss:  0.013278093\n",
      "Iteration:  15400 , loss:  0.013241483\n",
      "Iteration:  15500 , loss:  0.013245296\n",
      "Iteration:  15600 , loss:  0.013203539\n",
      "Iteration:  15700 , loss:  0.013277788\n",
      "Iteration:  15800 , loss:  0.013167106\n",
      "Iteration:  15900 , loss:  0.013243694\n",
      "Iteration:  16000 , loss:  0.013129098\n",
      "Iteration:  16100 , loss:  0.0131378425\n",
      "Iteration:  16200 , loss:  0.013094426\n",
      "Iteration:  16300 , loss:  0.013114205\n",
      "Iteration:  16400 , loss:  0.013061961\n",
      "Iteration:  16500 , loss:  0.0130884545\n",
      "Iteration:  16600 , loss:  0.013029993\n",
      "Iteration:  16700 , loss:  0.013038987\n",
      "Iteration:  16800 , loss:  0.013000835\n",
      "Iteration:  16900 , loss:  0.013012186\n",
      "Iteration:  17000 , loss:  0.012974944\n",
      "Iteration:  17100 , loss:  0.013560759\n",
      "Iteration:  17200 , loss:  0.012949992\n",
      "Iteration:  17300 , loss:  0.031920057\n",
      "Iteration:  17400 , loss:  0.012926159\n",
      "Iteration:  17500 , loss:  0.013371732\n",
      "Iteration:  17600 , loss:  0.012901554\n",
      "Iteration:  17700 , loss:  0.014222519\n",
      "Iteration:  17800 , loss:  0.012877358\n",
      "Iteration:  17900 , loss:  0.03420812\n",
      "Iteration:  18000 , loss:  0.012853905\n",
      "Iteration:  18100 , loss:  0.02744768\n",
      "Iteration:  18200 , loss:  0.012833528\n",
      "Iteration:  18300 , loss:  0.0128262285\n",
      "Iteration:  18400 , loss:  0.012815038\n",
      "Iteration:  18500 , loss:  0.0127959335\n",
      "Iteration:  18600 , loss:  0.012818067\n",
      "Iteration:  18700 , loss:  0.012779354\n",
      "Iteration:  18800 , loss:  0.016106978\n",
      "Iteration:  18900 , loss:  0.012760949\n",
      "Iteration:  19000 , loss:  0.012913608\n",
      "Iteration:  19100 , loss:  0.012742395\n",
      "Iteration:  19200 , loss:  0.020109843\n",
      "Iteration:  19300 , loss:  0.012721127\n",
      "Iteration:  19400 , loss:  0.016636696\n",
      "Iteration:  19500 , loss:  0.012703421\n",
      "Iteration:  19600 , loss:  0.013103153\n",
      "Iteration:  19700 , loss:  0.0126848845\n",
      "Iteration:  19800 , loss:  0.013870327\n",
      "Iteration:  19900 , loss:  0.012669925\n",
      "Execution time for 'Trainable' function is: 283.895 s, 4.732 mins\n"
     ]
    }
   ],
   "source": [
    "processes, samples, model = Trainable(x_u_train, t_u_train, u_train, \n",
    "                                      x_f_train, t_f_train, f_train, noise, layers,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8929d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Predictions ####################################\n",
    "u_pred, logk_1_pred, logk_2_pred = model.predict(np.concatenate([x_test, t_test], axis=-1), \n",
    "                                                 samples, processes, pde_fn=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ceee36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean & Std of k1 are 1.616, 0.068\n",
      "Mean & Std of k2 are 0.348, 0.039\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################### Postprocessing ###################################\n",
    "    # TODO: save the results, instead of visualizing them.\n",
    "plots(\n",
    "    logk_1_pred,\n",
    "    logk_2_pred,\n",
    "    u_pred,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    u_test,\n",
    "    x_u_train,\n",
    "    t_u_train,\n",
    "    u_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918fa0b6",
   "metadata": {},
   "source": [
    "### Prova con un'altra equazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_fn(x, u, k_1, k_2):\n",
    "    u_x, u_t = tf.split(tf.gradients(u, x)[0], 2, axis=-1)\n",
    "    u_xx = tf.gradients(u_x, x)[0][..., 0:1]\n",
    "    u_xxx = tf.gradients(u_xx, x)[0][..., 0:1]\n",
    "    f = u_t - tf.exp(k_1) * u * u_x - tf.exp(k_2) * u_xxx\n",
    "    # tf.exp(k_1) Computes exponential of k_1 element-wise (y = e^{k_1})\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8578a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
